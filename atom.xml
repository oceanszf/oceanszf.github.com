<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[Suzf Blog]]></title>
  <subtitle><![CDATA[Life is short, We need smile.]]></subtitle>
  <link href="/atom.xml" rel="self"/>
  <link href="http://blog.suzf.net/"/>
  <updated>2016-03-31T06:27:01.000Z</updated>
  <id>http://blog.suzf.net/</id>
  
  <author>
    <name><![CDATA[Jeffrey Su]]></name>
    <email><![CDATA[i@suzf.net]]></email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title><![CDATA[[译]  zookeeper 配置文件详解]]></title>
    <link href="http://blog.suzf.net/2016/03/29/'%5B%E8%AF%91%5D__zookeeper_%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3'/"/>
    <id>http://blog.suzf.net/2016/03/29/'[译]__zookeeper_配置文件详解'/</id>
    <published>2016-03-29T07:22:32.000Z</published>
    <updated>2016-03-31T06:27:01.000Z</updated>
    <content type="html"><![CDATA[<p><strong>必填配置参数</strong></p>
<p>clientPort</p>
<p>该端口监听客户端的连接。也就是说，客户端都会尝试连接该端口。</p>
<p>dataDir</p>
<p>该路径用于存储zookeeper内存数据库快照。除非有特殊设定，否则也会存储数据库更新的事物日志。事物日志的存放位置是很有讲究的。有一台专门用于存放事物日志的设备，可以产生持久的高性能。讲日志放在高负荷的设备上，会对性能产生副作用。<a id="more"></a></p>
<p>tickTime</p>
<p>一个心跳的长度，它是zookeeper毫秒级的一个基本时间单位。它用来设定心跳间隔和超时时间。例如，最小会话超时时间是两倍的心跳长度。</p>
<p><strong>可选配置参数</strong></p>
<p>dataLogDir</p>
<p>这个选项指定将事物日志存储于该路径，代替了dataDir。目的是可以用专门的设备来存储日志，这样可以避免日志和快照的资源竞争。有一个专门的 日志存储设备，可以导致高的吞吐量和稳定性。我们更推荐使用一台专用日志设备并用dataLogDir在该设备上指定目录来存放日志，这样可以保证 dataDir指定的目录不在该设备上(dataDir指定存放快照的目录，快照和日志会竞争资源)。</p>
<p>globalOutstandingLimit(java:zookeeper.globalOutstandingLimit)</p>
<p>客户端提交请求的速度可能会超过zookeeper处理请求的速度，尤其是存在大量的客户端。为了避免由于排队的请求导致的内存溢 出，zookeeper将会对客户端进行限流，将请求的数量保持在globalOutstandingLimit以下。 globalOutstandingLimit的默认值是1000。</p>
<p>preAllocSize(java:zookeeper.preAllocSize)</p>
<p>zookeeper将事务日志文件分割成preAllocSize kb大小的模块，这样可以避免查询带来的消耗。默认的模块大小是64M。当快照频繁产生时，我们可以肩上模块的大小来提高系统的效率(这段好难翻译，还不知道对不对)。</p>
<p>snapCount(java:zookeeper.snapCount)</p>
<p>zookeeper将所有事务记录到日志中。当记录了snapCount数量的事务后，会生成新的快照和事务日志文件。snapCount默认值是100000。</p>
<p>traceFile(Java:requestTraceFile)</p>
<p>如果使用该选项，我们会将请求记录在追踪文件中，并将其以traceFile.year.month.day格式命名。这个选项可以提供调试信息，但会影响性能。</p>
<p>maxClientCnxns</p>
<p>一个客户端的最大并发连接数(接口级别)，每台客户端用IP地址区分，成为zookeeper总体中的一个成员(貌似翻译的不对)。它用来防止某些DoS攻击，包括文件描述符耗尽(不懂-_-||)。默认值是60。将其设定为0，则取消并发连接数的限制。</p>
<p>clientPortAddress</p>
<p>监听客户端连接的地址(ipv4,ipv6,hostname)，也就是说，客户端会尝试连接该地址。可选配置，默认情况下，客户端都会连接到clientPort上(address,interface,nic)。</p>
<p>minSessionTimeout</p>
<p>最小会话超时时间(毫秒级)，默认是2倍的tickTime。</p>
<p>maxSessionTimeout</p>
<p>最大会话超时时间(毫秒级)，默认是20倍的tickTime。(在代码中会设置超时时间，但是必须在这里设定的最小与最大值之间，否则直接取最小/最大值)</p>
<p>fsync.warningthresholdms(java:fsync.warningthresholdms)</p>
<p>当日志中的fsync函数超出了该值的长度，就会在日志出输出警告信息。默认值是1000(毫秒级)，是系统属性。</p>
<p>autopurge.snapRetainCount</p>
<p>当启用时，zookeeper将自动储存最近autopurge.snapRetainCount次的快照和事务日志，分别放在dataDir和dataLogDir中，其余部分将被删除。默认值是3，最小值是3。</p>
<p>autopurge.purgeInterval</p>
<p>设置该定时器，能定时触发净化任务(清理快照和日志)，单位为小时，值为大于等于1的正整数，默认值是0。</p>
<p><strong>集群选项</strong></p>
<p>electionAlg</p>
<p>作用是实现选举。0是基于UDP的传统版本，1是基于未认证UDP的快速选举版本，2是基于已认证UDP的快速选举版本，3是基于TCP的快速选举版本。默认值是3。(0/1/2已经不建议使用，在下个版本准备取消)</p>
<p>initLimit</p>
<p>在心跳连接中，允许followers连接leader和与leader同步数据的时间。如果zookeeper管理的数据比较大，可以增加此值。</p>
<p>leaderServes(zookeeper.leaderServes)</p>
<p>leader接受客户端的连接。默认值是“yes”。leader主机的坐标更新。要实现使用很少的读取量而达到更高的更新量，leader可以不 接受客户端的连接而是只专注于负载的均衡。默认值是“yes”，就是可以接受连接。(当集群中存在3台以上的zookeeper服务端时，推荐使用 “no”)</p>
<p>server.x=[hostname]:nnnnn[:nnnnn]，etc</p>
<p>配置的服务端组成zookeeper集群。集群启动时，将在配置的服务端上寻找myid文件。该文件包含服务器编号，于server.x中的x值相匹配。</p>
<p>每台zookeeper服务器都持有这个服务器列表，客户端必须根据这个列表进行连接。</p>
<p>配置中还存在两个端口号nnnnn。第一个端口号用于follower连接leader，第二个端口号用于leader的选举。当electionAlg=1,2,3时，选举端口是必要的。当=0时，不是必要的。加入想要在单机上测试集群，可以使用不同端口号来模拟。</p>
<p>syncLimit</p>
<p>在心跳连接中，允许followers同步zookeeper数据的时间。如果followers与leader长久失去连接，它将被丢弃。</p>
<p>group.x=nnnnn[:nnnnn]</p>
<p>实现一个分层的法定人数的构造。“x”是组的标识，“=”后边是服务器的标识。</p>
<p>例：group.2=4:5:6<br>group.3=7:8:9</p>
<p>weight.x=nnnnn[:nnnnn]</p>
<p>要与group搭配使用，为服务器设置一个比重。这个比重就是选举投票时一台服务器的比重。group.1=1:2:3</p>
<p>例：weight.1=1<br>weight.2=1<br>weight.3=1<br>weight.4=1<br>weight.5=1<br>weight.6=1<br>weight.7=1<br>weight.8=1<br>weight.9=1</p>
<p>cnxTimeout</p>
<p>leader选举的超时时间，electionAlg=3时才起作用。默认值是5秒。</p>
<p>原文地址：<a href="http://zookeeper.apache.org/doc/r3.4.5/zookeeperAdmin.html" target="_blank" rel="external">http://zookeeper.apache.org/doc/r3.4.5/zookeeperAdmin.html</a></p>
<p>来源： <a href="http://my.csdn.net/u011796274" target="_blank" rel="external">静静的小猪</a></p>
]]></content>
    <summary type="html">
    <![CDATA[<p><strong>必填配置参数</strong></p>
<p>clientPort</p>
<p>该端口监听客户端的连接。也就是说，客户端都会尝试连接该端口。</p>
<p>dataDir</p>
<p>该路径用于存储zookeeper内存数据库快照。除非有特殊设定，否则也会存储数据库更新的事物日志。事物日志的存放位置是很有讲究的。有一台专门用于存放事物日志的设备，可以产生持久的高性能。讲日志放在高负荷的设备上，会对性能产生副作用。]]>
    
    </summary>
    
      <category term="zookeeper" scheme="http://blog.suzf.net/tags/zookeeper/"/>
    
      <category term="Hadoop" scheme="http://blog.suzf.net/categories/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[[译] zookpeer 入门教程]]></title>
    <link href="http://blog.suzf.net/2016/03/29/'%5B%E8%AF%91%5D_zookpeer_%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B'/"/>
    <id>http://blog.suzf.net/2016/03/29/'[译]_zookpeer_入门教程'/</id>
    <published>2016-03-29T07:19:33.000Z</published>
    <updated>2016-03-31T06:27:01.000Z</updated>
    <content type="html"><![CDATA[<h3 id="u5165_u95E8_uFF1A_u5206_u5E03_u5F0F_u5E94_u7528_u7A0B_u5E8F_u534F_u8C03_u670D_u52A1_ZooKeeper"><a href="#u5165_u95E8_uFF1A_u5206_u5E03_u5F0F_u5E94_u7528_u7A0B_u5E8F_u534F_u8C03_u670D_u52A1_ZooKeeper" class="headerlink" title="入门：分布式应用程序协调服务 ZooKeeper"></a>入门：分布式应用程序协调服务 ZooKeeper</h3><p>本文档包含的信息来帮助你的ZooKeeper快速入门。它是在开发人员希望能够尝试一下主要目的，并包含安装简单说明一个ZooKeeper的服务器，几个命令，以验证它是否正在运行，一个简单的编程示例。最后，为了方便，还有更多的关于安装复杂，几节，例如运行复制的部署和优化事务日志。然而，对于商业部署的完整说明，请参阅的<a href="http://zookeeper.apache.org/doc/trunk/zookeeperAdmin.html" target="_blank" rel="external">ZooKeeper管理员指南</a>。</p>
<h3 id="u5148_u51B3_u6761_u4EF6"><a href="#u5148_u51B3_u6761_u4EF6" class="headerlink" title="先决条件"></a>先决条件</h3><p>见管理员指南中的<a href="http://zookeeper.apache.org/doc/trunk/zookeeperAdmin.html#sc_systemReq" target="_blank" rel="external">系统要求</a>。</p>
<h3 id="u4E0B_u8F7D"><a href="#u4E0B_u8F7D" class="headerlink" title="下载"></a>下载</h3><p>从Apache下载镜像下载最近的<a href="http://zookeeper.apache.org/releases.html" target="_blank" rel="external">稳定版本</a> ，从而得到 ZooKeeper 程序。</p>
<h3 id="Standalone__u6A21_u5F0F_u4E0B_u64CD_u4F5C"><a href="#Standalone__u6A21_u5F0F_u4E0B_u64CD_u4F5C" class="headerlink" title="Standalone 模式下操作"></a>Standalone 模式下操作</h3><p>设置在独立模式&lt; standalone &gt;下的ZooKeeper服务器很简单。服务器被包含在一个单一的JAR文件中，所以安装包括创建一个新的配置。</p>
<p>一旦你下载一个稳定ZooKeeper的版本 解压它并进入解压的根路径<br>要启动的ZooKeeper你需要一个配置文件。下面是一个示例, 新建文件  conf/zoo.cfg：</p>
<p><pre class="lang:default decode:true ">tickTime=2000<br>dataDir=/var/lib/zookeeper<br>clientPort=2181</pre><br>这个文件可以叫任何一个名字，但是一般我们更喜欢 设置为  conf/zoo.cfg. 我们需要将 dataDir 的值 设置为一个指定的目录，一开始这个是空的。<br>下面是每个参数的含义：<br>tickTime：基本事件单元，以毫秒为单位。它用来指示心跳，最小的 session 过期时间为两倍的 tickTime. 。<br>dataDir：存储内存中数据库快照的位置，如果不设置参数，更新事务日志将被存储到默认位置。<br>clientPort：监听客户端连接的端口</p>
<p>现在你可以创建文件并且启动它了<br>bin/zkServer.sh start</p>
<p>ZooKeeper 日志使用 log4j – 更多详细信息请查看编程指南的 <a href="http://zookeeper.apache.org/doc/trunk/zookeeperProgrammers.html#Logging" target="_blank" rel="external">日志</a> 部分。 你将会看到日志出现在控制台&lt; 默认 &gt; 日志文件依赖于log4j 的配置文件。</p>
<p>上面所述的是如何使 ZooKeeper 运行在单点模式下。这里没有复制，所以如果 ZooKeeper 进程出现错误，服务将不可用。这是一个不错的开发解决方案，但是如果想要使 ZooKeeper 运行在复制模式下，请参见 <a href="http://zookeeper.apache.org/doc/trunk/zookeeperStarted.html#sc_RunningReplicatedZooKeeper" target="_blank" rel="external">Running Replicated ZooKeeper</a>.</p>
<h3 id="u7BA1_u7406_ZooKeeper__u5B58_u50A8"><a href="#u7BA1_u7406_ZooKeeper__u5B58_u50A8" class="headerlink" title="管理 ZooKeeper 存储"></a>管理 ZooKeeper 存储</h3><p>对于长期运行在生产环境的 ZooKeeper 来说 存储必须外部管理（dataDir &amp;&amp; logs）。获取更多信息见 <a href="http://zookeeper.apache.org/doc/trunk/zookeeperAdmin.html#sc_maintenance" target="_blank" rel="external">维护部分</a>。</p>
<h3 id="u8FDE_u63A5_ZooKeeper"><a href="#u8FDE_u63A5_ZooKeeper" class="headerlink" title="连接 ZooKeeper"></a>连接 ZooKeeper</h3><p>一旦 ZooKeeper 运行起来，你会有很多种方式连接它：</p>
<ul>
<li>Java:<br>bin/zkCli.sh -server 127.0.0.1:2181<br>这样是你的操作变得简单，想文件操作一样。</li>
<li>C:  C: compile cli_mt (multi-threaded) or cli_st (single-threaded) by running make     cli_mt or make cli_st in the src/c subdirectory in the ZooKeeper sources. See the     README contained within src/c for full details<br>You can run the program from src/c using:<br>LD_LIBRARY_PATH=. cli_mt 127.0.0.1:2181<br>or<br>LD_LIBRARY_PATH=. cli_st 127.0.0.1:2181<br>它会给你在ZooKeeper上提供一个简单的shell执行文件操作。<br>一旦你成功连接，你将会看到类似下面的信息：<br><pre class="lang:default decode:true ">Connecting to localhost:2181<br>log4j:WARN No appenders could be found for logger (org.apache.zookeeper.ZooKeeper).<br>log4j:WARN Please initialize the log4j system properly.<br>Welcome to ZooKeeper!<br>JLine support is enabled<br>[zkshell: 0]</pre><br>在shell中，在客户端键入 <code>help</code> 可以得到帮助信息：<br><pre class="lang:default decode:true">[zkshell: 0] help<br>ZooKeeper host:port cmd args<pre><code>get path [watch]
ls path [watch]
set path data [version]
delquota [-n|-b] path
quit
printwatches on|off
create path data acl
stat path [watch]
listquota path
history
setAcl path acl
getAcl path
sync path
redo cmdno
addauth scheme auth
delete path [version]
deleteall path
setquota -n|-b val path&lt;/pre&gt;
</code></pre>在这里，你可以键入一些简单的命令来感受这个简单的命令行界面。首先，从list 命令开始 ，如ls：<br><pre class="lang:default decode:true ">[zkshell: 8] ls /<br>[zookeeper]</pre><br>接下来，执行 <code>create /zk_test my_data</code> 创建一个新的 znode。这个新创建的znode 和字符串”my_data”是关联的。你应该可以看到：<br><pre class="lang:default decode:true ">[zkshell: 9] create /zk_test my_data<br>Created /zk_test</pre><br>发出另一个 <code>ls /</code> 命令查看目录：<br><pre class="lang:default decode:true ">[zkshell: 11] ls /<br>[zookeeper, zk_test]</pre><br>请注意，zk_test 目录现在已经创建完成了。<br>接下来，执行 get 命令来验证数据与其关联的znode:<br><pre class="lang:default decode:true ">[zkshell: 12] get /zk_test<br>my_data<br>cZxid = 5<br>ctime = Fri Jun 05 13:57:06 PDT 2009<br>mZxid = 5<br>mtime = Fri Jun 05 13:57:06 PDT 2009<br>pZxid = 5<br>cversion = 0<br>dataVersion = 0<br>aclVersion = 0<br>ephemeralOwner = 0<br>dataLength = 7<br>numChildren = 0</pre><br>我们可以使用 set 命令来修改与zk_test相关的数据：<br><pre class="lang:default decode:true">[zkshell: 14] set /zk_test junk<br>cZxid = 5<br>ctime = Fri Jun 05 13:57:06 PDT 2009<br>mZxid = 6<br>mtime = Fri Jun 05 14:01:52 PDT 2009<br>pZxid = 5<br>cversion = 0<br>dataVersion = 1<br>aclVersion = 0<br>ephemeralOwner = 0<br>dataLength = 4<br>numChildren = 0<br>[zkshell: 15] get /zk_test<br>junk<br>cZxid = 5<br>ctime = Fri Jun 05 13:57:06 PDT 2009<br>mZxid = 6<br>mtime = Fri Jun 05 14:01:52 PDT 2009<br>pZxid = 5<br>cversion = 0<br>dataVersion = 1<br>aclVersion = 0<br>ephemeralOwner = 0<br>dataLength = 4<br>numChildren = 0</pre><br>（请注意，我们在更新完数据之后通过get得到了它有变动）<br>最后，让我们删除我们之前创建的znode:<br><pre class="lang:default decode:true ">[zkshell: 16] delete /zk_test<br>[zkshell: 17] ls /<br>[zookeeper]<br>[zkshell: 18]</pre><br>到此为止吧。如果要获取更多信息，继续本文档的其余部分和 <a href="http://zookeeper.apache.org/doc/trunk/zookeeperProgrammers.html" target="_blank" rel="external">程序员指南</a>。</pre></li>
</ul>
<h3 id="ZooKeeper__u7F16_u7A0B"><a href="#ZooKeeper__u7F16_u7A0B" class="headerlink" title="ZooKeeper 编程"></a>ZooKeeper 编程</h3><p>ZooKeeper提供了 Java 和 C 两种程序语言接口。它们功能上是等价的。但是C接口有两种变种存在：单线程和多线程。这些只有在如何完成消息循环是不同的。欲了解更多信息，请参阅的<a href="http://zookeeper.apache.org/doc/trunk/zookeeperProgrammers.html" target="_blank" rel="external">ZooKeeper程序员指南中的编程示例</a>使用不同的API的示例代码。</p>
<h3 id="ZooKeeper_Replicated"><a href="#ZooKeeper_Replicated" class="headerlink" title="ZooKeeper Replicated"></a>ZooKeeper Replicated</h3><p>在开发和测试模式下，将ZooKeeper运行在独立模式下便于评估。但是在生产模式下，你应该讲ZooKeeper运行在 replicated 模式下。对于相同的应用程序来说，一组运行在replicated 的机器被称作 quorum。所有在 quorum 中的机器都有相同配置文件。</p>
<blockquote>
<p>注意：</p>
<p>对于复制模式来说，至少需要三台机器，这里强烈建议你有奇数台机器。如果你只有两台机器，那么你可能会出现这种情况，如果其中一个出现故障，在有些情况下没有足够的机器来形成多数quorum。两个服务器比单个服务器还不稳定，因为当有故障时它们都指向错误。<br>这里在复制模式下需要的 cong/zoo.cfg 文件与在单节点模式下很相近，但是这里有些不同。<br>请看下面的例子：</p>
<p><pre class="lang:default decode:true ">tickTime=2000<br>dataDir=/var/lib/zookeeper<br>clientPort=2181<br>initLimit=5<br>syncLimit=2<br>server.1=zoo1:2888:3888<br>server.2=zoo2:2888:3888<br>server.3=zoo3:2888:3888</pre><br>新的条目<br>initLimit 在心跳连接中，允许followers连接leader和与leader同步数据的时间。如果zookeeper管理的数据比较大，可以增加此值。<br>syncLimit 在心跳连接中，允许followers同步zookeeper数据的时间。如果followers与leader长久失去连接，它将被丢弃。</p>
</blockquote>
<p>有了这两个关于超时的参数，你可以使用tickTime确定时间单元。在这个例子中，initLimit 的超时是 5 ticks &lt;2000 毫秒 一 tick &gt;,或者是10 秒。</p>
<p>表单中的 <code>server.x</code> 列出了组成 ZooKeeper 服务的机器。当服务启动的时候，它通过查找数据目录中的文件身份识别码来识别它是哪台服务器。这个文件有包含了以ASCII码 编码的服务器编号。</p>
<p>最后，注意每个服务器名称后的两个端口号：”2888”和”3888”。同行使用当前端口连接到其他节点。这样的连接测试是必要的，这样对等体可以进行通信，例如，在更新的顺序一致中。更具体地说，ZooKeeper的服务器使用此端口将follower连接到leader。当一个新的leader出现，follower打开一个TCP连接，使用此端口连接到leader。因为默认leader选举也采用TCP，我们目前需要的其他端口用来leader的选举。这就是在server条目的第二端口。</p>
<blockquote>
<p>注意：</p>
<p>如果你现在单机上测试集群伪分布。在本地主机该服务器的配置文件中的每个server.X 中指定服务器名与唯一的 quorum &amp; leader 选举端口(如：2888:3888, 2889:3889, 2890:3890 )。当然，独立的dataDirs和不同的客户端端口也是必要的（在上面的复制例如，在一个单一的本地主机上运行，你仍然有三个配置文件）。</p>
<p>请注意，在一台机器上设置的集群伪分布不会产生任何冗余。如果出了什么错误造成机器不能正常提供服务，所有的ZooKeeper服务将下线。完全冗余需要每个服务器都有它自己的机器。它必须是一个完全独立的物理服务器。在同一台物理主机上的多个虚拟机仍然容易受到威胁。<br>&nbsp;</p>
</blockquote>
<h3 id="u5176_u4ED6_u64CD_u4F5C"><a href="#u5176_u4ED6_u64CD_u4F5C" class="headerlink" title="其他操作"></a>其他操作</h3><p>这里仍有一些其他配置参数可以大大提升性能：</p>
<p>有一个专门的事务日志目录是很重要的可以在更新的时候降低延迟。在默认情况下，在同一目录存放 data snapshots 和 myid 文件.这个 dataLogDir 参数表示不同的目录用于事务日志。</p>
<p>待定： … …</p>
<p>原文：<a href="http://zookeeper.apache.org/doc/trunk/zookeeperStarted.html" target="_blank" rel="external">ZooKeeper Getting Started Guide</a></p>
]]></content>
    <summary type="html">
    <![CDATA[<h3 id="u5165_u95E8_uFF1A_u5206_u5E03_u5F0F_u5E94_u7528_u7A0B_u5E8F_u534F_u8C03_u670D_u52A1_ZooKeeper"><a href="#u5165_u95E8_uFF1A_u5206_u5E]]>
    </summary>
    
      <category term="zookeeper" scheme="http://blog.suzf.net/tags/zookeeper/"/>
    
      <category term="Hadoop" scheme="http://blog.suzf.net/categories/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[zookeeper 工作原理]]></title>
    <link href="http://blog.suzf.net/2016/03/23/zookeeper_%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/"/>
    <id>http://blog.suzf.net/2016/03/23/zookeeper_工作原理/</id>
    <published>2016-03-23T13:26:16.000Z</published>
    <updated>2016-03-31T05:38:36.000Z</updated>
    <content type="html"><![CDATA[<p>ZooKeeper 是一个分布式的，开放源码的分布式应用程序协调服务，它包含一个简单的原语集，分布式应用程序可以基于它实现同步服务，配置维护和命名服务等。 Zookeeper是hadoop的一个子项目，其发展历程无需赘述。在分布式应用中，由于工程师不能很好地使用锁机制，以及基于消息的协调机制不适合在 某些应用中使用，因此需要有一种可靠的、可扩展的、分布式的、可配置的协调机制来统一系统的状态。Zookeeper的目的就在于此。本文简单分析 zookeeper的工作原理，对于如何使用zookeeper不是本文讨论的重点。<a id="more"></a></p>
<p><strong>1 Zookeeper的基本概念</strong></p>
<p><strong>1.1 角色</strong></p>
<p>Zookeeper中的角色主要有以下三类，如下表所示：</p>
<p><a href="http://suzf.net/wp-content/uploads/2016/03/zk1.png" target="_blank" rel="external"><img src="http://suzf.net/wp-content/uploads/2016/03/zk1.png" alt="zk1"></a></p>
<p>系统模型如图所示：</p>
<p><a href="http://suzf.net/wp-content/uploads/2016/03/zk2.png" target="_blank" rel="external"><img src="http://suzf.net/wp-content/uploads/2016/03/zk2.png" alt="zk2"></a></p>
<p><strong>1.2 设计目的</strong></p>
<p>1.最终一致性：client不论连接到哪个Server，展示给它都是同一个视图，这是zookeeper最重要的性能。</p>
<p>2 .可靠性：具有简单、健壮、良好的性能，如果消息m被到一台服务器接受，那么它将被所有的服务器接受。</p>
<p>3 .实时性：Zookeeper保证客户端将在一个时间间隔范围内获得服务器的更新信息，或者服务器失效的信息。但由于网络延时等原因，Zookeeper不能保证两个客户端能同时得到刚更新的数据，如果需要最新数据，应该在读数据之前调用sync()接口。</p>
<p>4 .等待无关（wait-free）：慢的或者失效的client不得干预快速的client的请求，使得每个client都能有效的等待。</p>
<p>5.原子性：更新只能成功或者失败，没有中间状态。</p>
<p>6 .顺序性：包括全局有序和偏序两种：全局有序是指如果在一台服务器上消息a在消息b前发布，则在所有Server上消息a都将在消息b前被发布；偏序是指如果一个消息b在消息a后被同一个发送者发布，a必将排在b前面。</p>
<p><strong>2 ZooKeeper的工作原理</strong></p>
<p>Zookeeper的核心是原子广播，这个机制保证了各个Server之间的同步。实现这个机制的协议叫做Zab协议。Zab协议有两种模式，它们 分别是恢复模式（选主）和广播模式（同步）。当服务启动或者在领导者崩溃后，Zab就进入了恢复模式，当领导者被选举出来，且大多数Server完成了和 leader的状态同步以后，恢复模式就结束了。状态同步保证了leader和Server具有相同的系统状态。</p>
<p>为了保证事务的顺序一致性，zookeeper采用了递增的事务id号（zxid）来标识事务。所有的提议（proposal）都在被提出的时候加 上了zxid。实现中zxid是一个64位的数字，它高32位是epoch用来标识leader关系是否改变，每次一个leader被选出来，它都会有一 个新的epoch，标识当前属于那个leader的统治时期。低32位用于递增计数。</p>
<p>每个Server在工作过程中有三种状态：</p>
<ul>
<li>LOOKING：当前Server不知道leader是谁，正在搜寻</li>
<li>LEADING：当前Server即为选举出来的leader</li>
<li>FOLLOWING：leader已经选举出来，当前Server与之同步<br><strong>2.1 选主流程</strong></li>
</ul>
<p>当leader崩溃或者leader失去大多数的follower，这时候zk进入恢复模式，恢复模式需要重新选举出一个新的leader，让所有 的Server都恢复到一个正确的状态。Zk的选举算法有两种：一种是基于basic paxos实现的，另外一种是基于fast paxos算法实现的。系统默认的选举算法为fast paxos。先介绍basic paxos流程：</p>
<ol>
<li>1 .选举线程由当前Server发起选举的线程担任，其主要功能是对投票结果进行统计，并选出推荐的Server；</li>
<li>2 .选举线程首先向所有Server发起一次询问(包括自己)；</li>
<li>3 .选举线程收到回复后，验证是否是自己发起的询问(验证zxid是否一致)，然后获取对方的id(myid)，并存储到当前询问对象列表中，最后获取对方提议的leader相关信息(id,zxid)，并将这些信息存储到当次选举的投票记录表中；</li>
<li>收到所有Server回复以后，就计算出zxid最大的那个Server，并将这个Server相关信息设置成下一次要投票的Server；</li>
<li>线程将当前zxid最大的Server设置为当前Server要推荐的Leader，如果此时获胜的Server获得n/2 + 1的Server票数， 设置当前推荐的leader为获胜的Server，将根据获胜的Server相关信息设置自己的状态，否则，继续这个过程，直到leader被选举出来。<br>通过流程分析我们可以得出：要使Leader获得多数Server的支持，则Server总数必须是奇数2n+1，且存活的Server的数目不得少于n+1.</li>
</ol>
<p>每个Server启动后都会重复以上流程。在恢复模式下，如果是刚从崩溃状态恢复的或者刚启动的server还会从磁盘快照中恢复数据和会话信息，zk会记录事务日志并定期进行快照，方便在恢复时进行状态恢复。选主的具体流程图如下所示：</p>
<p><a href="http://suzf.net/wp-content/uploads/2016/03/zk3.png" target="_blank" rel="external"><img src="http://suzf.net/wp-content/uploads/2016/03/zk3.png" alt="zk3"></a></p>
<p>fast paxos流程是在选举过程中，某Server首先向所有Server提议自己要成为leader，当其它Server收到提议以后，解决epoch和 zxid的冲突，并接受对方的提议，然后向对方发送接受提议完成的消息，重复这个流程，最后一定能选举出Leader。其流程图如下所示：</p>
<p><a href="http://suzf.net/wp-content/uploads/2016/03/zk4.png" target="_blank" rel="external"><img src="http://suzf.net/wp-content/uploads/2016/03/zk4.png" alt="zk4"></a></p>
<p><strong>2.2 同步流程</strong></p>
<p>选完leader以后，zk就进入状态同步过程。</p>
<ol>
<li>leader等待server连接；</li>
<li>2 .Follower连接leader，将最大的zxid发送给leader；</li>
<li>3 .Leader根据follower的zxid确定同步点；</li>
<li>4 .完成同步后通知follower 已经成为uptodate状态；</li>
<li>5 .Follower收到uptodate消息后，又可以重新接受client的请求进行服务了。<br>流程图如下所示：</li>
</ol>
<p><a href="http://suzf.net/wp-content/uploads/2016/03/zk5.png" target="_blank" rel="external"><img src="http://suzf.net/wp-content/uploads/2016/03/zk5.png" alt="zk5"></a></p>
<p><strong>2.3 工作流程</strong></p>
<p><strong>2.3.1 Leader工作流程</strong></p>
<p>Leader主要有三个功能：</p>
<ol>
<li>1 .恢复数据；</li>
<li>2 .维持与Learner的心跳，接收Learner请求并判断Learner的请求消息类型；</li>
<li>3 .Learner的消息类型主要有PING消息、REQUEST消息、ACK消息、REVALIDATE消息，根据不同的消息类型，进行不同的处理。<br>PING消息是指Learner的心跳信息；REQUEST消息是Follower发送的提议信息，包括写请求及同步请求；ACK消息是 Follower的对提议的回复，超过半数的Follower通过，则commit该提议；REVALIDATE消息是用来延长SESSION有效时间。<br>Leader的工作流程简图如下所示，在实际实现中，流程要比下图复杂得多，启动了三个线程来实现功能。</li>
</ol>
<p><a href="http://suzf.net/wp-content/uploads/2016/03/zk6.png" target="_blank" rel="external"><img src="http://suzf.net/wp-content/uploads/2016/03/zk6.png" alt="zk6"></a></p>
<p><strong>2.3.2 Follower工作流程</strong></p>
<p>Follower主要有四个功能：</p>
<ol>
<li>向Leader发送请求（PING消息、REQUEST消息、ACK消息、REVALIDATE消息）；</li>
<li>2 .接收Leader消息并进行处理；</li>
<li>3 .接收Client的请求，如果为写请求，发送给Leader进行投票；</li>
<li><p>4 .返回Client结果。<br>Follower的消息循环处理如下几种来自Leader的消息：</p>
</li>
<li><p><strong>1 .PING</strong>消息： 心跳消息；</p>
</li>
<li><strong>2 .PROPOSAL</strong>消息：Leader发起的提案，要求Follower投票；</li>
<li><strong>3 .COMMIT</strong>消息：服务器端最新一次提案的信息；</li>
<li><strong>4 .UPTODATE</strong>消息：表明同步完成；</li>
<li><strong>5 .REVALIDATE</strong>消息：根据Leader的REVALIDATE结果，关闭待revalidate的session还是允许其接受消息；</li>
<li><strong>6 .SYNC</strong>消息：返回SYNC结果到客户端，这个消息最初由客户端发起，用来强制得到最新的更新。<br>Follower的工作流程简图如下所示，在实际实现中，Follower是通过5个线程来实现功能的。</li>
</ol>
<p><a href="http://suzf.net/wp-content/uploads/2016/03/zk7.png" target="_blank" rel="external"><img src="http://suzf.net/wp-content/uploads/2016/03/zk7.png" alt="zk7"></a></p>
<p>对于observer的流程不再叙述，observer流程和Follower的唯一不同的地方就是observer不会参加leader发起的投票。</p>
<p>出处 未知</p>
<p>~ ~ EOF ~~</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>ZooKeeper 是一个分布式的，开放源码的分布式应用程序协调服务，它包含一个简单的原语集，分布式应用程序可以基于它实现同步服务，配置维护和命名服务等。 Zookeeper是hadoop的一个子项目，其发展历程无需赘述。在分布式应用中，由于工程师不能很好地使用锁机制，以及基于消息的协调机制不适合在 某些应用中使用，因此需要有一种可靠的、可扩展的、分布式的、可配置的协调机制来统一系统的状态。Zookeeper的目的就在于此。本文简单分析 zookeeper的工作原理，对于如何使用zookeeper不是本文讨论的重点。]]>
    
    </summary>
    
      <category term="zookeeper" scheme="http://blog.suzf.net/tags/zookeeper/"/>
    
      <category term="Hadoop" scheme="http://blog.suzf.net/categories/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[高可用 开源的 Redis 缓存集群方案]]></title>
    <link href="http://blog.suzf.net/2016/03/21/%E9%AB%98%E5%8F%AF%E7%94%A8_%E5%BC%80%E6%BA%90%E7%9A%84_Redis_%E7%BC%93%E5%AD%98%E9%9B%86%E7%BE%A4%E6%96%B9%E6%A1%88/"/>
    <id>http://blog.suzf.net/2016/03/21/高可用_开源的_Redis_缓存集群方案/</id>
    <published>2016-03-21T09:47:35.000Z</published>
    <updated>2016-03-31T05:38:36.000Z</updated>
    <content type="html"><![CDATA[<div id="content"><br><br><span class="author_general">作者 <a href="http://www.infoq.com/cn/author/%E6%9D%8E%E5%A3%AB%E7%AA%91" target="_blank" rel="external"> 李士窑 </a></span><br><br>原文 <a href="http://www.infoq.com/cn/news/2014/11/open-source-redis-cache" target="_blank" rel="external">链接</a><br><br>由于单台<a href="http://redis.io/" target="_blank" rel="external">Redis</a>服务器的内存管理能力有限，使用过大内存的Redis又会使得 服务器的性能急剧下降，一旦服务器发生故障将会影响更大范围业务，而Redis 3.0 beta1支持的集群功能还不适合生产环境的使用。于是为了获取更好的Redis缓存性能及可用性，很多公司都研发了Redis缓存集群方案。现对<a href="https://www.netflix.com/" target="_blank" rel="external">NetFlix</a>、Twitter、国内的<a href="http://www.wandoujia.com/" target="_blank" rel="external">豌豆荚</a>在缓存集群方面的解决方案进行一个汇总，以供读者参考，具体内容如下：<a id="more"></a><br><br>## 1、NetFlix对Dynamo的开源通用实现Dynomite<br><br><a href="https://github.com/Netflix/dynomite" target="_blank" rel="external">Dynomite</a>是NetFlix对亚马逊分布式存储引擎Dynamo的一个开源通用实现，使用C/C++语言编写、以代理的方式实现的Redis缓存集群方案。Dynomite不仅能够将基于内存的Redis和Memcached打造成分布式数据库，还支持持久化的MySQL、<a href="http://www.oracle.com/technetwork/database/database-technologies/berkeleydb/overview/index.html" target="_blank" rel="external">BerkeleyDB</a>、<a href="http://code.google.com/p/leveldb/" target="_blank" rel="external">LevelDB</a>等数据库，并具有简单、高效、支持跨数据中心的数据复制等优点。Dynomite的最终目标是提供数据库存储引擎不能提供的简单、高效、跨数据中心的数据复制功能。Dynomite遵循<a href="http://www.apache.org/licenses/LICENSE-2.0.html" target="_blank" rel="external">Apache License 2.0开源协议</a>发布，更多关于Dynomite的信息请查看NetFlix技术博客对<a href="http://techblog.netflix.com/2014/11/introducing-dynomite.html" target="_blank" rel="external">Dynomite的介绍</a>。<br><br>## 2、Twitter的Redis/Memcached代理服务Twemproxy<br><br><a href="https://github.com/twitter/twemproxy" target="_blank" rel="external">Twemproxy</a>是一个使用C语言编 写、以代理的方式实现的、轻量级的Redis代理服务器，它通过引入一个代理层，将应用程序后端的多台Redis实例进行统一管理，使应用程序只需要在 Twemproxy上进行操作，而不用关心后面具体有多少个真实的Redis或Memcached实例，从而实现了基于Redis和Memcached的 集群服务。当某个节点宕掉时，Twemproxy可以自动将它从集群中剔除，而当它恢复服务时，Twemproxy也会自动连接。由于是代理，所以 Twemproxy会有微小的性能损失。根据 Redis作者的测试结果，在大多数情况下，Twemproxy的性能相当不错，同直接操作Redis相比，最多只有20%的性能损失。 Twemproxy遵循Apache License 2.0开源协议发布，更多关于Twemproxy的信息请登录其在GitHub的主页查看。<br><br>## 3、豌豆荚的 Redis 集群解决方案Codis<br><br><a href="https://github.com/wandoulabs/codis" target="_blank" rel="external">Codis</a>是豌豆荚使用Go和C语言开 发、以代理的方式实现的一个Redis分布式集群解决方案,且完全兼容Twemproxy。Twemproxy对于上一层的应用来说, 连接Codis Proxy（Redis代理服务）和连接原生的Redis服务器没有明显的区别,上一层应用能够像使用单机的 Redis一样对待。Codis底层会处理请求的转发、不停机的数据迁移等工作, 所有底层的一切处理, 对于客户端来说是透明的。总之，可以简单的认为后台连接的是一个内存无限大的Redis服务。Codis遵循<a href="http://zh.wikipedia.org/wiki/MIT%E8%A8%B1%E5%8F%AF%E8%AD%89" target="_blank" rel="external">MIT开源协议</a>发布，更多关于Codis的信息请登录其在GitHub的主页查看。<br><br>另外，还有一些未开源的解决方案，比如新浪、百度、淘宝、腾讯等的Redis集群方案。在Redis官方正式推出可用于生产环境的集群方案前，以上三种方案是非常值得考虑在生产环境使用的方案。<br><br></div>]]></content>
    <summary type="html">
    <![CDATA[<div id="content"><br><br><span class="author_general">作者 <a href="http://www.infoq.com/cn/author/%E6%9D%8E%E5%A3%AB%E7%AA%91"> 李士窑 </a></span><br><br>原文 <a href="http://www.infoq.com/cn/news/2014/11/open-source-redis-cache">链接</a><br><br>由于单台<a href="http://redis.io/">Redis</a>服务器的内存管理能力有限，使用过大内存的Redis又会使得 服务器的性能急剧下降，一旦服务器发生故障将会影响更大范围业务，而Redis 3.0 beta1支持的集群功能还不适合生产环境的使用。于是为了获取更好的Redis缓存性能及可用性，很多公司都研发了Redis缓存集群方案。现对<a href="https://www.netflix.com/">NetFlix</a>、Twitter、国内的<a href="http://www.wandoujia.com/">豌豆荚</a>在缓存集群方面的解决方案进行一个汇总，以供读者参考，具体内容如下：]]>
    
    </summary>
    
      <category term="redis" scheme="http://blog.suzf.net/tags/redis/"/>
    
      <category term="Redis" scheme="http://blog.suzf.net/categories/Redis/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Redis 常用命令总结]]></title>
    <link href="http://blog.suzf.net/2016/03/21/Redis_%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93/"/>
    <id>http://blog.suzf.net/2016/03/21/Redis_常用命令总结/</id>
    <published>2016-03-21T09:03:39.000Z</published>
    <updated>2016-03-31T05:38:36.000Z</updated>
    <content type="html"><![CDATA[<p>Redis 提供了丰富的命令（ command）对数据库和各种数据类型进行操作<br>下面对常用操作做出简单总结, 希望对大家有所帮助。<br>Redis commands – <a href="http://redis.io/commands" target="_blank" rel="external">http://redis.io/commands</a></p>
<p><strong><em> redis 默认端口 6379 </em></strong><br>redis-cli -p ${port}    # 指定端口<a id="more"></a></p>
<p><pre class="lang:default decode:true ">===== 键值 相关命令 =====<br>keys<br>返回满足给定 pattern 的所有 key</pre></p>
<ul>
<li>表示所有key<br>redis 127.0.0.1:1111&gt; keys *<br>1) “mylist8”<br>2) “key1”<br>3) “mylist2”<br>4) “mylist4”<br>5) “myhash”<br>6) “name”<br>7) “age”<br>8) “mylist6”<br>9) “name6”<br>10) “key2”<br>11) “mail”<br>12) “mylist3”<br>13) “mylist7”<br>14) “mylist”<br>15) “mylist5”</li>
</ul>
<p>表达式 name<em> 表示所有以 name 开头的key<br>redis 127.0.0.1:1111&gt; keys name</em><br>1) “name”<br>2) “name6”</p>
<p>exists<br>– 1 存在<br>– 0 不存在<br>redis 127.0.0.1:1111&gt; EXISTS suzf.net<br>(integer) 0<br>redis 127.0.0.1:1111&gt; EXISTS name<br>(integer) 1</p>
<p>del<br>删除一个key<br>– 1 删除成功<br>– 0 删除失败<br>redis 127.0.0.1:1111&gt; DEL name6<br>(integer) 1<br>redis 127.0.0.1:1111&gt; EXISTS name6<br>(integer) 0</p>
<p>expire</p>
<p>设置一个key 的 生存时间 &lt; 单位: s/秒 &gt;<br>redis 127.0.0.1:1111&gt; help EXPIRE</p>
<p>  EXPIRE key seconds<br>  summary: Set a key’s time to live in seconds<br>  since: 0.09<br>  group: generic</p>
<p>redis 127.0.0.1:1111&gt; set mykey “hello world”<br>OK<br>redis 127.0.0.1:1111&gt; EXPIRE mykey 10<br>(integer) 1<br>redis 127.0.0.1:1111&gt; TTL mykey<br>(integer) 4<br>redis 127.0.0.1:1111&gt; TTL mykey<br>(integer) 3<br>redis 127.0.0.1:1111&gt; TTL mykey<br>(integer) -2</p>
<p>move<br>将当前数据库中的 key 转移到其它数据库中<br>redis 127.0.0.1:1111&gt; SELECT 0<br>OK<br>redis 127.0.0.1:1111&gt; set name athena<br>OK<br>redis 127.0.0.1:1111&gt; get name<br>“athena”<br>redis 127.0.0.1:1111&gt; move name 1<br>(integer) 1<br>redis 127.0.0.1:1111&gt; get name<br>(nil)<br>redis 127.0.0.1:1111&gt; SELECT 1<br>OK<br>redis 127.0.0.1:1111[1]&gt; get name<br>“athena”<br>redis 127.0.0.1:1111[1]&gt;<br>在本例中,我先显式的选择了数据库 0,然后在这个库中设置一个 key,接下来我们将这个<br>key 从数据库 0 移到数据库 1,之后我们确认在数据库 0 中无此 key 了, 但在数据库 1 中存在<br>这个 key,说明我们转移成功了</p>
<p>persist<br>移除给定 key 的过期时间<br>redis 127.0.0.1:1111[1]&gt; EXPIRE name 666<br>(integer) 1<br>redis 127.0.0.1:1111[1]&gt; TTL name<br>(integer) 660<br>redis 127.0.0.1:1111[1]&gt; PERSIST name<br>(integer) 1<br>redis 127.0.0.1:1111[1]&gt; TTL name<br>(integer) -1</p>
<p>randomkey<br>随机返回 key 空间的一个 key<br>redis 127.0.0.1:1111&gt; RANDOMKEY<br>“myhash”<br>redis 127.0.0.1:1111&gt; RANDOMKEY<br>“mail”<br>redis 127.0.0.1:1111&gt; RANDOMKEY<br>“key2”<br>redis 127.0.0.1:1111&gt; RANDOMKEY<br>“mylist5”</p>
<p>rename<br>rename key<br>redis 127.0.0.1:1111&gt; SELECT 1<br>OK<br>redis 127.0.0.1:1111[1]&gt; keys <em><br>1) “name”<br>redis 127.0.0.1:1111[1]&gt; RENAME name name_new<br>OK<br>redis 127.0.0.1:1111[1]&gt; keys </em><br>1) “name_new”</p>
<p>type<br>返回值的类型<br>redis 127.0.0.1:1111&gt; TYPE mylist<br>list<br>redis 127.0.0.1:1111&gt; TYPE addr<br>none<br>redis 127.0.0.1:1111&gt; TYPE mail<br>string<br>redis 127.0.0.1:1111&gt; TYPE myhash<br>hash</p>
<p>===== 服务器相关命令 =====</p>
<p>Ping 测试连接 时候存活<br>– 正常<br>  redis 127.0.0.1:1111&gt; ping<br>  PONG</p>
<p>– 错误</p>
<p>  #redis-cli  -p 2222 ping<br>  Could not connect to Redis at 127.0.0.1:2222: Connection refused</p>
<p>Echo<br>在命令行中打印内容<br>redis 127.0.0.1:1111&gt; ECHO “Hello Kitty”<br>“Hello Kitty”</p>
<p>Select<br>选择数据库. Redis 数据库编号从 0~15,我们可以选择任意一个数据库来进行数据的存取.<br>redis 127.0.0.1:1111&gt; help select </p>
<p>  SELECT index<br>  summary: Change the selected database for the current connection<br>  since: 0.07<br>  group: connection<br>redis 127.0.0.1:1111&gt; SELECT 9<br>OK<br>redis 127.0.0.1:1111[9]&gt; SELECT 16<br>(error) ERR invalid DB index</p>
<p>Quit<br>退出连接<br>redis 127.0.0.1:1111[16]&gt; QUIT<br>^_^[16:15:32][root@master01 ~]#</p>
<p>Dbsize<br>返回当前数据库中 key 的条目</p>
<p>redis 127.0.0.1:1111&gt; DBSIZE<br>(integer) 12<br>redis 127.0.0.1:1111&gt; keys *<br> 1) “mylist8”<br> 2) “key1”<br> 3) “mylist2”<br> 4) “mylist4”<br> 5) “myhash”<br> 6) “mylist6”<br> 7) “key2”<br> 8) “mail”<br> 9) “mylist3”<br>10) “mylist7”<br>11) “mylist”<br>12) “mylist5”</p>
<p>当前数据库中有 12 个 key</p>
<p>Info<br>获取服务器信息和统计<br>redis 127.0.0.1:1111&gt; INFO</p>
<h1 id="Server"><a href="#Server" class="headerlink" title="Server"></a>Server</h1><p>redis_version:3.0.7<br>redis_git_sha1:00000000<br>…<br>…</p>
<h1 id="Cluster"><a href="#Cluster" class="headerlink" title="Cluster"></a>Cluster</h1><p>cluster_enabled:0</p>
<h1 id="Keyspace"><a href="#Keyspace" class="headerlink" title="Keyspace"></a>Keyspace</h1><p>db0:keys=12,expires=0,avg_ttl=0<br>db1:keys=1,expires=0,avg_ttl=0</p>
<p>Monitor<br>实时转储接到的请求<br>redis 127.0.0.1:1111&gt; MONITOR<br>OK<br>1458548482.249883 [0 192.168.9.70:44260] “PING”<br>1458548482.485299 [0 192.168.9.10:49031] “PING”<br>1458548483.309169 [0 192.168.9.70:44260] “PING”<br>1458548483.370627 [0 192.168.9.70:44260] “PUBLISH” “<strong>sentinel</strong>:hello” “192.168.9.70,6666,b5cd420208ca00f50c45b95587205235b6b2b675,9,master-1111,192.168.9.10,1111,9”<br>1458548483.559755 [0 192.168.9.10:49031] “PING”<br>1458548484.120162 [0 192.168.9.10:49031] “PUBLISH” “<strong>sentinel</strong>:hello” “192.168.9.10,6666,555e6555dc34bd819f8343005cd76af147ebec63,9,master-1111,192.168.9.10,1111,9”<br>1458548484.384204 [0 192.168.9.70:44260] “PING”<br>1458548484.567478 [0 192.168.9.10:49031] “PING”<br>1458548485.403481 [0 127.0.0.1:51102] “keys” “*”</p>
<p>从上面可以看出 服务器收到了 “keys *” “PUBLISH” 和 “PING” 请求</p>
<p>Conf get<br>获取当前服务器配置<br>redis 127.0.0.1:1111&gt; CONFIG GET dir<br>1) “dir”<br>2) “/var/lib/redis/1111”<br>redis 127.0.0.1:1111&gt; CONFIG GET timeout<br>1) “timeout”<br>2) “0”<br>redis 127.0.0.1:1111&gt; CONFIG GET slaveof<br>1) “slaveof”<br>2) “”<br>redis 127.0.0.1:1111&gt; CONFIG GET <em><br>执行” config get </em>”即可将全部的值都显示出来</p>
<p>Conf set<br>设置临时环境变量, 重启后失效<br>config set $variable $value<br>E.g.<br>redis 127.0.0.1:1111&gt; config set repl-timeout 300<br>OK</p>
<p>Flushdb<br>删除当前选择数据库中的所有 key<br>redis 127.0.0.1:1111&gt; DBSIZE<br>(integer) 12<br>redis 127.0.0.1:1111&gt; FLUSHDB<br>OK<br>redis 127.0.0.1:1111&gt; DBSIZE<br>(integer) 0</p>
<p>Flushall<br>删除所有数据库中的所有 key<br>redis 127.0.0.1:1111&gt; SELECT 1<br>OK<br>redis 127.0.0.1:1111[1]&gt; DBSIZE<br>(integer) 1<br>redis 127.0.0.1:1111[1]&gt; SELECT 0<br>OK<br>redis 127.0.0.1:1111&gt; FLUSHALL<br>OK<br>redis 127.0.0.1:1111&gt; SELECT 1<br>OK<br>redis 127.0.0.1:1111[1]&gt; DBSIZE<br>(integer) 0</p>
<p>client list<br>获取客户连接列表<br>redis 127.0.0.1:1111&gt; client list<br>id=100 addr=127.0.0.1:51251 fd=13 name= age=1315 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=32768 obl=0 oll=0 omem=0 events=r cmd=client<br>id=101 addr=127.0.0.1:51897 fd=14 name= age=33 idle=33 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=NULL</p>
<p>client kill<br>终止某个客户端连接<br>redis 127.0.0.1:1111&gt; client kill 127.0.0.1:51897<br>OK</p>
<p>save<br>立即保存数据到硬盘<br>redis 127.0.0.1:1111&gt; help Save</p>
<p>  SAVE -<br>  summary: Synchronously save the dataset to disk<br>  since: 0.07<br>  group: server</p>
<p>redis 127.0.0.1:1111&gt; save<br>OK</p>
<p>bgsave<br>异步保存数据到硬盘</p>
<p>lastsave<br>获取上次成功保存到硬盘的unix时间戳<br>redis 127.0.0.1:1111&gt; lastsave<br>(integer) 1458550236</p>
<p>slowlog len<br>查询慢查询日志条数<br>redis 127.0.0.1:1111&gt; slowlog len<br>(integer) 5</p>
<p>slowlog get<br>返回所有的慢查询日志,最大值取决于slowlog-max-len配置<br>redis 127.0.0.1:1111&gt; slowlog get<br>1) 1) (integer) 4<br>   2) (integer) 1458550236<br>   3) (integer) 10857<br>   4) 1) “save”<br>2) 1) (integer) 3<br>   2) (integer) 1458550230<br>   3) (integer) 10731<br>   4) 1) “save”<br>3) 1) (integer) 2<br>   2) (integer) 1458548969<br>   3) (integer) 10589<br>   4) 1) “FLUSHALL”<br>4) 1) (integer) 1<br>   2) (integer) 1458539756<br>   3) (integer) 26752<br>   4) 1) “hset”<br>      2) “myhash”<br>      3) “field1”<br>      4) “hello”<br>5) 1) (integer) 0<br>   2) (integer) 1458270728<br>   3) (integer) 21491<br>   4) 1) “SETNX”<br>      2) “858C783EA7F646021E63E5A6147B7B58”<br>      3) “null”</p>
<p>slowlog get 2<br>打印两条慢查询日志<br>redis 127.0.0.1:1111&gt; slowlog get 2<br>1) 1) (integer) 4<br>   2) (integer) 1458550236<br>   3) (integer) 10857<br>   4) 1) “save”<br>2) 1) (integer) 3<br>   2) (integer) 1458550230<br>   3) (integer) 10731<br>   4) 1) “save”</p>
<p>slowlog reset<br>清空慢查询日志信息<br>redis 127.0.0.1:1111&gt; slowlog reset<br>OK<br>redis 127.0.0.1:1111&gt; slowlog get<br>(empty list or set)<br>&nbsp;</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>Redis 提供了丰富的命令（ command）对数据库和各种数据类型进行操作<br>下面对常用操作做出简单总结, 希望对大家有所帮助。<br>Redis commands – <a href="http://redis.io/commands">http://redis.io/commands</a></p>
<p><strong><em> redis 默认端口 6379 </em></strong><br>redis-cli -p ${port}    # 指定端口]]>
    
    </summary>
    
      <category term="redis" scheme="http://blog.suzf.net/tags/redis/"/>
    
      <category term="Redis" scheme="http://blog.suzf.net/categories/Redis/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Nginx+Redis+Tomcat实现session共享的集群]]></title>
    <link href="http://blog.suzf.net/2016/03/18/Nginx+Redis+Tomcat%E5%AE%9E%E7%8E%B0session%E5%85%B1%E4%BA%AB%E7%9A%84%E9%9B%86%E7%BE%A4/"/>
    <id>http://blog.suzf.net/2016/03/18/Nginx+Redis+Tomcat实现session共享的集群/</id>
    <published>2016-03-18T06:56:32.000Z</published>
    <updated>2016-03-31T05:38:36.000Z</updated>
    <content type="html"><![CDATA[<p>Nginx 作为目前最流行的开源反向代理HTTP Server，用于实现资源缓存、web server负载均衡等功能，由于其轻量级、高性能、高可靠等特点在互联网项目中有着非常普遍的应用，相关概念网上有丰富的介绍。分布式web server集群部署后需要实现session共享，针对 tomcat 服务器的实现方案多种多样，比如 tomcat cluster session 广播、nginx IP hash策略、nginx sticky module等方案，本文主要介绍了使用 redis 服务器进行 session 统一存储管理的共享方案。</p>
<p>使 用Nginx作为Tomcat的负载平衡器，Tomcat的会话Session数据存储在Redis，能够实现0当机的7×24运营效果。因为将会话存储 在Redis中，因此Nginx就不必配置成stick粘粘某个Tomcat方式，这样才能真正实现后台多个Tomcat负载平衡，用户请求能够发往任何 一个tomcat主机，当我们需要部署新应用代码时，只要停止任何一台tomcat，所有当前在线用户都会导向到运行中的tomcat实例，因为会话数据 被序列化到Redis，在线用户不会受到影响，一旦停掉的tomcat实例上线，另外其他重复部署过程。<a id="more"></a></p>
<p><a href="http://suzf.net/wp-content/uploads/2016/03/frame-20160121153429_41249.png" target="_blank" rel="external"><img src="http://suzf.net/wp-content/uploads/2016/03/frame-20160121153429_41249.png" alt="frame-20160121153429_41249"></a><br><strong>实验环境</strong></p>
<p><pre class="lang:default decode:true">      IP            Roles               port</pre></p>
<p>node1 192.168.9.10  nginx,redis,tomcat  80,1111,8080</p>
<p>node2 192.168.9.70  tomcat              8080<br><strong>软件工具包</strong><br>apache-tomcat-7.0.68.tar<br>redis-3.0.7.tar<br>jdk-7u79-linux-x64.rpm<br>nginx-1.0.15-12.el6.x86_64.rpm</p>
<p><strong>tomcat需要的jar包</strong><br>commons-logging-1.1.3.jar<br>commons-pool2-2.2.jar<br>jedis-2.5.2.jar<br>tomcat-juli.jar<br>tomcat-redis-session-manage-tomcat7.jar<br><strong>安装redis</strong></p>
<ol>
<li>Redis 安装<br>== Redis 源码安装<br>— 参照源码 README<br>— 默认端口 6379</li>
</ol>
<p><strong><em> 安装redis之前先要确认系统已经安装了GCC和libc库 </em></strong></p>
<p><pre class="lang:default decode:true ">wget <a href="http://download.redis.io/releases/redis-3.0.7.tar.gz" target="_blank" rel="external">http://download.redis.io/releases/redis-3.0.7.tar.gz</a><br>tar xf redis-3.0.7.tar.gz<br>cd redis-3.0.7<br>make</pre></p>
<h1 id="make_test"><a href="#make_test" class="headerlink" title="make test"></a>make test</h1><p>make PREFIX=/usr/local/redis install<br>&nbsp;</p>
<p>== 可执行命令</p>
<p><pre class="lang:default decode:true ">redis-server    Redis服务系统<br>redis-cli       Redis一个客户端管理工具<br>redis-benchmark 用来检测redis性能<br>redis-check-aof &amp; redis-check-dump 用来处理损坏的数据文件<br>redis-sentinel -&gt; redis-server   &lt; soft link &gt;</pre></p>
<p>cd utils<br>./install_server.sh</p>
<p>^_^[15:50:34][root@master01 utils]#bash install_server.sh<br>Welcome to the redis service installer<br>This script will help you easily set up a running redis server</p>
<p>Please select the redis port for this instance: [6379] 1111<br>Please select the redis config file name [/etc/redis/1111.conf]<br>Selected default – /etc/redis/1111.conf<br>Please select the redis log file name [/var/log/redis_1111.log]<br>Selected default – /var/log/redis_1111.log<br>Please select the data directory for this instance [/var/lib/redis/1111]<br>Selected default – /var/lib/redis/1111<br>Please select the redis executable path [/usr/sbin/redis-server] /usr/local/redis/bin/redis-server<br>Selected config:<br>Port           : 1111<br>Config file    : /etc/redis/1111.conf<br>Log file       : /var/log/redis_1111.log<br>Data dir       : /var/lib/redis/1111<br>Executable     : /usr/local/redis/bin/redis-server<br>Cli Executable : /usr/bin/redis-cli<br>Is this ok? Then press ENTER to go on or Ctrl-C to abort.<br>Copied /tmp/1111.conf =&gt; /etc/init.d/redis_1111<br>Installing service…<br>Successfully added to chkconfig!<br>Successfully added to runlevels 345!<br>Starting Redis server…<br>Installation successful!<br>&nbsp;</p>
<p>Redis 系统配置</p>
<p><pre class="lang:default decode:true">echo “vm.overcommit_memory = 1” &gt;&gt; /etc/sysctl.conf<br>sysctl vm.overcommit_memory=1<br>echo 511 &gt; /proc/sys/net/core/somaxconn</pre><br>启动服务</p>
<p>/etc/init.d/redis_1111 start</p>
<p>配置文件可以用默认的配置，从服务器上配置文文件打开slavefo 加上主服务器的ip和端口，还有其他的参数如日志和dump.rdb保存路径可以适当修改</p>
<p>FAQ:</p>
<p>make时如果有类似如下报错：<br>Selecting a non-default memory allocator when building Redis is done by setting<br>the <code>[MALLOC](https://www.baidu.com/s?wd=MALLOC&amp;amp;tn=44039180_cpr&amp;amp;fenlei=mv6quAkxTZn0IZRqIHckPjm4nH00T1YLPvnvnHIWuHTYnvPWP1mL0ZwV5Hcvrjm3rH6sPfKWUMw85HfYnjn4nH6sgvPsT6K1TL0qnfK1TL0z5HD0IgF_5y9YIZ0lQzqlpA-bmyt8mh7GuZR8mvqVQL7dugPYpyq8Q1csP1RvnjcdPHnYP1nzPjDzPW6)</code> environment variable. Redis is compiled and linked against libc<br><a href="https://www.baidu.com/s?wd=malloc&amp;tn=44039180_cpr&amp;fenlei=mv6quAkxTZn0IZRqIHckPjm4nH00T1YLPvnvnHIWuHTYnvPWP1mL0ZwV5Hcvrjm3rH6sPfKWUMw85HfYnjn4nH6sgvPsT6K1TL0qnfK1TL0z5HD0IgF_5y9YIZ0lQzqlpA-bmyt8mh7GuZR8mvqVQL7dugPYpyq8Q1csP1RvnjcdPHnYP1nzPjDzPW6" target="_blank" rel="external">malloc</a> by default, with the exception of je<a href="https://www.baidu.com/s?wd=malloc&amp;tn=44039180_cpr&amp;fenlei=mv6quAkxTZn0IZRqIHckPjm4nH00T1YLPvnvnHIWuHTYnvPWP1mL0ZwV5Hcvrjm3rH6sPfKWUMw85HfYnjn4nH6sgvPsT6K1TL0qnfK1TL0z5HD0IgF_5y9YIZ0lQzqlpA-bmyt8mh7GuZR8mvqVQL7dugPYpyq8Q1csP1RvnjcdPHnYP1nzPjDzPW6" target="_blank" rel="external">malloc</a> being the default on Linux<br>systems. This default was picked because jemalloc has proven to have fewer<br>fragmentation problems than libc malloc.</p>
<p>make MALLOC=libc<br><strong>安装 JDK and Tomcat</strong></p>
<p><pre class="lang:default decode:true"># wget -c –header “Cookie: oraclelicense=accept-securebackup-cookie” <code>curl -s http://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html | awk -F&#39;&quot;&#39; &#39;/jdk\-7.*\-linux\-x64.rpm/{print $12;exit}&#39;</code></pre></p>
<h1 id="rpm_-ivh_jdk-7u79-linux-x64-rpm"><a href="#rpm_-ivh_jdk-7u79-linux-x64-rpm" class="headerlink" title="rpm -ivh jdk-7u79-linux-x64.rpm"></a>rpm -ivh jdk-7u79-linux-x64.rpm</h1><h1 id="cat__26gt_3B_/etc/profile-d/java-sh__26lt_3B_26lt_3B_EOF"><a href="#cat__26gt_3B_/etc/profile-d/java-sh__26lt_3B_26lt_3B_EOF" class="headerlink" title="cat &gt; /etc/profile.d/java.sh &lt;&lt; EOF"></a>cat &gt; /etc/profile.d/java.sh &lt;&lt; EOF</h1><p>JAVA_HOME=/usr/java/latest</p>
<p>PATH=\$JAVA_HOME/bin:\$PATH</p>
<p>export JAVA_HOME PATH</p>
<p>EOF</p>
<h1 id="wget_-c_curl_-s__26quot_3Bhttps_3A//tomcat-apache-org/download-70-cgi_26quot_3B__7C_awk_-F_26_2339_3B_26quot_3B_26_2339_3B__26_2339_3B/apache_5C-tomcat_5C-7-*-tar-gz/_7Bprint__242_3Bexit_7D_26_2339_3B"><a href="#wget_-c_curl_-s__26quot_3Bhttps_3A//tomcat-apache-org/download-70-cgi_26quot_3B__7C_awk_-F_26_2339_3B_26quot_3B_26_2339_3B__26_2339_3B/apache_5C-tomcat_5C-7-*-tar-gz/_7Bprint__242_3Bexit_7D_26_2339_3B" class="headerlink" title="wget -c curl -s &quot;https://tomcat.apache.org/download-70.cgi&quot; | awk -F&#39;&quot;&#39; &#39;/apache\-tomcat\-7.*.tar.gz/{print $2;exit}&#39;"></a>wget -c <code>curl -s &quot;https://tomcat.apache.org/download-70.cgi&quot; | awk -F&#39;&quot;&#39; &#39;/apache\-tomcat\-7.*.tar.gz/{print $2;exit}&#39;</code></h1><h1 id="tar_xf_apache-tomcat-7-*-tar-gz_-C_/usr/local/"><a href="#tar_xf_apache-tomcat-7-*-tar-gz_-C_/usr/local/" class="headerlink" title="tar xf apache-tomcat-7.*.tar.gz -C /usr/local/"></a>tar xf apache-tomcat-7.*.tar.gz -C /usr/local/</h1><h1 id="ln_-sv_/usr/local/apache-tomcat-7-*_/usr/local/tomcat"><a href="#ln_-sv_/usr/local/apache-tomcat-7-*_/usr/local/tomcat" class="headerlink" title="ln -sv /usr/local/apache-tomcat-7.* /usr/local/tomcat"></a>ln -sv /usr/local/apache-tomcat-7.* /usr/local/tomcat</h1><h1 id="cat__26gt_3B_/etc/profile-d/tomcat-sh__26lt_3B_26lt_3B_EOF"><a href="#cat__26gt_3B_/etc/profile-d/tomcat-sh__26lt_3B_26lt_3B_EOF" class="headerlink" title="cat &gt; /etc/profile.d/tomcat.sh &lt;&lt; EOF"></a>cat &gt; /etc/profile.d/tomcat.sh &lt;&lt; EOF</h1><p>export CATALINA_HOME=/usr/local/tomcat</p>
<p>export PATH=\$CATALINA_HOME/bin:\$PATH</p>
<p>EOF</p>
<h1 id="source_/etc/profile-d/java-sh"><a href="#source_/etc/profile-d/java-sh" class="headerlink" title="source /etc/profile.d/java.sh"></a>source /etc/profile.d/java.sh</h1><h1 id="source_/etc/profile-d/tomcat-sh"><a href="#source_/etc/profile-d/tomcat-sh" class="headerlink" title="source /etc/profile.d/tomcat.sh"></a>source /etc/profile.d/tomcat.sh</h1><h1 id="catalina-sh_version"><a href="#catalina-sh_version" class="headerlink" title="catalina.sh version"></a>catalina.sh version</h1><p>Using CATALINA_BASE:   /usr/local/tomcat</p>
<p>Using CATALINA_HOME:   /usr/local/tomcat</p>
<p>Using CATALINA_TMPDIR: /usr/local/tomcat/temp</p>
<p>Using JRE_HOME:        /usr/java/latest</p>
<p>Using CLASSPATH:       /usr/local/tomcat/bin/bootstrap.jar:/usr/local/tomcat/bin/tomcat-juli.jar</p>
<p>Server version: Apache Tomcat/7.0.68</p>
<p>Server built:   Feb 8 2016 20:25:54 UTC</p>
<p>Server number:  7.0.68.0</p>
<p>OS Name:        Linux</p>
<p>OS Version:     2.6.32-573.8.1.el6.x86_64</p>
<p>Architecture:   amd64</p>
<p>JVM Version:    1.7.0_79-b15</p>
<p>JVM Vendor:     Oracle Corporation<br>&nbsp;</p>
<p><strong><em> 将jar包全都拷进tomcat lib目录下 </em></strong></p>
<p><pre class="lang:default decode:true ">^<em>^[14:43:41][root@master01 lib]#pwd<br>/usr/local/tomcat/lib<br>^</em>^[14:44:47][root@master01 lib]#ls -lth | tail -5<br>-rw-r–r– 1 root root  61K Nov 13 15:18 commons-logging-1.1.3.jar<br>-rw-r–r– 1 root root 106K Nov 13 15:18 commons-pool2-2.2.jar<br>-rw-r–r– 1 root root 308K Nov 13 15:18 jedis-2.5.2.jar<br>-rw-r–r– 1 root root  74K Nov 13 15:18 tomcat-juli.jar<br>-rw-r–r– 1 root root  20K Nov 13 15:18 tomcat-redis-session-manage-tomcat7.jar</pre><br>修改conf目录下context.xml配置文件，session共享保存设置<br>在&lt;Context&gt;标签中</p>
<p><pre class="lang:default decode:true ">&lt;Valve className=”com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve” /&gt;<br>&lt;Manager className=”com.orangefunction.tomcat.redissessions.RedisSessionManager”<br>host=”192.168.9.10”<br>port=”1111”<br>database=”0”<br>maxInactiveInterval=”60”/&gt;</pre><br>添加测试页</p>
<p><pre class="lang:default decode:true ">vim webapps/ROOT/test.jsp</pre></p>
<p>&lt;%@ page language=”java” %&gt;</p>
<p>&lt;html&gt;</p>
<p>  &lt;head&gt;&lt;title&gt;TomcatI&lt;/title&gt;&lt;/head&gt;</p>
<p>  &lt;body&gt;</p>
<pre><code>&amp;lt;h1&amp;gt;&amp;lt;font color=&quot;green&quot;&amp;gt;TomcatI.suzf.net&amp;lt;/font&amp;gt;&amp;lt;/h1&amp;gt;

&amp;lt;table align=&quot;centre&quot; border=&quot;1&quot;&amp;gt;

  &amp;lt;tr&amp;gt;

    &amp;lt;td&amp;gt;Session ID&amp;lt;/td&amp;gt;

&amp;lt;% session.setAttribute(&quot;tomcat.suzf.net&quot;,&quot;tomcat.suzf.net&quot;); %&amp;gt;

    &amp;lt;td&amp;gt;&amp;lt;%= session.getId() %&amp;gt;&amp;lt;/td&amp;gt;

  &amp;lt;/tr&amp;gt;

  &amp;lt;tr&amp;gt;

    &amp;lt;td&amp;gt;Created on&amp;lt;/td&amp;gt;

    &amp;lt;td&amp;gt;&amp;lt;%= session.getCreationTime() %&amp;gt;&amp;lt;/td&amp;gt;

 &amp;lt;/tr&amp;gt;

&amp;lt;/table&amp;gt;
</code></pre><p>  &lt;/body&gt;</p>
<p>&lt;/html&gt;<br>将tomcat目录拷贝到其他tomcat服务器<br>将测试页代码 Titile 和 color 修改下，以作区分。</p>
<p><strong>Nginx安装</strong></p>
<p><pre class="lang:default decode:true ">yum install nginx -y </pre></p>
<p>Nginx 相关配置</p>
<h1 id="grep_-v__u201C_5E_24_7C_5E-*_23_u201D_/etc/nginx/nginx-conf"><a href="#grep_-v__u201C_5E_24_7C_5E-*_23_u201D_/etc/nginx/nginx-conf" class="headerlink" title="grep -v “^$|^.*#”  /etc/nginx/nginx.conf"></a>grep -v “^$|^.*#”  /etc/nginx/nginx.conf</h1><p>user              nginx;<br>worker_processes  1;<br>error_log  /var/log/nginx/error.log;<br>pid        /var/run/nginx.pid;</p>
<p>events {</p>
<pre><code>worker_connections  1024;
</code></pre><p>}</p>
<p>http {</p>
<pre><code>include       /etc/nginx/mime.types;
default_type  application/octet-stream;
log_format  main  &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos;

                  &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos;

                  &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;;

upstream suzf-net-tomcat {

   server 192.168.9.10:8080;
   server 192.168.9.70:8080;

}

server {

    listen 80;
    server_name tomcat.suzf.net;

    location / {

         index   index.jsp index.html index.htm;
         proxy_pass http://suzf-net-tomcat;
         proxy_redirect off;
         proxy_set_header Host $host;
         proxy_set_header X-Real-IP $remote_addr;
         proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

    }

}

access_log  /var/log/nginx/access.log  main;
sendfile        on;
server_tokens   off;
keepalive_timeout  65;

include /etc/nginx/conf.d/*.conf;
</code></pre><p>}<br>&nbsp;</p>
<p>检测nginx 配置文件 &amp; 重载配置文件</p>
<p><pre class="lang:default decode:true">#/etc/init.d/nginx configtest </pre></p>
<p>nginx: the configuration file /etc/nginx/nginx.conf syntax is ok</p>
<p>nginx: configuration file /etc/nginx/nginx.conf test is successful</p>
<p>#/etc/init.d/nginx  reload</p>
<p>Reloading nginx:                                           [  OK  ]<br><strong>浏览器验证：</strong></p>
<p><a href="http://suzf.net/wp-content/uploads/2016/03/tom1-20160318130409.png" target="_blank" rel="external"><img src="http://suzf.net/wp-content/uploads/2016/03/tom1-20160318130409.png" alt="tom1-20160318130409"></a></p>
<p><a href="http://suzf.net/wp-content/uploads/2016/03/tom2-20160318130451.png" target="_blank" rel="external"><img src="http://suzf.net/wp-content/uploads/2016/03/tom2-20160318130451.png" alt="tom2-20160318130451"></a></p>
<p>&nbsp;</p>
<p><strong> 查看Redis 数据</strong></p>
<p><a href="http://suzf.net/wp-content/uploads/2016/03/redis-20160318130539.png" target="_blank" rel="external"><img src="http://suzf.net/wp-content/uploads/2016/03/redis-20160318130539.png" alt="redis-20160318130539"></a></p>
<p>&nbsp;</p>
<p><strong>通过 tomcat-redis-session-manager  自动获取tomcat 所需 jar 包  </strong></p>
<p><strong>*</strong> 未测 <strong>* </strong></p>
<p>tomcat-redis-session-manager 是一个用来将 Tomcat 的 Session 数据存储在 Redis 库中的项目。</p>
<p>官网：<a href="https://github.com/jcoleman/tomcat-redis-session-manager" target="_blank" rel="external">https://github.com/jcoleman/tomcat-redis-session-manager</a></p>
<p><strong><em> 由于源码构建基于 gradle，请先配置 gradle 环境。</em></strong></p>
<p><pre class="lang:default decode:true">wget <a href="https://downloads.gradle.org/distributions/gradle-2.10-all.zip" target="_blank" rel="external">https://downloads.gradle.org/distributions/gradle-2.10-all.zip</a></pre></p>
<p>unzip -q gradle-2.10-all.zip -d /usr/local/</p>
<p>ln -sv /usr/local/gradle-2.10 /usr/local/gradle</p>
<p>#echo “export PATH=/usr/local/gradle/bin:\$PATH” &gt; /etc/profile.d/gradle2.10.sh</p>
<p>#source /etc/profile.d/gradle2.10.sh<br>&nbsp;</p>
<p>安装 tomcat-redis-session-manager</p>
<p><pre class="lang:default decode:true">git clone <a href="https://github.com/jcoleman/tomcat-redis-session-manager.git" target="_blank" rel="external">https://github.com/jcoleman/tomcat-redis-session-manager.git</a></pre></p>
<p>cd tomcat-redis-session-manager/</p>
<p>mv build.gradle build.gradle.bak</p>
<p>vim build.gradle</p>
<p>#diff -ruN build.gradle*</p>
<p>— build.gradle 2016-01-04 07:07:59.000000000 +0800</p>
<p>+++ build.gradle.old 2016-03-18 10:48:15.620704187 +0800</p>
<p>@@ -44,13 +44,8 @@</p>
<p>   archives sourcesJar</p>
<p> }</p>
<p>-//signing {</p>
<p>-//  sign configurations.archives</p>
<p>-//}</p>
<p>-</p>
<p>-task copyJars(type: Copy) {</p>
<ul>
<li><p>from configurations.runtime</p>
</li>
<li><p>into ‘dist’  </p>
</li>
</ul>
<p>+signing {</p>
<ul>
<li><p>sign configurations.archives</p>
<p>}</p>
<p>uploadArchives {</p>
</li>
</ul>
<p>@@ -58,9 +53,9 @@</p>
<pre><code>mavenDeployer {

  beforeDeployment { MavenDeployment deployment -&amp;gt; signing.signPom(deployment) }
</code></pre><ul>
<li><p>//repository(url: “<a href="https://oss.sonatype.org/service/local/staging/deploy/maven2/" target="_blank" rel="external">https://oss.sonatype.org/service/local/staging/deploy/maven2/</a>“) {</p>
</li>
<li><p>//  authentication(userName: sonatypeUsername, password: sonatypePassword)</p>
</li>
<li><p>//}</p>
</li>
</ul>
<ul>
<li><p>repository(url: “<a href="https://oss.sonatype.org/service/local/staging/deploy/maven2/" target="_blank" rel="external">https://oss.sonatype.org/service/local/staging/deploy/maven2/</a>“) {</p>
</li>
<li><p>authentication(userName: sonatypeUsername, password: sonatypePassword)</p>
</li>
<li><p>}</p>
<p>//repository(url: “<a href="https://oss.sonatype.org/content/repositories/snapshots" target="_blank" rel="external">https://oss.sonatype.org/content/repositories/snapshots</a>“) {</p>
<p>//  authentication(userName: sonatypeUsername, password: sonatypePassword)</p>
<p>//}</p>
</li>
</ul>
<p>@@ -101,4 +96,4 @@</p>
<pre><code>  }

}
</code></pre><p>   }</p>
<p>-}</p>
<p>\ No newline at end of file</p>
<p>+}</p>
<h1 id="gradle_build_-x_test_copyJars"><a href="#gradle_build_-x_test_copyJars" class="headerlink" title="gradle build -x test copyJars"></a>gradle build -x test copyJars</h1><h1 id="mkdir_/tmp/jar"><a href="#mkdir_/tmp/jar" class="headerlink" title="mkdir /tmp/jar"></a>mkdir /tmp/jar</h1><h1 id="cp_-a_build/libs/-jar_/tmp/jar/__26amp_3B_26amp_3B_cp_-a_dist/-jar_/tmp/jar/"><a href="#cp_-a_build/libs/-jar_/tmp/jar/__26amp_3B_26amp_3B_cp_-a_dist/-jar_/tmp/jar/" class="headerlink" title="cp -a build/libs/.jar /tmp/jar/ &amp;&amp; cp -a dist/.jar /tmp/jar/"></a>cp -a build/libs/<em>.jar /tmp/jar/ &amp;&amp; cp -a dist/</em>.jar /tmp/jar/</h1><p>最后将 jar 包 分发到tomcat 项目中</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>Nginx 作为目前最流行的开源反向代理HTTP Server，用于实现资源缓存、web server负载均衡等功能，由于其轻量级、高性能、高可靠等特点在互联网项目中有着非常普遍的应用，相关概念网上有丰富的介绍。分布式web server集群部署后需要实现session共享，针对 tomcat 服务器的实现方案多种多样，比如 tomcat cluster session 广播、nginx IP hash策略、nginx sticky module等方案，本文主要介绍了使用 redis 服务器进行 session 统一存储管理的共享方案。</p>
<p>使 用Nginx作为Tomcat的负载平衡器，Tomcat的会话Session数据存储在Redis，能够实现0当机的7×24运营效果。因为将会话存储 在Redis中，因此Nginx就不必配置成stick粘粘某个Tomcat方式，这样才能真正实现后台多个Tomcat负载平衡，用户请求能够发往任何 一个tomcat主机，当我们需要部署新应用代码时，只要停止任何一台tomcat，所有当前在线用户都会导向到运行中的tomcat实例，因为会话数据 被序列化到Redis，在线用户不会受到影响，一旦停掉的tomcat实例上线，另外其他重复部署过程。]]>
    
    </summary>
    
      <category term="Nginx" scheme="http://blog.suzf.net/tags/Nginx/"/>
    
      <category term="redis" scheme="http://blog.suzf.net/tags/redis/"/>
    
      <category term="tomcat" scheme="http://blog.suzf.net/tags/tomcat/"/>
    
      <category term="Nginx" scheme="http://blog.suzf.net/categories/Nginx/"/>
    
      <category term="Redis" scheme="http://blog.suzf.net/categories/Nginx/Redis/"/>
    
      <category term="Tomcat" scheme="http://blog.suzf.net/categories/Nginx/Redis/Tomcat/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Redis Sentinel Test]]></title>
    <link href="http://blog.suzf.net/2016/03/17/redis-sentinel-test/"/>
    <id>http://blog.suzf.net/2016/03/17/redis-sentinel-test/</id>
    <published>2016-03-17T10:00:00.000Z</published>
    <updated>2016-03-31T05:38:36.000Z</updated>
    <content type="html"><![CDATA[<p>Redis Sentinel 是一套用于管理Redis实例的分布式系统,主要完成3项任务:</p>
<p>1. Monitoring:持续监控Redis master或slave实例的运行情况是否符合预期<br>2. Notification:若被监控的Redis实例运行异常,sentinel会通过API通知外界（人或程序）<br>3. Automation failover:若master实例故障,sentinel会重新选主并启动自动故障切换:选择slave-priority最小的那个slave实例并将其提升为master,同时修改其它slave的配置,使其master配置项指向新的master,当old master恢复重启后,会自动降级为new master的slave.最后,根据配置,Redis Sentinel还会将新的master地址通知给当前正在访问Redis的应用程序.</p>
<p>Raft分布式算法</p>
<p>1. 主要用途:用于分布式系统,系统容错,以及选出领头羊<br>2. 作者:Diego Ongaro,毕业于哈佛<br>3. 目前用到这个算法的项目有:<br>a. CoreOS<br>b. ectd : a distributed, consistent shared configuration<br>c. LogCabin : 分布式存储系统<br>d. redis sentinel : redis 的监控系统</p>
<p>Sentinel使用的Raft算法核心: 原则</p>
<p>1. 所有sentinel都有选举的领头羊的权利<br>2. 每个sentinel都会要求其他sentinel选举自己为领头羊(主要由发现redis客观下线的sentinel先发起选举)<br>3. 每个sentinel只有一次选举的机会<br>4. 采用先到先得的原则<br>5. 一旦加入到系统了,则不会自动清除(这一点很重要, why?)<br>6. 每个sentinel都有唯一的uid,不会因为重启而变更<br>7. 达到领头羊的条件是 N/2 + 1个sentinel选择了自己<br>8. 采用配置纪元,如果一次选举出现脑裂,则配置纪元会递增,进入下一次选举,所有sentinel都会处于统一配置纪元,以最新的为标准.</p>
<p>Sentinel 配置样例</p>
<p><pre class="lang:default decode:true ">  port 26379<br>  dir /tmp<br>  sentinel monitor mymaster 127.0.0.1 6379 2<br>  sentinel down-after-milliseconds mymaster 30000<br>  sentinel parallel-syncs mymaster 1<br>  sentinel failover-timeout mymaster 180000<br>  sentinel notification-script myredis &lt;script-path&gt;</pre><br>其中:<br>port: 指定sentinel的侦听端口（即与redis server或client建立tcp连接的端口）<br>dir: 工作路径,sentinel一般指定/tmp比较简单<br>monitor: 指定sentinel要monitor的redis实例,包括一个redis实例的别名（alias）及redis实例的ip+port,该行最后的数字2表示至少2个setinel实例同时检测到redis server异常时,才将redis server的状态判决为real fail.也即,若这里配置为2,但实际部署中sentinel只部署了1套,则即使redis实例已经挂掉,sentinel也不会给出任何警告.这一点需要特别引起注意.<br>down-after-milliseconds: 指定sentinel监控到redis实例持续异常多长时间后,会判决其状态为down.若实际业务需要sentinel尽快判决出redis实例异常,则该值可适当配小.<br>failover-timeout: 若sentinel在该配置值内未能完成failover操作（即故障时master/slave自动切换）,则认为本次failover失败.该配置有4个用途,具体可参考sentinel.conf中的说明,限于篇幅,此处不再赘述.<br>parallel-syncs: 指定failover过程中,同时被sentinel reconfigure的最大slave实例数.由于reconfigure过程中,对应的slave会中断响应客户端请求,故为避免所有的slave同时不可用,该值需适当配小.<br>notification-script: 指定sentinel检测到master-name指向的实例异常时,调用的报警脚本.该配置项可选,但线上系统建议配置.</p>
<p>启动 sentinel的方法</p>
<p>当前Redis stable版已经自带了redis-sentinel这个工具.虽然 Redis Sentinel 已经提供了一个单独的可执行文件 redis-sentinel , 但实际上它只是一个运行在特殊模式下的 Redis实例, 你可以在启动一个普通 Redis实例时通过给定 –sentinel 选项来启动 Redis Sentinel 实例.也就是说:<br>redis-sentinel /path/to/sentinel.conf<br>等同于<br>redis-server /path/to/sentinel.conf –sentinel<br>其中sentinel.conf是redis的配置文件,Redis sentinel会需要写入配置文件来保存sentinel的当前状态.当配置文件无法写入时,Sentinel启动失败.</p>
<p>sentinel 测试<br>实验环境 &lt; one master / Three slaves / two sentinels &gt;:<br>a. one master（slave-priority为90）部署在ip为192.168.9.10的机器上；<br>b.Three slaves（slave-priority分别为100）的均部署在ip为192.168.9.70的机器上；<br>c. 启用两个sentinel进程监控redis集群状态</p>
<p>配置 sentinel</p>
<p>Sentinel可以通过master Redis实例来获得它的从实例的信息.所以每一个Sentinel只配置主实例的监控即可.Sentinel之间端口有所不同.</p>
<p><pre class="lang:default decode:true">  port 6666<br>  daemonize yes<br>  logfile “/var/log/redis/sentinel-6666.log”</pre></p>
<p>  #master 1111<br>  sentinel monitor master-1111 192.168.9.10 11111 1<br>  sentinel config-epoch master-1111 6<br>  sentinel leader-epoch master-1111 6<br>  sentinel known-slave master-1111 192.168.9.70 2222<br>启动 sentinel<br>配置文件修改完成后,启动各监控进程即可,例如:<br>redis-server /etc/redis/sentinel-6666.conf</p>
<p>连接Sentinel和主动failover</p>
<p>在默认情况下,Sentinel 使用TCP端口26379（普通 Redis 服务器使用的是 6379）.<br>Sentinel 接受 Redis 协议格式的命令请求,所以你可以使用 redis-cli 或者任何其他 Redis 客户端来与 Sentinel 进行通讯.<br>有两种方式可以和 Sentinel 进行通讯:<br>第一种方法是通过直接发送命令来查询被监视 Redis 服务器的当前状态, 以及进行主动转移等操作.这些命令包括:</p>
<p>SENTINEL masters<br>列出所有被监视的主Redis服务实例,以及这些主服务实例的当前状态.</p>
<p>SENTINEL slaves<br>列出给定主服务实例的所有从实例,以及这些从实例的当前状态.</p>
<p>SENTINEL get-master-addr-by-name<br>返回给定名字的主实例的 IP 地址和端口号. 如果这个主实例正在执行故障转移操作, 或者针对这个主实例的故障转移操作已经完成, 那么这个命令返回新的主服务器的 IP 地址和端口号.</p>
<p>SENTINEL reset:<br>重置所有名字和给定模式 pattern 相匹配的主服务器. pattern 参数是一个 Glob 风格的模式. 重置操作清除该sentinel的所保存的所有状态信息,并进行一次重新的发现过程.</p>
<p>SENTINEL failover<br>进行一次主动的failover.即在不询问其他 Sentinel 意见的情况下, 强制开始一次自动故障迁移 .发起故障转移的 Sentinel 会向其他 Sentinel 发送一个新的配置,其他 Sentinel 会根据这个配置进行相应的更新.^_^[17:19:25][root@master01 ~]#redis-cli  -p 6666</p>
<p><pre class="lang:default decode:true ">redis 127.0.0.1:6666&gt; SENTINEL masters<br>1)  1) “name”<br>2) “master-1111”<br>3) “ip”<br>4) “192.168.9.10”<br>5) “port”<br>6) “1111”<br>7) “runid”<br>8) “5d6c2f08547ffe9446eb54c85dc40959e66b203d”<br>9) “flags”<br>10) “master”<br>11) “pending-commands”<br>12) “0”<br>13) “last-ping-sent”<br>14) “0”<br>15) “last-ok-ping-reply”<br>16) “947”<br>17) “last-ping-reply”<br>18) “947”<br>19) “down-after-milliseconds”<br>20) “30000”<br>21) “info-refresh”<br>22) “6259”<br>23) “role-reported”<br>24) “master”<br>25) “role-reported-time”<br>26) “126884”<br>27) “config-epoch”<br>28) “7”<br>29) “num-slaves”<br>30) “3”<br>31) “num-other-sentinels”<br>32) “1”<br>33) “quorum”<br>34) “1”<br>35) “failover-timeout”<br>36) “180000”<br>37) “parallel-syncs”<br>38) “1”</pre></p>
<p>redis 127.0.0.1:6666&gt; SENTINEL slaves master-1111<br>1)  1) “name”<br>2) “192.168.9.10:1112”<br>3) “ip”<br>4) “192.168.9.10”<br>5) “port”<br>6) “1112”<br>7) “runid”<br>8) “”<br>9) “flags”<br>10) “s_down,slave,disconnected”<br>11) “pending-commands”<br>12) “0”<br>13) “last-ping-sent”<br>14) “215549”<br>15) “last-ok-ping-reply”<br>16) “215549”<br>17) “last-ping-reply”<br>18) “215549”<br>19) “s-down-time”<br>20) “185544”<br>21) “down-after-milliseconds”<br>22) “30000”<br>23) “info-refresh”<br>24) “1458206565223”<br>25) “role-reported”<br>26) “slave”<br>27) “role-reported-time”<br>28) “215549”<br>29) “master-link-down-time”<br>30) “0”<br>31) “master-link-status”<br>32) “err”<br>33) “master-host”<br>34) “?”<br>35) “master-port”<br>36) “0”<br>37) “slave-priority”<br>38) “100”<br>39) “slave-repl-offset”<br>40) “0”<br>2)  1) “name”<br>2) “192.168.9.70:2222”<br>3) “ip”<br>4) “192.168.9.70”<br>5) “port”<br>6) “2222”<br>7) “runid”<br>8) “”<br>9) “flags”<br>10) “s_down,slave,disconnected”<br>11) “pending-commands”<br>12) “0”<br>13) “last-ping-sent”<br>14) “215549”<br>15) “last-ok-ping-reply”<br>16) “215549”<br>17) “last-ping-reply”<br>18) “215549”<br>19) “s-down-time”<br>20) “185544”<br>21) “down-after-milliseconds”<br>22) “30000”<br>23) “info-refresh”<br>24) “1458206565223”<br>25) “role-reported”<br>26) “slave”<br>27) “role-reported-time”<br>28) “215549”<br>29) “master-link-down-time”<br>30) “0”<br>31) “master-link-status”<br>32) “err”<br>33) “master-host”<br>34) “?”<br>35) “master-port”<br>36) “0”<br>37) “slave-priority”<br>38) “100”<br>39) “slave-repl-offset”<br>40) “0”<br>3)  1) “name”<br>2) “192.168.9.70:2223”<br>3) “ip”<br>4) “192.168.9.70”<br>5) “port”<br>6) “2223”<br>7) “runid”<br>8) “9987aebafc55d750145a61f9109cf7d9fb7c8613”<br>9) “flags”<br>10) “slave”<br>11) “pending-commands”<br>12) “0”<br>13) “last-ping-sent”<br>14) “0”<br>15) “last-ok-ping-reply”<br>16) “372”<br>17) “last-ping-reply”<br>18) “372”<br>19) “down-after-milliseconds”<br>20) “30000”<br>21) “info-refresh”<br>22) “4616”<br>23) “role-reported”<br>24) “slave”<br>25) “role-reported-time”<br>26) “215549”<br>27) “master-link-down-time”<br>28) “0”<br>29) “master-link-status”<br>30) “ok”<br>31) “master-host”<br>32) “192.168.9.10”<br>33) “master-port”<br>34) “1111”<br>35) “slave-priority”<br>36) “100”<br>37) “slave-repl-offset”<br>38) “29082”</p>
<p>查看当前的master<br>redis 127.0.0.1:6666&gt;  SENTINEL get-master-addr-by-name master-1111<br>1) “192.168.9.10”<br>2) “1111”<br>&nbsp;</p>
<p>使用发布与订阅功能, 通过接收 Sentinel 发送的通知: 当执行故障转移操作, 或者某个被监视的实例被判断为主观下线或者客观下线时, Sentinel 就会发送相应的信息.<br>一个频道能够接收和这个频道的名字相同的事件. 比如说,名为 +sdown 的频道就可以接收所有实例进入主观下线（SDOWN）状态的事件.<br>通过执行 PSUBSCRIBE * 命令可以接收所有事件信息.例如：</p>
<p><pre class="lang:default decode:true ">^_^[17:50:13][root@master01 ~]#redis-cli -p 6666 info| grep 192<br>master0:name=master-1111,status=ok,address=192.168.9.10:1111,slaves=3,sentinels=2</pre></p>
<p>^_^[17:50:21][root@master01 ~]#redis-cli -p 6666 sentinel failover master-1111<br>OK</p>
<p>@_@[17:50:09][root@master01 ~]#redis-cli -p 6666<br>redis 127.0.0.1:6666&gt;  SENTINEL get-master-addr-by-name master-1111<br>1) “192.168.9.10”<br>2) “1111”<br>redis 127.0.0.1:6666&gt; PSUBSCRIBE <em><br>Reading messages… (press Ctrl-C to quit)<br>1) “psubscribe”<br>2) “</em>“<br>3) (integer) 1<br>1) “pmessage”<br>2) “<em>“<br>3) “+new-epoch”<br>4) “8”<br>1) “pmessage”<br>2) “</em>“<br>3) “+try-failover”<br>4) “master master-1111 192.168.9.10 1111”<br>1) “pmessage”<br>2) “<em>“<br>3) “+vote-for-leader”<br>4) “691dc32d3a3c1afdc5b18a8e5541c885aa04c487 8”<br>1) “pmessage”<br>2) “</em>“<br>3) “+elected-leader”<br>4) “master master-1111 192.168.9.10 1111”<br>1) “pmessage”<br>2) “<em>“<br>3) “+failover-state-select-slave”<br>4) “master master-1111 192.168.9.10 1111”<br>1) “pmessage”<br>2) “</em>“<br>3) “+selected-slave”<br>4) “slave 192.168.9.10:1112 192.168.9.10 1112 @ master-1111 192.168.9.10 1111”<br>1) “pmessage”<br>2) “<em>“<br>3) “+failover-state-send-slaveof-noone”<br>4) “slave 192.168.9.10:1112 192.168.9.10 1112 @ master-1111 192.168.9.10 1111”<br>1) “pmessage”<br>2) “</em>“<br>3) “+failover-state-wait-promotion”<br>4) “slave 192.168.9.10:1112 192.168.9.10 1112 @ master-1111 192.168.9.10 1111”<br>1) “pmessage”<br>2) “<em>“<br>3) “-role-change”<br>4) “slave 192.168.9.10:1112 192.168.9.10 1112 @ master-1111 192.168.9.10 1111 new reported role is master”<br>1) “pmessage”<br>2) “</em>“<br>3) “+promoted-slave”<br>4) “slave 192.168.9.10:1112 192.168.9.10 1112 @ master-1111 192.168.9.10 1111”<br>1) “pmessage”<br>2) “<em>“<br>3) “+failover-state-reconf-slaves”<br>4) “master master-1111 192.168.9.10 1111”<br>1) “pmessage”<br>2) “</em>“<br>3) “+slave-reconf-sent”<br>4) “slave 192.168.9.70:2222 192.168.9.70 2222 @ master-1111 192.168.9.10 1111”<br>1) “pmessage”<br>2) “<em>“<br>3) “+slave-reconf-inprog”<br>4) “slave 192.168.9.70:2222 192.168.9.70 2222 @ master-1111 192.168.9.10 1111”<br>1) “pmessage”<br>2) “</em>“<br>3) “+slave-reconf-done”<br>4) “slave 192.168.9.70:2222 192.168.9.70 2222 @ master-1111 192.168.9.10 1111”<br>1) “pmessage”<br>2) “<em>“<br>3) “+slave-reconf-sent”<br>4) “slave 192.168.9.70:2223 192.168.9.70 2223 @ master-1111 192.168.9.10 1111”<br>1) “pmessage”<br>2) “</em>“<br>3) “+slave-reconf-inprog”<br>4) “slave 192.168.9.70:2223 192.168.9.70 2223 @ master-1111 192.168.9.10 1111”<br>1) “pmessage”<br>2) “<em>“<br>3) “+slave-reconf-done”<br>4) “slave 192.168.9.70:2223 192.168.9.70 2223 @ master-1111 192.168.9.10 1111”<br>1) “pmessage”<br>2) “</em>“<br>3) “+failover-end”<br>4) “master master-1111 192.168.9.10 1111”<br>1) “pmessage”<br>2) “<em>“<br>3) “+switch-master”<br>4) “master-1111 192.168.9.10 1111 192.168.9.10 1112”<br>1) “pmessage”<br>2) “</em>“<br>3) “+slave”<br>4) “slave 192.168.9.70:2222 192.168.9.70 2222 @ master-1111 192.168.9.10 1112”<br>1) “pmessage”<br>2) “<em>“<br>3) “+slave”<br>4) “slave 192.168.9.70:2223 192.168.9.70 2223 @ master-1111 192.168.9.10 1112”<br>1) “pmessage”<br>2) “</em>“<br>3) “+slave”<br>4) “slave 192.168.9.10:1111 192.168.9.10 1111 @ master-1111 192.168.9.10 1112”<br>1) “pmessage”<br>2) “<em>“<br>3) “-role-change”<br>4) “slave 192.168.9.10:1111 192.168.9.10 1111 @ master-1111 192.168.9.10 1112 new reported role is master”<br>1) “pmessage”<br>2) “</em>“<br>3) “+role-change”<br>4) “slave 192.168.9.10:1111 192.168.9.10 1111 @ master-1111 192.168.9.10 1112 new reported role is slave”<br>一次故障转移操作由以下步骤组成：<br>(1). 由sentinel主动发起failover或者发现主服务器已经进入客观下线状态.<br>(2). sentinel对我们的当前纪元(epoch)进行自增,并尝试在这个纪元中当选为此次failover的总指挥.<br>(3). 如果当选失败, 那么在设定的故障迁移超时时间的两倍之后, 重新尝试当选. 如果当选成功, 那么执行以下步骤.<br>(4). 选出一个从redis实例,并将它升级为主redis实例.<br>(5). 向被选中的从redis实例发送 SLAVEOF NO ONE 命令,让它转变为主redis实例.<br>(6). 通过发布与订阅功能, 将更新后的配置传播给所有其他 Sentinel , 其他 Sentinel 对它们自己的配置进行更新.<br>(7). 向已下线主服务器的从服务器发送SLAVEOF命令, 让它们去复制新的主服务器.<br>(8). 当所有从redis实例都已经开始复制新的主redis实例时, 领头Sentinel 终止这次故障迁移操作.</p>
<p>FAQ:<br>若master实例故障,则最好等sentinel选出new master且稳定后（选新主并完成切换的时间与配置有关,典型值在1分钟之内）,再重启old master,避免引发sentinel的误判,导致整个系统无法选出new master.</p>
<p>最大内存问题:要设置好最大内存,以防不停的申请内存,造成系统内存都被用完.</p>
<p>Fork进程问题:’vm.overcommit_memory = 1’这一个选项要加到系统的配置中,防止fork因内存不足而失败.</p>
<p>密码问题:需要设置复杂一些,防止暴力破解.</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>Redis Sentinel 是一套用于管理Redis实例的分布式系统,主要完成3项任务:</p>
<p>1. Monitoring:持续监控Redis master或slave实例的运行情况是否符合预期<br>2. Notification:若被监控的Redis实例运行异]]>
    </summary>
    
      <category term="redis" scheme="http://blog.suzf.net/tags/redis/"/>
    
      <category term="Redis" scheme="http://blog.suzf.net/categories/Redis/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Redis 主从复制]]></title>
    <link href="http://blog.suzf.net/2016/03/17/Redis_%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"/>
    <id>http://blog.suzf.net/2016/03/17/Redis_主从复制/</id>
    <published>2016-03-17T07:56:24.000Z</published>
    <updated>2016-03-31T05:38:36.000Z</updated>
    <content type="html"><![CDATA[<p>Redis 安装见 <a href="http://suzf.net/thread-0314-616.html" target="_blank" rel="external">Redis Setup</a></p>
<p>环境<br>CentOS 6.x<br>Redis=3.0.7</p>
<p>master01<br>port 1111<br>192.168.9.10/24</p>
<p>ocean-lab<br>port 2222<br>192.168.9.70/24</p>
<p>主从复制<br>1.为什么使用，好处？<br>1.1 单个redis服务器压力过大，可考虑，master写，slave读，分散缓解服务器压力。<br>1.2 一个master可以拥有多个slave，而一个slave又可以拥有多个slave</p>
<p>2.主从复制过程<br>2.1 master、slave 建立连接且slave 向master 发起同步请求<br>2.2 请求成功之后 slave 接受master发送过来的dump.rdb的快照文件<br>2.3 slave载入dump.rdb文件<br>2.4 当master和slave的连接断开时slave可以自动重新建立连接。如果master同时收到多个 slave发来的同步连接命令，只会使用启动一个进程来写数据库镜像，然后发送给所有slave。</p>
<p><a href="http://suzf.net/wp-content/uploads/2016/03/redis_replication.png" target="_blank" rel="external"><img src="http://suzf.net/wp-content/uploads/2016/03/redis_replication.png" alt="redis_replication"></a></p>
<p>主从配置<br>配置 Master-Slave,只需要在 Slave 上配置 Master 节点IP Port:</p>
<h1 id="slaveof__26lt_3Bmasterip_26gt_3B__26lt_3Bmasterport_26gt_3B"><a href="#slaveof__26lt_3Bmasterip_26gt_3B__26lt_3Bmasterport_26gt_3B" class="headerlink" title="slaveof &lt;masterip&gt; &lt;masterport&gt;"></a>slaveof &lt;masterip&gt; &lt;masterport&gt;</h1><h1 id="Since_Redis_2-6_by_default_slaves_are_read-only_-_slave-read-only_yes"><a href="#Since_Redis_2-6_by_default_slaves_are_read-only_-_slave-read-only_yes" class="headerlink" title="Since Redis 2.6 by default slaves are read-only - slave-read-only yes"></a>Since Redis 2.6 by default slaves are read-only - slave-read-only yes</h1><p>[16:44:26][root@ocean-lab ~]$ echo “slaveof  192.168.9.10 1111” &gt;&gt; /etc/redis/2222.conf<br>[16:44:40][root@ocean-lab ~]$ /etc/init.d/redis_2222 restart</p>
<p>测试<br>^<em>^[16:52:22][root@master01 ~]#redis-cli -h 192.168.9.70 -p 2222 ping<br>PONG<br>^</em>^[16:56:39][root@master01 ~]#redis-cli -h 192.168.9.10 -p 1111 ping<br>PONG</p>
<p>验证</p>
<p>在master 上查看当前有多少key<br>^<em>^[16:52:10][root@master01 ~]#redis-cli -p 1111 get name<br>“suzf.net”<br>^</em>^[16:56:57][root@master01 ~]#redis-cli -h 192.168.9.10 -p 1111 keys *<br>1) “name”</p>
<p>在master上添加一个key<br>^_^[16:59:54][root@master01 ~]#redis-cli -h 192.168.9.10 -p 1111 set homepage suzf.net<br>OK</p>
<p>然后在slave上面查看<br>^<em>^[17:02:19][root@master01 ~]#redis-cli -h 192.168.9.70 -p 2222 keys *<br>1) “name”<br>2) “homepage”<br>^</em>^[17:02:59][root@master01 ~]#redis-cli -h 192.168.9.10 -p 1111 get homepage<br>“suzf.net”</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>Redis 安装见 <a href="http://suzf.net/thread-0314-616.html" target="_blank" rel="external">Redis Setup</a></p>
<p>环境<br>CentOS 6.x<br>Redis=]]>
    </summary>
    
      <category term="redis" scheme="http://blog.suzf.net/tags/redis/"/>
    
      <category term="Redis" scheme="http://blog.suzf.net/categories/Redis/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Redis 监控技巧]]></title>
    <link href="http://blog.suzf.net/2016/03/14/Redis_%E7%9B%91%E6%8E%A7%E6%8A%80%E5%B7%A7/"/>
    <id>http://blog.suzf.net/2016/03/14/Redis_监控技巧/</id>
    <published>2016-03-14T10:03:29.000Z</published>
    <updated>2016-03-31T05:38:36.000Z</updated>
    <content type="html"><![CDATA[<div id="wrap"><br><div id="content"><br><div id="contentleft"><br><div class="postarea"><br><div id="wrap"><br><div id="content"><br><div id="contentleft"><br><div class="postarea"><br><br>本文来自 <a href="https://bugsnag.com/" target="_blank" rel="external">Bugsnag</a> 的联合创始人 <a href="https://twitter.com/snmaynard/" target="_blank" rel="external">Simon Maynard</a> 的系列文章，作者根据几年来对 <span class="wp_keywordlink_affiliate"><a href="http://blog.nosqlfan.com/tags/redis" title="查看 Redis 的全部文章" target="_blank" rel="external">Redis</a></span> 的使用经历，对 Redis <span class="wp_keywordlink_affiliate"><a href="http://blog.nosqlfan.com/tags/%e7%9b%91%e6%8e%a7" title="查看 监控 的全部文章" target="_blank" rel="external">监控</a></span>方法进行了系统性的总结，干货很多，值得一看。<br><br>原文链接：<a href="http://snmaynard.com/2013/01/22/redis-masterclass-part-two-monitoring-redis/" target="_blank" rel="external">Redis Masterclass – Part 2, Monitoring</a><br><br>Redis 监控最直接的方法当然就是使用系统提供的 info 命令来做了，你只需要执行下面一条命令，就能获得 Redis 系统的状态报告。<br><pre>redis-cli info</pre><br><br>### 内存使用<br><br>如果 Redis 使用的内存超出了可用的物理内存大小，那么 Redis 很可能系统会被 <a href="http://linux-mm.org/OOM_Killer" target="_blank" rel="external">OOM Killer</a> 杀掉。针对这一点，你可以通过 info 命令对 _used<em>memory</em> 和 _used_memory<em>peak</em> 进行监控，为使用内存量设定阈值，并设定相应的报警机制。当然，报警只是手段，重要的是你得预先计划好，当内存使用量过大后，你应该做些什么，是清除一些没用的冷数据，还是把 Redis 迁移到更强大的机器上去。<br><br>### 持久化<br><br>如果因为你的机器或 Redis 本身的问题导致 Redis 崩溃了，那么你唯一的救命稻草可能就是 dump 出来的 rdb文件了，所以，对 Redis dump 文件进行监控也是很重要的。你可以通过对 _rdb_last_save<em>time</em> 进行监控，了解你最近一次 dump 数据操作的时间，还可以通过对 _rdb_changes_since_last<em>save</em> 进行监控来知道如果这时候出现故障，你会丢失多少数据。<br><br>### 主从复制<br><br>如果你设置了主从复制模式，那么你最好对复制的情况是否正常做一些监控，主要是对 info 输出中的 _master_link<em>status</em> 进行监控，如果这个值是 up，那么说明同步正常，如果是 down，那么你就要注意一下输出的其它一些诊断信息了。比如下面这些：<br><pre>role:slave master_host:192.168.1.128 master_port:6379 master_link_status:down master_last_io_seconds_ago:-1 master_sync_in_progress:0 master_link_down_since_seconds:1356900595</pre><br><br>### Fork 性能<br><br>当 Redis 持久化数据到磁盘上时，它会进行一次 fork 操作，通过 fork 对内存的 copy on write 机制最廉价的实现内存镜像。但是虽然内存是 copy on write 的，但是虚拟内存表是在 fork 的瞬间就需要分配，所以 fork 会造成主线程短时间的卡顿（停止所有读写操作），这个卡顿时间和当前 Redis 的内存使用量有关。通常 GB 量级的 Redis 进行 fork 操作的时间在毫秒级。你可以通过对 info 输出的 _latest_fork<em>usec</em> 进行监控来了解最近一次 fork 操作导致了多少时间的卡顿。<br><br>### 配置一致<br><br>Redis 支持使用 <a href="http://redis.io/commands/config-set" target="_blank" rel="external">CONFIG SET</a> 操作来实现运行实的配置修改，这很方便，但同时也会导致一个问题。就是通过这个命令动态修改的配置，是不会同步到你的配置文件中去的。所以当你因为某些原 因重启 Redis 时，你使用 CONFIG SET 做的配置修改就会丢失掉，所以我们最好保证在每次使用 CONFIG SET 修改配置时，也把配置文件一起相应地改掉。为了防止人为的失误，所以我们最好对配置进行监控，使用 <a href="http://redis.io/commands/config-get" target="_blank" rel="external">CONFIG GET</a> 命令来获取当前运行时的配置，并与 redis.conf 中的配置值进行对比，如果发现两边对不上，就启动报警。<br><br>### 慢日志<br><br>Redis 提供了 <a href="http://redis.io/commands/slowlog" target="_blank" rel="external">SLOWLOG</a> 指令来获取最近的慢日志，Redis 的慢日志是直接存在内存中的，所以它的慢日志开销并不大，在实际应用中，我们通过 crontab 任务执行 SLOWLOG 命令来获取慢日志，然后将慢日志存到文件中，并用 <a href="http://kibana.org/" target="_blank" rel="external">Kibana</a> 生成实时的性能图表来实现性能监控。<br><br>值得一提的是，Redis 的慢日志记录的时间，仅仅包括 Redis 自身对一条命令的执行时间，不包括 IO 的时间，比如接收客户端数据和发送客户端数据这些时间。另外，Redis 的慢日志和其它数据库的慢日志有一点不同，其它数据库偶尔出现 100ms 的慢日志可能都比较正常，因为一般数据库都是多线程并发执行，某个线程执行某个命令的性能可能并不能代表整体性能，但是对<br><br>来说，它是单线程的，一旦出现慢日志，可能就需要马上得到重视，最好去查一下具体是什么原因了。<br><br>### 监控服务<br><br>#### -Sentinel<br><br><a href="http://redis.io/topics/sentinel" target="_blank" rel="external">Sentinel</a> 是 Redis 自带的工具，它可以对 Redis 主从复制进行监控，并实现主挂掉之后的自动故障转移。在转移的过程中，它还可以被配置去执行一个用户自定义的脚本，在脚本中我们就能够实现报警通知等功能。<br><br>#### -Redis Live<br><br><a href="http://www.nkrode.com/article/real-time-dashboard-for-redis" target="_blank" rel="external">Redis Live</a> 是一个更通用的 Redis 监控方案，它的原理是定时在 Redis 上执行 <a href="http://redis.io/commands/monitor" target="_blank" rel="external">MONITOR</a> 命令，来获取当前 Redis 当前正在执行的命令，并通过统计分析，生成web页面的可视化分析报表。<br><br>#### -Redis Faina<br><br><a href="http://instagram-engineering.tumblr.com/post/23132009381/redis-faina-a-query-analysis-tool-for-redis" target="_blank" rel="external">Redis Faina</a> 是由著名的图片分享应用 instagram 开发的 Redis 监控服务，其原理和 Redis Live 类似，都是对通过 <span class="wp_keywordlink_affiliate"><a href="http://blog.nosqlfan.com/tags/monitor" title="查看 MONITOR 的全部文章" target="_blank" rel="external">MONITOR</a></span> 来做的。<br><br>### 数据分布<br><br>弄清 Redis 中数据存储分布是一件很难的是，比如你想知道哪类型的 key 值占用内存最多。下面是一些工具，可以帮助你对 Redis 的数据集进行分析。<br><br>#### -Redis-sampler<br><br><a href="https://github.com/antirez/redis-sampler" target="_blank" rel="external">Redis-sampler</a> 是 Redis 作者开发的工具，它通过采样的方法，能够让你了解到当前Redis 中的数据的大致类型，数据及分布状况。<br><br>#### -Redis-audit<br><br><a href="https://github.com/snmaynard/redis-audit" target="_blank" rel="external">Redis-audit</a> 是一个脚本，通过它，我们可以知道每一类 key 对内存的使用量。它可以提供的数据有：某一类 key 值的访问频率如何，有多少值设置了过期时间，某一类 key 值使用内存的大小，这很方便让我们能排查哪些 key 不常用或者压根不用。<br><br>#### -Redis-rdb-tools<br><br><a href="https://github.com/sripathikrishnan/redis-rdb-tools" target="_blank" rel="external">Redis-rdb-tools</a>跟 Redis-audit 功能类似，不同的是它是通过对 rdb 文件进行分析来取得统计数据的。<br><br>来源: <a href="http://blog.nosqlfan.com/html/4166.html" target="_blank" rel="external">nosqlfan</a><br><br></div><br></div><br></div><br></div><br></div><br></div><br></div><br></div>]]></content>
    <summary type="html">
    <![CDATA[<div id="wrap"><br><div id="content"><br><div id="contentleft"><br><div class="postarea"><br><div id="wrap"><br><div id="content"><br><div i]]>
    </summary>
    
      <category term="NoSQL" scheme="http://blog.suzf.net/tags/NoSQL/"/>
    
      <category term="redis" scheme="http://blog.suzf.net/tags/redis/"/>
    
      <category term="Redis" scheme="http://blog.suzf.net/categories/Redis/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Redis 安装与特性简述]]></title>
    <link href="http://blog.suzf.net/2016/03/14/Redis_%E5%AE%89%E8%A3%85%E4%B8%8E%E7%89%B9%E6%80%A7%E7%AE%80%E8%BF%B0/"/>
    <id>http://blog.suzf.net/2016/03/14/Redis_安装与特性简述/</id>
    <published>2016-03-14T09:51:57.000Z</published>
    <updated>2016-03-31T05:38:36.000Z</updated>
    <content type="html"><![CDATA[<p>Redis&lt; Remote Dictionary Server  &gt;作为NoSQL数据库的一种应用，响应速度和命中率上还是比较高效的。<br>项目中需要用集中式可横向扩展的缓存框架，做了一点调研，即便redis、memcached存在效率上的差异（具体比较参考<a href="http://timyang.net/data/mcdb-tt-redis/），但其实都能满足目前项目的需求；但是redis还是比较风骚的，支持链表和集合操作，支持正则表达式查找key，目前项目缓存的结果大多是链表，如果链表新增或者修改数据的话，redis就体现出了极大的优势（memcached只能重新加载链表，redis可以对链表新增或者修改）" target="_blank" rel="external">http://timyang.net/data/mcdb-tt-redis/），但其实都能满足目前项目的需求；但是redis还是比较风骚的，支持链表和集合操作，支持正则表达式查找key，目前项目缓存的结果大多是链表，如果链表新增或者修改数据的话，redis就体现出了极大的优势（memcached只能重新加载链表，redis可以对链表新增或者修改）</a></p>
<p>到目前为止Redis 支持的数据类型如下：</p>
<p>– 字符串类型<br>– 散列类型<br>– 列表类型<br>– 集合类型<br>– 有序集合类型</p>
<p><strong>1. Redis 安装</strong><br>== Redis 源码安装<br>– 参照源码 README<br>– 默认端口 6379</p>
<p><strong><em> 安装redis之前先要确认系统已经安装了GCC和libc库 </em></strong></p>
<p>wget <a href="http://download.redis.io/releases/redis-3.0.7.tar.gz" target="_blank" rel="external">http://download.redis.io/releases/redis-3.0.7.tar.gz</a><br>tar xf redis-3.0.7.tar.gz<br>cd redis-3.0.7<br>make</p>
<h1 id="make_test"><a href="#make_test" class="headerlink" title="make test"></a>make test</h1><p>make PREFIX=/usr/local/redis install</p>
<p>== 可执行命令<br>redis-server    Redis服务系统<br>redis-cli       Redis一个客户端管理工具<br>redis-benchmark 用来检测redis性能<br>redis-check-aof &amp; redis-check-dump 用来处理损坏的数据文件<br>redis-sentinel -&gt; redis-server   &lt; soft link &gt;</p>
<p>cd utils<br>./install_server.sh</p>
<p>^_^[15:50:34][root@master01 utils]#bash install_server.sh<br>Welcome to the redis service installer<br>This script will help you easily set up a running redis server</p>
<p>Please select the redis port for this instance: [6379] 1111<br>Please select the redis config file name [/etc/redis/1111.conf]<br>Selected default - /etc/redis/1111.conf<br>Please select the redis log file name [/var/log/redis_1111.log]<br>Selected default - /var/log/redis_1111.log<br>Please select the data directory for this instance [/var/lib/redis/1111]<br>Selected default - /var/lib/redis/1111<br>Please select the redis executable path [/usr/sbin/redis-server] /usr/local/redis/bin/redis-server<br>Selected config:<br>Port           : 1111<br>Config file    : /etc/redis/1111.conf<br>Log file       : /var/log/redis_1111.log<br>Data dir       : /var/lib/redis/1111<br>Executable     : /usr/local/redis/bin/redis-server<br>Cli Executable : /usr/bin/redis-cli<br>Is this ok? Then press ENTER to go on or Ctrl-C to abort.<br>Copied /tmp/1111.conf =&gt; /etc/init.d/redis_1111<br>Installing service…<br>Successfully added to chkconfig!<br>Successfully added to runlevels 345!<br>Starting Redis server…<br>Installation successful!</p>
<p><strong>2. 系统配置</strong><br>设置内存分配策略（可选，根据服务器的实际情况进行设置）<br>/proc/sys/vm/overcommit_memory<br>可选值：0、1、2。<br>0， 表示内核将检查是否有足够的可用内存供应用进程使用；如果有足够的可用内存，内存申请允许；否则，内存申请失败，并把错误返回给应用进程。<br>1， 表示内核允许分配所有的物理内存，而不管当前的内存状态如何。<br>2， 表示内核允许分配超过所有物理内存和交换空间总和的内存</p>
<p>值得注意的一点是，redis在dump数据的时候，会fork出一个子进程，理论上child进程所占用的内存和parent是一样的，比如parent占用的内存为8G，这个时候也要同样分配8G的内存给child,如果内存无法负担，往往会造成redis服务器的down机或者IO负载过高，效率下降。所以这里比较优化的内存分配策略应该设置为 1（表示内核允许分配所有的物理内存，而不管当前的内存状态如何）</p>
<p>防火墙开启redis端口</p>
<p>加入端口配置<br>iptables -A INPUT -m state –state NEW -m tcp -p tcp –dport 1111 -j ACCEPT  # &lt; redis instance port &gt;</p>
<p>写入配置文件<br>iptables-save &gt; /etc/sysconfig/iptables</p>
<p><strong>3. 启动redis服务</strong><br>/etc/init.d/redis_1111  start</p>
<p><strong>4. 测试redis</strong></p>
<p>#redis-cli  -p 1111<br>redis 127.0.0.1:1111&gt; set name suzf.net<br>OK<br>redis 127.0.0.1:1111&gt; get name<br>“suzf.net”</p>
<p>客户端连接验证</p>
<p>#redis-cli -p 1111 ping<br>PONG</p>
<p><strong>5. 关闭redis服务</strong><br>停止Redis<br>/etc/init.d/redis_1111  stop</p>
<p>关闭指定端口的redis-server<br>redis-cli -p 1111 shutdown</p>
<p>redis服务关闭后，缓存数据会自动dump到硬盘上，硬盘地址为redis.conf中的配置项dbfilename dump.rdb所设定<br>强制备份数据到磁盘，使用如下命令</p>
<p>redis-cli save<br>redis-cli -p 111 save（指定端口）</p>
<p><strong>6. Redis 常用命令</strong><br>info #查看server版本内存使用连接等信息</p>
<p>client list #获取客户连接列表</p>
<p>client kill 127.0.0.1:33441 #终止某个客户端连接</p>
<p>dbsize #当前保存key的数量</p>
<p>save #立即保存数据到硬盘</p>
<p>bgsave #异步保存数据到硬盘</p>
<p>flushdb #当前库中移除所有key</p>
<p>flushall #移除所有key从所有库中</p>
<p>lastsave #获取上次成功保存到硬盘的unix时间戳</p>
<p>monitor #实时监测服务器接收到的请求</p>
<p>slowlog len #查询慢查询日志条数</p>
<p>slowlog get #返回所有的慢查询日志，最大值取决于slowlog-max-len配置</p>
<p>slowlog get 2 #打印两条慢查询日志</p>
<p>slowlog reset #清空慢查询日志信息</p>
<p><strong>7. Redis与Mongodb 多数据库 区别</strong></p>
<p>redis数据库</p>
<p>redis的数据库个数，在配置文件中设定死了，并且名称是不允许改的。<br>databases 16     //默认16个数据库</p>
<p>这16个数据库编号是0-15，如果没有切换数据库的话，默认是0号数据库.</p>
<p><pre class="lang:default decode:true ">    #redis-cli<br>    redis 127.0.0.1:6379&gt; set test 111<br>    OK<br>    redis 127.0.0.1:6379&gt; select 1<br>    OK<br>    redis 127.0.0.1:6379[1]&gt; set test 222<br>    OK<br>    redis 127.0.0.1:6379[1]&gt; get test<br>    “222”<br>    redis 127.0.0.1:6379[1]&gt; select 0<br>    OK<br>    redis 127.0.0.1:6379&gt; get test<br>    “111”<br>    redis 127.0.0.1:6379&gt;</pre><br>数据库间相同的key,相互不受影响。</p>
<p>mongodb数据库<br>mongodb非常像关系型数据库，与redis不同的是，mongodb不用事先定义多少个数据库，数据库名也是自定义的。限制比redis少。</p>
<p><pre class="lang:default decode:true ">    #mongo<br>    MongoDB shell version: 2.4.14<br>    connecting to: test<br>    &gt; use Fern     // 如果数据库不存在会自动创建<br>    switched to db Fern</pre><br>&nbsp;</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>Redis&lt; Remote Dictionary Server  &gt;作为NoSQL数据库的一种应用，响应速度和命中率上还是比较高效的。<br>项目中需要用集中式可横向扩展的缓存框架，做了一点调研，即便redis、memcached存在效率上的差异（具体比较参考<]]>
    </summary>
    
      <category term="NoSQL" scheme="http://blog.suzf.net/tags/NoSQL/"/>
    
      <category term="redis" scheme="http://blog.suzf.net/tags/redis/"/>
    
      <category term="Redis" scheme="http://blog.suzf.net/categories/Redis/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Python time 模块简述]]></title>
    <link href="http://blog.suzf.net/2016/03/10/Python_time_%E6%A8%A1%E5%9D%97%E7%AE%80%E8%BF%B0/"/>
    <id>http://blog.suzf.net/2016/03/10/Python_time_模块简述/</id>
    <published>2016-03-10T08:33:51.000Z</published>
    <updated>2016-03-31T05:38:36.000Z</updated>
    <content type="html"><![CDATA[<p>一、简介</p>
<p>time模块提供各种操作时间的函数<br>说明：一般有两种表示时间的方式:<br>第一种是时间戳的方式(相对于1970.1.1 00:00:00以秒计算的偏移量),时间戳是惟一的<br>第二种以数组的形式表示即(struct_time),共有九个元素，分别表示，同一个时间戳的struct_time会因为时区不同而不同<br>year (four digits, e.g. 1998)<br>month (1-12)<br>day (1-31)<br>hours (0-23)<br>minutes (0-59)<br>seconds (0-59)<br>weekday (0-6, Monday is 0)<br>Julian day (day in the year, 1-366)<br>DST (Daylight Savings Time) flag (-1, 0 or 1) 是否是夏令时<br>If the DST flag is 0, the time is given in the regular time zone;<br>if it is 1, the time is given in the DST time zone;<br>if it is -1, mktime() should guess based on the date and time.<br>夏令时介绍：<a href="http://baike.baidu.com/view/100246.htm" target="_blank" rel="external">http://baike.baidu.com/view/100246.htm</a><br>UTC介绍：<a href="http://wenda.tianya.cn/wenda/thread?tid=283921a9da7c5aef&amp;clk=wttpcts" target="_blank" rel="external">http://wenda.tianya.cn/wenda/thread?tid=283921a9da7c5aef&amp;clk=wttpcts</a></p>
<p>二、函数介绍<br>1.asctime()<br>asctime([tuple]) -&gt; string<br>将一个struct_time(默认为当时时间)，转换成字符串<br>Convert a time tuple to a string, e.g. ‘Sat Jun 06 16:26:11 1998’.<br>When the time tuple is not present, current time as returned by localtime()<br>is used.</p>
<p>2.clock()<br>clock() -&gt; floating point number<br>该函数有两个功能，<br>在第一次调用的时候，返回的是程序运行的实际时间；<br>以第二次之后的调用，返回的是自第一次调用后,到这次调用的时间间隔</p>
<p>示例：</p>
<p>[python] view plain copy</p>
<p>import time<br>if <strong>name</strong> == ‘<strong>main</strong>‘:<br>time.sleep(1)<br>print “clock1:%s” % time.clock()<br>time.sleep(1)<br>print “clock2:%s” % time.clock()<br>time.sleep(1)<br>print “clock3:%s” % time.clock()</p>
<p>输出：<br>clock1:3.35238137808e-006<br>clock2:1.00004944763<br>clock3:2.00012040636<br>其中第一个clock输出的是程序运行时间<br>第二、三个clock输出的都是与第一个clock的时间间隔</p>
<p>3.sleep(…)<br>sleep(seconds)<br>线程推迟指定的时间运行，经过测试，单位为秒，但是在帮助文档中有以下这样一句话，这关是看不懂<br>“The argument may be a floating point number for subsecond precision.”</p>
<p>4.ctime(…)<br>ctime(seconds) -&gt; string<br>将一个时间戳(默认为当前时间)转换成一个时间字符串<br>例如：<br>time.ctime()<br>输出为：’Sat Mar 28 22:24:24 2009’</p>
<p>5.gmtime(…)<br>gmtime([seconds]) -&gt; (tm_year, tm_mon, tm_day, tm_hour, tm_min,tm_sec, tm_wday, tm_yday, tm_isdst)<br>将一个时间戳转换成一个UTC时区(0时区)的struct_time，如果seconds参数未输入，则以当前时间为转换标准</p>
<p>6.localtime(…)<br>localtime([seconds]) -&gt; (tm_year,tm_mon,tm_day,tm_hour,tm_min,tm_sec,tm_wday,tm_yday,tm_isdst)<br>将一个时间戳转换成一个当前时区的struct_time，如果seconds参数未输入，则以当前时间为转换标准</p>
<p>7.mktime(…)<br>mktime(tuple) -&gt; floating point number<br>将一个以struct_time转换为时间戳</p>
<p>8.strftime(…)<br>strftime(format[, tuple]) -&gt; string<br>将指定的struct_time(默认为当前时间)，根据指定的格式化字符串输出<br>python中时间日期格式化符号：<br>%y 两位数的年份表示（00-99）<br>%Y 四位数的年份表示（000-9999）<br>%m 月份（01-12）<br>%d 月内中的一天（0-31）<br>%H 24小时制小时数（0-23）<br>%I 12小时制小时数（01-12）<br>%M 分钟数（00=59）<br>%S 秒（00-59）</p>
<p>%a 本地简化星期名称<br>%A 本地完整星期名称<br>%b 本地简化的月份名称<br>%B 本地完整的月份名称<br>%c 本地相应的日期表示和时间表示<br>%j 年内的一天（001-366）<br>%p 本地A.M.或P.M.的等价符<br>%U 一年中的星期数（00-53）星期天为星期的开始<br>%w 星期（0-6），星期天为星期的开始<br>%W 一年中的星期数（00-53）星期一为星期的开始<br>%x 本地相应的日期表示<br>%X 本地相应的时间表示<br>%Z 当前时区的名称<br>%% %号本身</p>
<p>9.strptime(…)<br>strptime(string, format) -&gt; struct_time<br>将时间字符串根据指定的格式化符转换成数组形式的时间<br>例如：<br>2009-03-20 11:45:39  对应的格式化字符串为：%Y-%m-%d %H:%M:%S<br>Sat Mar 28 22:24:24 2009 对应的格式化字符串为：%a %b %d %H:%M:%S %Y</p>
<p>10.time(…)<br>time() -&gt; floating point number<br>返回当前时间的时间戳</p>
<p>三、疑点<br>1.夏令时<br>在struct_time中，夏令时好像没有用，例如<br>a = (2009, 6, 28, 23, 8, 34, 5, 87, 1)<br>b = (2009, 6, 28, 23, 8, 34, 5, 87, 0)<br>a和b分别表示的是夏令时和标准时间，它们之间转换为时间戳应该相关3600，但是转换后输出都为646585714.0</p>
<p>四、小应用<br>1.python获取当前时间<br>time.time() 获取当前时间戳<br>time.localtime() 当前时间的struct_time形式<br>time.ctime() 当前时间的字符串形式</p>
<p>2.python格式化字符串<br>格式化成2009-03-20 11:45:39形式<br>time.strftime(“%Y-%m-%d %H:%M:%S”, time.localtime())</p>
<p>不加参数时，默认就是输出当前的时间<br>time.strftime(‘%Y-%m-%d %H:%M:%S’)</p>
<p>格式化成Sat Mar 28 22:24:24 2009形式<br>time.strftime(“%a %b %d %H:%M:%S %Y”, time.localtime())</p>
<p>3.将格式字符串转换为时间戳<br>a = “Sat Mar 28 22:24:24 2009”<br>b = time.mktime(time.strptime(a,”%a %b %d %H:%M:%S %Y”))</p>
<p>4.将时间字符串转换为时间元组struct_time<br>time.strptime(‘2015-09-16 10:27:36’,’%Y-%m-%d %H:%M:%S’)</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>一、简介</p>
<p>time模块提供各种操作时间的函数<br>说明：一般有两种表示时间的方式:<br>第一种是时间戳的方式(相对于1970.1.1 00:00:00以秒计算的偏移量),时间戳是惟一的<br>第二种以数组的形式表示即(struct_time),共有九个元素]]>
    </summary>
    
      <category term="Python" scheme="http://blog.suzf.net/tags/Python/"/>
    
      <category term="Python" scheme="http://blog.suzf.net/categories/Python/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[MySQLdb 参数处理的坑]]></title>
    <link href="http://blog.suzf.net/2016/02/29/MySQLdb_%E5%8F%82%E6%95%B0%E5%A4%84%E7%90%86%E7%9A%84%E5%9D%91/"/>
    <id>http://blog.suzf.net/2016/02/29/MySQLdb_参数处理的坑/</id>
    <published>2016-02-29T11:36:49.000Z</published>
    <updated>2016-03-31T05:38:36.000Z</updated>
    <content type="html"><![CDATA[<div class="entry-content">

<p>前几天又有同事掉进了给 SQL 的 IN 条件传参的坑，就像 SELECT col1, col2 FROM table1 WHERE id IN (1, 2, 3) 这类 SQL，如果是一个可变的列表作为 IN 的参数，那这个参数应该怎么传呢？</p>
<p>我见过至少这么几种：</p>
<p><pre class="lang:default decode:true">id_list = [1, 2, 3]<br>cursor.execute(‘SELECT col1, col2 FROM table1 WHERE id IN (%s)’, id_list)<br></pre><br>这种方式是语法错误的，原因是 MySQLdb 做字符串格式化时占位符和参数个数不匹配。</p>
<p><pre class="lang:default decode:true">id_list = [1, 2, 3]<br>cursor.execute(‘SELECT col1, col2 FROM table1 WHERE id IN (%s)’, (id_list,))<br></pre><br>这种方式语法是正确的，但语义是错误的，因为生成的 SQL 是 SELECT col1, col2 FROM table1 WHERE id IN ((‘1’, ‘2’, ‘3’))</p>
<p><pre class="lang:default decode:true">id_list = [1, 2, 3]<br>id_list = ‘,’.join([str(i) for i in id_list])<br>cursor.execute(‘SELECT col1, col2 FROM table1 WHERE id IN (%s)’, id_list)</pre><br>这种方式语义也是错误的，因为生成的 SQL 是 SELECT col1, col2 FROM table1 WHERE id IN (‘1,2,3’)</p>
<p>这三种是第一次使用 MySQLdb 给 IN 传参时犯的最多的错误，大多数人遇到第一种错和掉进后两个坑之后，转而采用了下面的方式：</p>
<p><pre class="lang:default decode:true">id_list = [1, 2, 3]<br>id_list = ‘,’.join([str(i) for i in id_list])<br>cursor.execute(‘SELECT col1, col2 FROM table1 WHERE id IN (%s)’ % id_list)<br></pre><br>这个方式对于可信的参数(比如自己生成的列表：<code>range(1, 10, 2)</code>)来说可以用，但由于参数未经 escape，对于从用户端接受的不可信参数来说，存在 SQL 注入的风险。</p>
<p>严防 SQL 注入的问题时刻都不能松懈，于是就有了这样的改进版本：</p>
<p><pre class="lang:default decode:true">id_list = [1, 2, 3]<br>id_list = ‘,’.join([str(cursor.connection.literal(i)) for i in id_list])<br>cursor.execute(‘SELECT col1, col2 FROM table1 WHERE id IN (%s)’ % id_list)<br></pre><br>这个方式控制了 SQL 注入问题的滋生，但由于 <code>cursor.connection.literal</code> 是内部接口，并不推荐从外部使用。</p>
<p>然后就有了这样的方式：</p>
<p><pre class="lang:default decode:true">id_list = [1, 2, 3]<br>arg_list = ‘,’.join([‘%s’] * len(id_list))<br>cursor.execute(‘SELECT col1, col2 FROM table1 WHERE id IN (%s)’ % arg_list, id_list)<br></pre><br>这个方式是先生成与参数个数相同的 %s 占位，拼出 ‘SELECT col1, col2 FROM table1 WHERE id IN (%s,%s,%s)’ 这样的 SQL，然后使用安全的方式来传参。</p>
<p>就是想传一个参数而已，怎么会这么麻烦呢？触令丧惨！</p>
<p><strong>更正：以下划线内容为未经充分测试的错误结论，仅做记录：</strong></p>
<p>一直以为 MySQLdb 是不支持给 IN 传参的，直到这次又有同事掉坑我才读了 MySQLdb escape 部分的代码，然后发现，MySQLdb 是在很多类型的 Python object 和 SQL 支持的类型之间做自动转换的，比如 MySQLdb 会对 list 和 tuple 内的元素逐个进行 escape，生成一个 tuple，因此这才是正确的给 IN 传参的方式：</p>
<p><pre class="lang:default decode:true">id_list = [1, 2, 3]<br>cursor.execute(‘SELECT col1, col2 FROM table1 WHERE id IN %s’, (id_list,))<br></pre><br>可以把 MySQLdb 处理参数的过程简化描述为：</p>
<ol>
<li>对参数 (id_list,) 做 escape 得到 ((‘1’, ‘2’, ‘3’),)</li>
<li>用 escape 过的参数对 SQL 进行格式化：’SELECT col1, col2 FROM table1 WHERE id IN %s’ % ((‘1’, ‘2’, ‘3’),)，得到完整 SQL：’SELECT col1, col2 FROM table1 WHERE id IN (‘1’, ‘2’, ‘3’)<br>整理一下口诀：IN 的参数和其他参数一样，是一个整体，就要不要对属于参数一部分的 <code>()</code> 念念不忘了……</li>
</ol>
<p>总结一下评论中对这个方法提出的问题：</p>
<ol>
<li>如果参数列表只有一个元素，比如 <code>cursor.execute(&#39;SELECT col1, col2 FROM table1 WHERE id IN %s&#39;, ([1],))</code>，生成的 SQL 是 <code>SELECT col1, col2 FROM table1 WHERE id IN (&#39;1&#39;,)</code>，是语法错误的</li>
<li>对列表内元素做 esacpe 时增加的引号会被留下，如果列表元素是字符串，结果会是错误的，比如 <code>cursor.execute(&#39;SELECT col1, col2 FROM table1 WHERE id IN %s&#39;, ([&quot;1&quot;, &quot;2&quot;],))</code> 生成的 SQL 是 <code>SELECT col1, col2 FROM table1 WHERE id IN (&quot;&#39;1&#39;&quot;, &quot;&#39;2&#39;&quot;)</code>，而对于数字参数恰好能正确工作的原因是，在执行 SQL 时如果列定义是 int 而传参为字符串，MySQL 会做隐式类型转换（<a href="http://dev.mysql.com/doc/refman/5.5/en/type-conversion.html" target="_blank" rel="external">Type Conversion in Expression Evaluation</a>）。<br>MySQLdb 支持对各种类型的 Python object 进行转换和 escape，感兴趣的同学可以看看 <code>MySQLdb.converters</code> 和 <code>_mysql.c</code> 中 <code>*_escape*</code> 系列的函数，另外 MySQLdb 也支持自定义转换规则，参见 <code>MySQLdb.connect</code> 的 <code>conv</code> 参数。</li>
</ol>
<p></p></div><br>来源: <a href="http://blog.xupeng.me/2013/09/25/mysqldb-args-processing/" target="_blank" rel="external"> 互联网</a><p></p>
]]></content>
    <summary type="html">
    <![CDATA[<div class="entry-content">

<p>前几天又有同事掉进了给 SQL 的 IN 条件传参的坑，就像 SELECT col1, col2 FROM table1 WHERE id IN (1, 2, 3) 这类 SQL，如果是一个可变的列表作为 IN 的参]]>
    </summary>
    
      <category term="Mysql" scheme="http://blog.suzf.net/tags/Mysql/"/>
    
      <category term="Python" scheme="http://blog.suzf.net/tags/Python/"/>
    
      <category term="Python" scheme="http://blog.suzf.net/categories/Python/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[LVS 负载均衡简述]]></title>
    <link href="http://blog.suzf.net/2016/02/28/LVS_%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%80%E8%BF%B0/"/>
    <id>http://blog.suzf.net/2016/02/28/LVS_负载均衡简述/</id>
    <published>2016-02-28T03:33:11.000Z</published>
    <updated>2016-03-31T05:38:36.000Z</updated>
    <content type="html"><![CDATA[<p>基础知识及一些要点<br>LVS 性能调优<br>工作模式<br>– 通过NAT实现虚拟服务器（VS/NAT）<br>– 通过IP隧道实现虚拟服务器（VS/TUN）<br>– 通过直接路由实现虚拟服务器（VS/DR）</p>
<p><strong>Load Balancer(负载均衡器)：</strong></p>
<p><strong>Load Balancer</strong>是整个集群系统的前端，负责把客户请求转发到Real Server上。Load Balancer通过Ldirectord监测各Real Server的健康状况。在Real Server不可用时把它从群中剔除，恢复时重新加入。<br><strong>Backup</strong>是备份Load Balancer，当Load Balancer不可用时接替它，成为实际的Load Balancer。</p>
<p><strong>Server Array(服务器群)：</strong></p>
<p><strong>Server Array</strong>是 一组运行实际应用服务的机器，比如WEB, Mail, FTP, DNS, Media等等。在实际应用中，Load Balancer和Backup也可以兼任Real Server的角色。以下的测试就是一台服务器既担任了LVSserver,同时也是realserver节点.</p>
<p><strong>Shared Storage(共享存储)：</strong></p>
<p><strong>Shared Storage</strong>为所有Real Server提供共享存储空间和一致的数据内容。<br><strong>Director</strong>: 前端负载均衡器即运行LVS服务可以针对web、ftp、cache、mms甚至mysql等服务做load balances。<br><strong>RealServer</strong>: 后端需要负载均衡的服务器，可以为各类系统，Linux、Solaris、Aix、BSD、Windows都可，甚至Director本身也可以作为 RealServer使用.<a id="more"></a></p>
<p><strong>LVS( Linux Virtual Server)</strong>,Linux下的负载均衡器，支持<strong>LVS-NAT、 LVS-DR、LVS-TUNL</strong>三种不同的方式</p>
<p><strong>nat</strong>用的不是很多，主要用的是DR、TUNL方式。</p>
<p><strong>DR</strong>方式适合所有的RealServer同一网段下，即接在同一个交换机上.</p>
<p><strong>TUNL</strong>方式就对于RealServer的位置可以任意了，完全可以跨地域、空间，只要系统支持Tunnel就可以,方便以后扩充的话直接Tunl方式即可</p>
<h2 id="u57FA_u7840_u77E5_u8BC6_u4ECB_u7ECD"><a href="#u57FA_u7840_u77E5_u8BC6_u4ECB_u7ECD" class="headerlink" title="基础知识介绍"></a>基础知识介绍</h2><p><strong>1、LVS基础及介绍</strong><br>LVS是Linux Virtual Server的简写，意即Linux虚拟服务器，是一个虚拟的服务器集群系统。本项目在1998年5月由<strong>章文嵩（目前就职于阿里）</strong>博士成立，是中国国内最早出现的自由软件项目之一。<br>目前有三种IP负载均衡技术（VS/NAT、VS/TUN和VS/DR）；</p>
<p>十种调度算法（rrr|wrr|lc|wlc|lblc|lblcr|dh|sh|sed|nq）<br>【参考资料:】<br>1)官方中文参考资料: <a href="http://www.linuxvirtualserver.org/zh/index.html" target="_blank" rel="external">http://www.linuxvirtualserver.org/zh/index.html</a></p>
<p>2)LinuxTone 相关LVS技术档汇总: <a href="http://bbs.linuxtone.org/thread-1191-1-1.html" target="_blank" rel="external">http://bbs.linuxtone.org/thread-1191-1-1.html</a></p>
<p><strong>2、 LVS 三种IP负载均衡技术对比</strong><br>三种IP负载均衡技术的优缺点归纳在下表中：</p>
<p><table class="t_table" cellspacing="0"></table></p>
<p><tbody></tbody></p>
<p><tr></tr></p>
<p><td width="175"></td></p>
<p><td>VS/NAT</td></p>
<p><td>VS/TUN</td></p>
<p><td>VS/DR</td><br></p>
<p><tr></tr></p>
<p><td width="175">Server</td></p>
<p><td>any</td></p>
<p><td>Tunneling</td></p>
<p><td>Non-arp device</td><br></p>
<p><tr></tr></p>
<p><td width="175">server network</td></p>
<p><td>private</td></p>
<p><td>LAN/WAN</td></p>
<p><td>LAN</td><br></p>
<p><tr></tr></p>
<p><td width="175">server number</td></p>
<p><td>low (10~20)</td></p>
<p><td>High (100)</td></p>
<p><td>High (100)</td><br></p>
<p><tr></tr></p>
<p><td>server gateway</td></p>
<p><td>load balancer</td></p>
<p><td width="140">own router</td></p>
<p><td>Own router</td><br><br><br><br>【注】 以上三种方法所能支持最大服务器数目的估计是假设调度器使用100M网卡，调度器的硬件配置与后端服务器的硬件配置相同，而且是对一般Web服务。使用更 高的硬件配置（如千兆网卡和更快的处理器）作为调度器，调度器所能调度的服务器数量会相应增加。当应用不同时，服务器的数目也会相应地改变。所以，以上数 据估计主要是为三种方法的伸缩性进行量化比较。</p>
<p><strong>3、LVS目前实现的几种调度算法</strong><br>IPVS 在内核中的负载均衡调度是以连接为粒度的。在HTTP协议（非持久）中，每个对象从WEB服务器上获取都需要建立一个TCP连接，同一用户的不同请求会被 调度到不同的服务器上，所以这种细粒度的调度在一定程度上可以避免单个用户访问的突发性引起服务器间的负载不平衡。<br>在内核中的连接调度算法上，IPVS已实现了以下十种调度算法：</p>
<ul>
<li>轮叫调度（Round-Robin Scheduling）</li>
<li><strong>加权轮叫调度（Weighted Round-Robin Scheduling）</strong></li>
<li>最小连接调度（Least-Connection Scheduling）</li>
<li>加权最小连接调度（Weighted Least-Connection Scheduling）</li>
<li>基于局部性的最少链接（Locality-Based Least Connections Scheduling）</li>
<li>带复制的基于局部性最少链接（Locality-Based Least Connections with Replication Scheduling）</li>
<li>目标地址散列调度（Destination Hashing Scheduling）</li>
<li>源地址散列调度（Source Hashing Scheduling）</li>
<li>最短预期延时调度（Shortest Expected Delay Scheduling）</li>
<li>不排队调度（Never Queue Scheduling）<br>对应: rr|wrr|lc|wlc|lblc|lblcr|dh|sh|sed|nq,</li>
</ul>
<p>Ldirecotrd配置选项及ipvsadm使用参数.</p>
<p><table class="t_table" cellspacing="0"></table></p>
<p><tbody></tbody></p>
<p><tr></tr></p>
<td>

<p>ldirectord配置选项</p>
<p></p></td><p></p>
<td width="156">

<p>ipvsadm使用的参数</p>
<p></p></td><p></p>
<td>

<p>ipvsadm -L的输出</p>
<p></p></td><p></p>
<td>

<p>LVS转发方法</p>
<p></p></td><br><p></p>
<p><tr></tr></p>
<td>

<p>gate</p>
<p></p></td><p></p>
<td width="156">

<p>-g</p>
<p></p></td><p></p>
<td>

<p>Route</p>
<p></p></td><p></p>
<td>

<p>LVS-DR</p>
<p></p></td><br><p></p>
<p><tr></tr></p>
<td>

<p>ipip</p>
<p></p></td><p></p>
<td width="156">

<p>-i</p>
<p></p></td><p></p>
<td>

<p>Tunnel</p>
<p></p></td><p></p>
<td>

<p>LVS-TUN</p>
<p></p></td><br><p></p>
<p><tr></tr></p>
<td>

<p>masq</p>
<p></p></td><p></p>
<td width="156">

<p>-m</p>
<p></p></td><p></p>
<td>

<p>Masq</p>
<p></p></td><p></p>
<td>

<p>LVS-NAT</p>
<p></p></td><br><br><br><br><strong>4、集群架构时我们应该采用什么样的调度算法?</strong><p></p>
<p>在一般的网络服务（如HTTP和Mail Service等）调度中，我会使用<strong>加权最小连接调度</strong>wlc或者<strong>加权轮叫调度wrr算法</strong>。<br>基于局部性的最少链接LBLC和带复制的基于局部性最少链接LBLCR主要适用于Web Cache集群。<br>目标地址散列调度和源地址散列调度是用静态映射方法，可能主要适合防火墙调度。<br>最短预期延时调度SED和不排队调度NQ主要是对处理时间相对比较长的网络服务。<br>其实，它们的适用范围不限于这些。我想最好参考内核中的连接调度算法的实现原理，看看那种调度方法适合你的应用。</p>
<p><strong>5、LVS的ARP问题</strong><br>2.4.x kernels:<br>Hidden Patch<br>arptable<br>iptables</p>
<p>2.6.x kernels: （关闭arp查询响应请求）<br>net.ipv4.conf.eth0.arp_ignore = 1<br>net.ipv4.conf.eth0.arp_announce = 2<br>net.ipv4.conf.all.arp_ignore = 1<br>net.ipv4.conf.all.arp_announce = 2<br>arping tools</p>
<h2 id="u4E8C_u3001_u57FA_u7840_u77E5_u8BC6_u53CA_u4E00_u4E9B_u8981_u70B9"><a href="#u4E8C_u3001_u57FA_u7840_u77E5_u8BC6_u53CA_u4E00_u4E9B_u8981_u70B9" class="headerlink" title="二、基础知识及一些要点"></a>二、基础知识及一些要点</h2><p>1、InActConn并不代表错误连接，它是指不活跃连接(Inactive Connections)，<br>我们将处于TCP ESTABLISH状态以外的连接都称为不活跃连接，例如处于SYN_RECV状态的连接，处于TIME_WAIT状态的连接等。</p>
<p>2、用四个参数来<strong>关闭arp查询响应请求</strong>：<br>echo 1 &gt; /proc/sys/net/ipv4/conf/lo/arp_ignore<br>echo 2 &gt; /proc/sys/net/ipv4/conf/lo/arp_announce<br>echo 1 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore<br>echo 2 &gt; /proc/sys/net/ipv4/conf/all/arp_announce</p>
<p>3、ipvsadm -L -n –stats<br>Prot LocalAddress:Port Conns InPkts OutPkts InBytes OutBytes<br>连接数 输入包 输出包 输入流量 输出流量</p>
<p>4、注意事项:<br>1）在LVS方案中，虚拟ip地址与普通网络接口大大不同，这点需要特别注意。<br>虚拟ip地址的广播地址是它本身，子网掩码是255.255.255.255。 为什么要这样呢？因为有若干机器要使用同一个ip地址，<br>用本身做广播地址和把子网掩码设成4个255就不会造成ip地址冲突了,否则lvs将不能正常转发访问请求。</p>
<p>2） 假如两台VS之间使用的互备关系，那么当一台VS接管LVS服务时，可能会网络不通，这时因为路由器的MAC缓存表里关于vip这个地址的MAC地 址还是被替换的VS的MAC，有两种解决方法，一种是修改新VS的MAC地址，另一种是使用send_arp 命令（piranha软件包里带的一个小工具） 格式如下：<br>send_arp:<br>send_arp [-i dev] src_ip_addr src_hw_addr targ_ip_addr tar_hw_addr<br>这个命令不一定非要在VS上执行，只+要在同一VLAN即可。<br>/sbin/arping -f -q -c 5 -w 5 -I eth0 -s <span id="MathJax-Element-1-Frame" class="MathJax"><span id="MathJax-Span-1" class="math"><span id="MathJax-Span-2" class="mrow"><span id="MathJax-Span-3" class="mi">W</span><span id="MathJax-Span-4" class="mi">E</span><span id="MathJax-Span-5" class="msubsup"><span id="MathJax-Span-6" class="mi">B</span><span id="MathJax-Span-7" class="mi">V</span></span><span id="MathJax-Span-8" class="mi">I</span><span id="MathJax-Span-9" class="mi">P</span><span id="MathJax-Span-10" class="mo">−</span><span id="MathJax-Span-11" class="mi">U</span></span></span></span>GW</p>
<p>5.Virtual Server via Direct Routing（VS/DR）<br>VS/DR 通过改写请求报文的MAC地址，将请求发送到真实服务器，而真实服务器将响应直接返回给客户。同VS/TUN技术一样，VS/DR技术可极大地提高集群系 统的伸缩性。这种方法没有IP隧道的开销，对集群中的真实服务器也没有必须支持IP隧道协议的要求，但是要求调度器与真实服务器都有一块网卡连在同一物理 网段上。</p>
<p><strong>6. LVS 经验:</strong><br>1). LVS调度的最小单位是“连接”。<br>2). 当apache的KeepAlive被设置成Off时，“连接”才能被较均衡的调度。<br>3). 在不指定-p参数时，LVS才真正以“连接”为单位按“权值”调度流量。<br>4). 在指定了-p参数时，则一个client在一定时间内，将会被调度到同一台RS。<br>5). 可以通过”ipvsadm ?set tcp tcpfin udp”来调整TCP和UDP的超时，让连接淘汰得快一些。<br>6). 在NAT模式时，RS的PORT参数才有意义。<br>7). DR和TUN模式时，InActConn 是没有意义的(Thus the count in the InActConn column for LVS-DR, LVS-Tun is<br>inferred rather than real.)<br>/sbin/arping -f -q -c 5 -w 5 -I eth0 -s <span id="MathJax-Element-2-Frame" class="MathJax"><span id="MathJax-Span-12" class="math"><span id="MathJax-Span-13" class="mrow"><span id="MathJax-Span-14" class="mi">W</span><span id="MathJax-Span-15" class="mi">E</span><span id="MathJax-Span-16" class="msubsup"><span id="MathJax-Span-17" class="mi">B</span><span id="MathJax-Span-18" class="mi">V</span></span><span id="MathJax-Span-19" class="mi">I</span><span id="MathJax-Span-20" class="mi">P</span><span id="MathJax-Span-21" class="mo">−</span><span id="MathJax-Span-22" class="mi">U</span></span></span></span>GW</p>
<h2 id="u4E09_u3001LVS__u6027_u80FD_u8C03_u4F18"><a href="#u4E09_u3001LVS__u6027_u80FD_u8C03_u4F18" class="headerlink" title="三、LVS 性能调优"></a>三、LVS 性能调优</h2><p>Least services in System or Compile kernel.</p>
<p>Performace Tuning base LVS:<br>LVS self tuning( ipvsadm Timeout (tcp tcpfin udp)).<br>ipvsadm -Ln –timeout<br>Timeout (tcp tcpfin udp): 900 120 300<br>ipvsadm –set tcp tcpfin udp</p>
<p>Improving TCP/IP performance<br>net.ipv4.tcp_tw_recyle=1<br>net.ipv4.tcp_tw_reuse=1<br>net.ipv4.tcp_max_syn_backlog=8192<br>net.ipv4.tcp_keepalive_time=1800<br>net.ipv4.tcp_fin_timeout=30<br>net.core.rmem_max=16777216<br>net.core.wmem_max=16777216<br>net.ipv4.tcp_rmem=4096 87380 16777216<br>net.ipv4.tcp_wmem=4096 65536 16777216<br>net.core.netdev_max_backlog=3000</p>
<h2 id="1__u901A_u8FC7NAT_u5B9E_u73B0_u865A_u62DF_u670D_u52A1_u5668_uFF08VS/NAT_uFF09"><a href="#1__u901A_u8FC7NAT_u5B9E_u73B0_u865A_u62DF_u670D_u52A1_u5668_uFF08VS/NAT_uFF09" class="headerlink" title="1 通过NAT实现虚拟服务器（VS/NAT）"></a><strong>1 通过NAT实现虚拟服务器（VS/NAT）</strong></h2><div><br><div>　　NAT的工作原理是报文头（目标地址、源地址和端口等）被正确改写后，客户相信它们连接一个IP地址，而不同IP地址的服务器组也认为它们是与客户直接相连的。</div><br></div><br><div><br><div>　　可以用NAT方法将不同IP地址的并行网络服务变成在一个IP地址上的一个虚拟服务。</div><br></div><br><div><br><div>　 　客户通过Virtual IP Address（虚拟服务的IP地址）访问网络服务时，请求报文到达调度器，调度器根据连接调度算法从一组真实服务器中选出一台服务器，将报文的目标地址 Virtual IP Address改写成选定服务器的地址，报文的目标端口改写成选定服务器的相应端口，最后将修改后的报文发送给选出的服务器。同时，调度器在连接Hash 表中记录这个连接，当这个连接的下一个报文到达时，从连接Hash表中可以得到原选定服务器的地址和端口，进行同样的改写操作，并将报文传给原选定的服务 器。当来自真实服务器的响应报文经过调度器时，调度器将报文的源地址和源端口改为Virtual IP Address和相应的端口，再把报文发给用户。</div><br></div><br><div><br><div>　 　在连接上引入一个状态机，不同的报文会使得连接处于不同的状态，不同的状态有不同的超时值。在TCP连接中，根据标准的TCP有限状态机进行状态迁移； 在UDP中，我们只设置一个UDP状态。不同状态的超时值是可以设置的，在缺省情况下，SYN状态的超时为1分钟，ESTABLISHED状态的超时为 15分钟，FIN状态的超时为1分钟；UDP状态的超时为5分钟。当连接终止或超时，调度器将这个连接从连接Hash表中删除。</div><br><div></div><br></div>

<h2 id="2__u901A_u8FC7IP_u96A7_u9053_u5B9E_u73B0_u865A_u62DF_u670D_u52A1_u5668_uFF08VS/TUN_uFF09"><a href="#2__u901A_u8FC7IP_u96A7_u9053_u5B9E_u73B0_u865A_u62DF_u670D_u52A1_u5668_uFF08VS/TUN_uFF09" class="headerlink" title="2 通过IP隧道实现虚拟服务器（VS/TUN）"></a><strong>2 通过IP隧道实现虚拟服务器（VS/TUN）</strong></h2><div><br><div>　　大多数Internet服务都有这样的特点：请求报文较短而响应报文往往包含大量的数据。如果能将请求和响应分开处理，即在负载调度器中只负责调度请求而响应直接返回给客户，将极大地提高整个集群系统的吞吐量。</div><br></div><br><div><br><div>　 　调度器根据各个服务器的负载情况，动态地选择一台服务器，将请求报文封装在另一个IP报文中，再将封装后的IP报文转发给选出的服务器；服务器收到报文 后，先将报文解封获得原来目标地址为VIP的报文，服务器发现VIP地址被配置在本地的IP隧道设备上，所以就处理这个请求，然后根据路由表将响应报文直 接返回给客户。</div><br></div><br><div><br><div>　　响应报文根据服务器的路由表直接返回给客户，而不经过负载调度器，所以负载调度器只处于从客户到服务器的半连接中</div><br><div></div><br></div>

<h2 id="3__u901A_u8FC7_u76F4_u63A5_u8DEF_u7531_u5B9E_u73B0_u865A_u62DF_u670D_u52A1_u5668_uFF08VS/DR_uFF09"><a href="#3__u901A_u8FC7_u76F4_u63A5_u8DEF_u7531_u5B9E_u73B0_u865A_u62DF_u670D_u52A1_u5668_uFF08VS/DR_uFF09" class="headerlink" title="3 通过直接路由实现虚拟服务器（VS/DR）"></a><strong>3 通过直接路由实现虚拟服务器（VS/DR）</strong></h2><div><br><div>　　VS/DR利用大多数Internet服务的非对称特点，负载调度器中只负责调度请求，而服务器直接将响应返回给客户，可以极大地提高整个集群系统的吞吐量</div><br></div><br><div><br><div>　　在VS/DR中，调度器根据各个服务器的负载情况，动态地选择一台服务器，不修改也不封装IP报文，而是将数据帧的MAC地址改为选出服务器的MAC地址， 再将修改后的数据帧在与服务器组的局域网上发送。因为数据帧的MAC地址是选出的服务器，所以服务器肯定可以收到这个数据帧，从中可以获得该IP报文。当 服务器发现报文的目标地址VIP是在本地的网络设备上，服务器处理这个报文，然后根据路由表将响应报文直接返回给客户。</div><br></div><br><div><br><table class="ynote_table" border="1" cellspacing="0" cellpadding="2"><br><tbody><br><tr><br><td valign="top"></td><br><td valign="top"><br><div>VS/NAT</div></td><br><td valign="top"><br><div>VS/TUN</div></td><br><td valign="top"><br><div> VS/DR</div></td><br></tr><br><tr><br><td valign="top"><br><div>Server</div></td><br><td valign="top"><br><div>any</div></td><br><td valign="top"><br><div>Tuneling</div></td><br><td valign="top"><br><div>Non-arp device</div></td><br></tr><br><tr><br><td valign="top"><br><div>server number</div></td><br><td valign="top"><br><div>low10-20</div></td><br><td valign="top"><br><div>high100</div></td><br><td valign="top"><br><div>high100</div></td><br></tr><br><tr><br><td valign="top"><br><div>server gateway</div></td><br><td valign="top"><br><div>loadbalancer</div></td><br><td valign="top"><br><div>own router</div></td><br><td valign="top"><br><div>own router</div></td><br></tr><br><tr><br><td valign="top"><br><div>server network</div></td><br><td valign="top"><br><div>private</div></td><br><td valign="top"><br><div>lan/wan</div></td><br><td valign="top"><br><div>lan</div></td><br></tr><br></tbody><br></table><br></div><br><div><strong>NAT </strong></div><br><div>    当服务器数目变多时，调度器成为瓶颈</div><br><div><strong>IP Tuneling </strong></div><br><div>    术对服务器有要求，即所有的服务器必须支持“IP Tunneling”者“IPEncapsulation ”协议</div><br><div><strong>DR </strong></div><br><div>    跟VS/TUN相比，这种方法没有IP隧道的开销，但是要求负载调度器与实际服务器都有一块网卡连在同一物理网段上，服务器网络设备（或者设备别名）不作ARP响应，或者能将报文重定向（Redirect）到本地的Socket端口上。</div><br><div></div><br><div>来源:  <a href="http://www.cnblogs.com/xing901022/p/3977647.html" target="_blank" rel="external">互联网</a></div><br><div></div>]]></content>
    <summary type="html">
    <![CDATA[<p>基础知识及一些要点<br>LVS 性能调优<br>工作模式<br>– 通过NAT实现虚拟服务器（VS/NAT）<br>– 通过IP隧道实现虚拟服务器（VS/TUN）<br>– 通过直接路由实现虚拟服务器（VS/DR）</p>
<p><strong>Load Balancer(负载均衡器)：</strong></p>
<p><strong>Load Balancer</strong>是整个集群系统的前端，负责把客户请求转发到Real Server上。Load Balancer通过Ldirectord监测各Real Server的健康状况。在Real Server不可用时把它从群中剔除，恢复时重新加入。<br><strong>Backup</strong>是备份Load Balancer，当Load Balancer不可用时接替它，成为实际的Load Balancer。</p>
<p><strong>Server Array(服务器群)：</strong></p>
<p><strong>Server Array</strong>是 一组运行实际应用服务的机器，比如WEB, Mail, FTP, DNS, Media等等。在实际应用中，Load Balancer和Backup也可以兼任Real Server的角色。以下的测试就是一台服务器既担任了LVSserver,同时也是realserver节点.</p>
<p><strong>Shared Storage(共享存储)：</strong></p>
<p><strong>Shared Storage</strong>为所有Real Server提供共享存储空间和一致的数据内容。<br><strong>Director</strong>: 前端负载均衡器即运行LVS服务可以针对web、ftp、cache、mms甚至mysql等服务做load balances。<br><strong>RealServer</strong>: 后端需要负载均衡的服务器，可以为各类系统，Linux、Solaris、Aix、BSD、Windows都可，甚至Director本身也可以作为 RealServer使用.]]>
    
    </summary>
    
      <category term="LB" scheme="http://blog.suzf.net/tags/LB/"/>
    
      <category term="LVS" scheme="http://blog.suzf.net/tags/LVS/"/>
    
      <category term="LVS" scheme="http://blog.suzf.net/categories/LVS/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[How to limit Flask dev server to only one visiting ip address]]></title>
    <link href="http://blog.suzf.net/2016/02/23/How_to_limit_Flask_dev_server_to_only_one_visiting_ip_address/"/>
    <id>http://blog.suzf.net/2016/02/23/How_to_limit_Flask_dev_server_to_only_one_visiting_ip_address/</id>
    <published>2016-02-23T06:41:28.000Z</published>
    <updated>2016-03-31T05:38:36.000Z</updated>
    <content type="html"><![CDATA[<div class="post-text">

<p>I’m developing a website using the Python <a href="http://flask.pocoo.org/" target="_blank" rel="external">Flask framework</a> and I now do some devving, pushing my changes to a remote dev server. I set this remote dev server up to serve the website publically using <code>app.run(host=&#39;0.0.0.0&#39;)</code>.</p>
<p>This works fine, but I just don’t want other people to view my website yet. For this reason I somehow want to whitelist my ip so that the dev server only serves the website to my own ip address, giving no response, 404’s or some other non-useful response to other ip addresses. I can of course set up the server to use apache or nginx to actually serve the website, but I like the automatic reloading of the website on code changes for devving my website</p>
<p>So does anybody know of a way to do this using the built in Flask dev server? All tips are welcome!</p>
<p></p></div><p></p>
<div class="post-text">

<p>Using <em>just</em> the features of Flask, you could use a <a href="https://flask.readthedocs.org/en/latest/api/#flask.Flask.before_request" target="_blank" rel="external"><code>before_request()</code> hook</a> testing the <a href="http://werkzeug.pocoo.org/docs/wrappers/#werkzeug.wrappers.BaseRequest.remote_addr" target="_blank" rel="external"><code>request.remote_addr</code> attribute</a>:</p>
<p><pre class="lang:default decode:true">from flask import abort, request</pre></p>
<p>@app.before_request<br>def limit_remote_addr():<br>    if request.remote_addr != ‘10.20.30.40’:<br>        abort(403)  # Forbidden<br>but using a firewall rule on the server is probably the safer and more robust option.</p>
<p>Note that the Remote_Addr can be masked if there is a reverse proxy in between the browser and your server; be careful how you limit this and don’t lock yourself out. If the proxy lives close to the server itself (like a load balancer or front-end cache), you can inspect the <a href="http://werkzeug.pocoo.org/docs/wrappers/#werkzeug.wrappers.BaseRequest.access_route" target="_blank" rel="external"><code>request.access_route</code> list</a> to access the actual IP address. _Do this only if <code>remote_addr</code> itself is a trusted IP address too_:</p>
<p><pre class="lang:default decode:true">trusted_proxies = (‘42.42.42.42’, ‘82.42.82.42’, ‘127.0.0.1’)</pre></p>
<p>def limit_remote_addr():<br>    remote = request.remote_addr<br>    route = list(request.access_route)<br>    while remote in trusted_proxies:<br>        remote = route.pop()</p>
<pre><code>if remote != &apos;10.20.30.40&apos;:
    abort(403)  # Forbidden&lt;/pre&gt;
</code></pre><p></p></div><br>来源： <a href="http://stackoverflow.com/questions/22251038/how-to-limit-flask-dev-server-to-only-one-visiting-ip-address" target="_blank" rel="external">stackoverflow</a><p></p>
]]></content>
    <summary type="html">
    <![CDATA[<div class="post-text">

<p>I’m developing a website using the Python <a href="http://flask.pocoo.org/" target="_blank" rel="external">Flask]]>
    </summary>
    
      <category term="Flask" scheme="http://blog.suzf.net/tags/Flask/"/>
    
      <category term="Python" scheme="http://blog.suzf.net/tags/Python/"/>
    
      <category term="Python" scheme="http://blog.suzf.net/categories/Python/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Shell 正则表达式]]></title>
    <link href="http://blog.suzf.net/2016/02/21/Shell_%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"/>
    <id>http://blog.suzf.net/2016/02/21/Shell_正则表达式/</id>
    <published>2016-02-21T09:53:41.000Z</published>
    <updated>2016-03-31T05:38:36.000Z</updated>
    <content type="html"><![CDATA[<div class="title"><br><br>## 正则表达式的分类<br><br>1.  基本的正则表达式（Basic Regular Expression 又叫Basic RegEx 简称BREs）<br>2.  扩展的正则表达式（Extended Regular Expression 又叫Extended RegEx 简称EREs）<br>3.  Perl的正则表达式（Perl Regular Expression 又叫Perl RegEx 简称PREs）<br></div><br><div class="title"><br><br>## 基本组成部分<br><br>正则表达式的基本组成部分。<br><br><a href="http://suzf.net/wp-content/uploads/2016/02/Re_2016-03-12T02-09-32.504Z.png" target="_blank" rel="external"><img src="http://suzf.net/wp-content/uploads/2016/02/Re_2016-03-12T02-09-32.504Z.png" alt="Re_2016-03-12T02-09-32.504Z"></a><br><br>&nbsp;<br><br></div><br><div class="title"><br><br>## POSIX字符类<br><br>POSIX字符类是一个形如[:…:]的特殊元序列（meta sequence），他可以用于匹配特定的字符范围。<br><br><a href="http://suzf.net/wp-content/uploads/2016/02/Re_2016-03-12T02-10-24.294Z.png" target="_blank" rel="external"><img src="http://suzf.net/wp-content/uploads/2016/02/Re_2016-03-12T02-10-24.294Z.png" alt="Re_2016-03-12T02-10-24.294Z"></a><br><br></div><br><div class="title"><br><br>## 元字符<br><br>元字符（meta character）是一种Perl风格的正则表达式，只有一部分文本处理工具支持它，并不是所有的文本处理工具都支持。<br><br><a href="http://suzf.net/wp-content/uploads/2016/02/Re_2016-03-12T02-10-44.117Z.png" target="_blank" rel="external"><img src="http://suzf.net/wp-content/uploads/2016/02/Re_2016-03-12T02-10-44.117Z.png" alt="Re_2016-03-12T02-10-44.117Z"></a><br><br></div><br>&nbsp;<br><div class="title"></div>]]></content>
    <summary type="html">
    <![CDATA[<div class="title"><br><br>## 正则表达式的分类<br><br>1.  基本的正则表达式（Basic Regular Expression 又叫Basic RegEx 简称BREs）<br>2.  扩展的正则表达式（Extended Regular E]]>
    </summary>
    
      <category term="Re" scheme="http://blog.suzf.net/tags/Re/"/>
    
      <category term="Shell" scheme="http://blog.suzf.net/categories/Shell/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Linux 下 僵尸进程与D进程]]></title>
    <link href="http://blog.suzf.net/2016/02/11/Linux_%E4%B8%8B_%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8B%E4%B8%8ED%E8%BF%9B%E7%A8%8B/"/>
    <id>http://blog.suzf.net/2016/02/11/Linux_下_僵尸进程与D进程/</id>
    <published>2016-02-11T09:43:59.000Z</published>
    <updated>2016-03-31T05:38:36.000Z</updated>
    <content type="html"><![CDATA[<p>————- 1 关于ZOMBIE进程：</p>
<h1 id="ps_-el_7C_grep_Z"><a href="#ps_-el_7C_grep_Z" class="headerlink" title="ps -el| grep Z"></a>ps -el| grep Z</h1><p>F S   UID   PID  PPID  C PRI  NI ADDR SZ WCHAN  TTY          TIME CMD<br>0 Z     0  3288  3278  0  80   0 -     0 exit   ?        00:00:00 sh &lt;defunct&gt;<br>0 Z     0  7289  7282  0  80   0 -     0 exit   ?        00:00:00 sh &lt;defunct&gt;<br>0 Z     0  9862  9856  0  80   0 -     0 exit   ?        00:00:00 sh &lt;defunct&gt;</p>
<h1 id="ps_-ef__7Cgrep_defunct"><a href="#ps_-ef__7Cgrep_defunct" class="headerlink" title="ps -ef |grep defunct"></a>ps -ef |grep defunct</h1><p>root      3288  3278  0 Feb19 ?        00:00:00 [sh] &lt;defunct&gt;<br>root      3789  1710  0 17:05 pts/8    00:00:00 grep defunct<br>root      7289  7282  0 07:11 ?        00:00:00 [sh] &lt;defunct&gt;<br>root      9862  9856  0 Feb26 ?        00:00:00 [sh] &lt;defunct&gt;</p>
<p>这些进程已经死亡，但没有释放系统资源，包括内存和一些一些系统表等， 如果这样的进程很多，会引发系统问题。用ps -el看出的进程状态如果是Z，就是僵尸进程。</p>
<p>Z 之所以杀不死，是因为它已经死了，否则怎么叫 Zombie（僵尸）呢？冤魂不散，自然是生前有结未解之故。在UNIX/Linux中，每个进程都有一个父进程，进程号叫PID（Process ID），相应地，父进程号就叫PPID（Parent PID）。当进程死亡时，它会自动关闭已打开的文件，舍弃已占用的内存、交换空间等等系统资源，然后向其父进程返回一个退出状态值，报告死讯。如果程序有 bug，就会在这最后一步出问题。儿子说我死了，老子却没听见，没有及时收棺入殓，儿子便成了僵尸。在UNIX/Linux中消灭僵尸的手段比较残忍，执 行 ps axjf 找出僵尸进程的父进程号（PPID，第一列），先杀其父，然后再由进程天子 init（其PID为1，PPID为0）来一起收拾父子僵尸，超度亡魂，往生极乐。注意，子进程变成僵尸只是碍眼而已，并不碍事，如果僵尸的父进程当前有 要务在身，则千万不可贸然杀之。</p>
<p>清除ZOMBIE（僵尸）进程可以使用如下方法：<br>1&gt; kill –18 PPID （PPID是其父进程）<br>这个信号是告诉父进程，该子进程已经死亡了，请收回分配给他的资源。<br>2&gt;如 果不行则看能否终止其父进程（如果其父进程不需要的话）。先看其父进程又无其他子进程，如果有，可能需要先kill其他子进程，也就是兄弟进程。方法是：<br>kill –15 PID1 PID2(PID1,PID2是僵尸进程的父进程的其它子进程)。<br>然后再kill父进程：kill –15 PPID<br>这 样僵尸进程就可能被完全杀掉了。</p>
<p>ps alx | grep 17191<br>lsof   -p 进程ID<br>pstree -p 进程ID<br>ps     -p 进程ID</p>
<p>详细信息查看：<br>/proc/[PID]/stat</p>
<h1 id="cat_/proc/6873/stat"><a href="#cat_/proc/6873/stat" class="headerlink" title="cat /proc/6873/stat"></a>cat /proc/6873/stat</h1><p>6873 (a.out) R 6723 6873 6723 34819 6873 8388608 77 0 0 0 41958 31 0 0 25 0 3 0 5882654 1409024 56 4294967295 134512640 134513720 3215579040 0 2097798 0 0 0 0 0 0 0 17 0 0 0 [root@localhost ~]#</p>
<p>每个参数意思为：<br>参数 解释<br>pid=6873 进程(包括轻量级进程，即线程)号<br>comm=a.out 应用程序或命令的名字<br>task_state=R 任务的状态，R:runnign, S:sleeping (TASK_INTERRUPTIBLE), D:disk sleep (TASK_UNINTERRUPTIBLE), T: stopped, T:tracing stop,Z:zombie, X:dead<br>ppid=6723 父进程ID<br>pgid=6873 线程组号<br>sid=6723 c该任务所在的会话组ID<br>tty_nr=34819(pts/3) 该任务的tty终端的设备号，INT（34817/256）=主设备号，（34817-主设备号）=次设备号<br>tty_pgrp=6873 终端的进程组号，当前运行在该任务所在终端的前台任务(包括shell 应用程序)的PID。<br>task-&gt;flags=8388608 进程标志位，查看该任务的特性<br>min_flt=77 该任务不需要从硬盘拷数据而发生的缺页（次缺页）的次数<br>cmin_flt=0 累计的该任务的所有的waited-for进程曾经发生的次缺页的次数目<br>maj_flt=0 该任务需要从硬盘拷数据而发生的缺页（主缺页）的次数<br>cmaj_flt=0 累计的该任务的所有的waited-for进程曾经发生的主缺页的次数目<br>utime=1587 该任务在用户态运行的时间，单位为jiffies<br>stime=1 该任务在核心态运行的时间，单位为jiffies<br>cutime=0 累计的该任务的所有的waited-for进程曾经在用户态运行的时间，单位为jiffies<br>cstime=0 累计的该任务的所有的waited-for进程曾经在核心态运行的时间，单位为jiffies<br>priority=25 任务的动态优先级<br>nice=0 任务的静态优先级<br>num_threads=3 该任务所在的线程组里线程的个数<br>it_realvalue=0 由于计时间隔导致的下一个 SIGALRM 发送进程的时延，以 jiffy 为单位.<br>start_time=5882654 该任务启动的时间，单位为jiffies<br>vsize=1409024（page） 该任务的虚拟地址空间大小<br>rss=56(page) 该任务当前驻留物理地址空间的大小<br>Number of pages the process has in real memory,minu 3 for administrative purpose.<br>这些页可能用于代码，数据和栈。<br>rlim=4294967295（bytes） 该任务能驻留物理地址空间的最大值<br>start_code=134512640 该任务在虚拟地址空间的代码段的起始地址<br>end_code=134513720 该任务在虚拟地址空间的代码段的结束地址<br>start_stack=3215579040 该任务在虚拟地址空间的栈的结束地址<br>kstkesp=0 esp(32 位堆栈指针) 的当前值, 与在进程的内核堆栈页得到的一致.<br>kstkeip=2097798 指向将要执行的指令的指针, EIP(32 位指令指针)的当前值.<br>pendingsig=0 待处理信号的位图，记录发送给进程的普通信号<br>block_sig=0 阻塞信号的位图<br>sigign=0 忽略的信号的位图<br>sigcatch=082985 被俘获的信号的位图<br>wchan=0 如果该进程是睡眠状态，该值给出调度的调用点<br>nswap 被swapped的页数，当前没用<br>cnswap 所有子进程被swapped的页数的和，当前没用<br>exit_signal=17 该进程结束时，向父进程所发送的信号<br>task_cpu(task)=0 运行在哪个CPU上<br>task_rt_priority=0 实时进程的相对优先级别<br>task_policy=0 进程的调度策略，0=非实时进程，1=FIFO实时进程；2=RR实时进程</p>
<p>这类进程是有问题的. 需要回收资源.<br>在unix程序设计的一本书里印像有一种情况会出现这样的进程.<br>主程序fork出的子进程结束之后. 父进程没有释放子进程所占用的资源. 这时这个进程就一直是zombie状态.</p>
<p>—- 百科：<br>ZOMBIE：僵尸状态，表示进程结束但尚未消亡的一种状态，此时进程已经结束运行并释放大部分资源，但尚未释放进程控制块。<br>与ZOMBIE对应的进程状态还有RUNNING（正在运行或等待运行状态），UNINTERRUPTABLE（不可中断阻塞状态），INTERRUPTABLE（可中断阻塞状态），STOPPED（挂起状态）。</p>
<p>服务器通常都会带来一些僵尸进程，占用系统资源，浪费资源等，一般我们使用top命令就可以看得出来，如图：<br>（可以看到，我的服务器已经产生了两个僵尸进程）</p>
<p>解决方法：</p>
<p>#ps -A -o stat,ppid,pid,cmd |grep -e “^[Zz]”　　　　//先查看具体进程：</p>
<p>#lsof -p ppid;</p>
<p>#lsof -p pid;</p>
<p>#kill -9 pid号　　　　　　　　　//杀死z进程（这些动作是比较危险的，希望在真正的服务器上面慎用！！！）</p>
<p>假若你的z进程比较多，可以编写个小小的脚本，下面是参与网上的</p>
<p>#ps -A -o stat,ppid,pid,cmd | grep -e ‘^[Zz]’ | awk ‘{print $2}’ | xargs kill</p>
<p>首先，我们可以用top命令来查看服务器当前是否有僵尸进程，可以看到第二行行尾有个 0 zombie，如果数字大于0，那么意味着服务器当前存在有僵尸进程  可以用ps和grep命令寻找僵尸进程</p>
<p>ps -A -ostat,ppid,pid,cmd | grep -e ‘^[Zz]’</p>
<p>命令选项说明:</p>
<p>-A 参数列出所有进程<br>-o 自定义输出字段 我们设定显示字段为 stat（状态）, ppid（进程父id）, pid(进程id)，cmd（命令）这四个参数<br>因为状态为 z或者Z的进程为僵尸进程，所以我们使用grep抓取stat状态为zZ进程</p>
<p>运行结果参考如下<br>Z 12334 12339 /path/cmd<br>这时，我们可以使用 kill -HUP 12339来杀掉这个僵尸进程<br>运行后，可以再次运行ps -A -ostat,ppid,pid,cmd | grep -e ‘^[Zz]’来确认是否将僵尸进程杀死<br>如果kill 子进程的无效，可以尝试kill 其父进程来解决问题，例如上面例子父进程pid是 12334，那么我们就运行<br>kill -HUP 12334来解决问题</p>
<hr>
<p>1) 检查当前僵尸进程信息</p>
<h1 id="ps_-ef__7C_grep_defunct__7C_grep_-v_grep__7C_wc_-l"><a href="#ps_-ef__7C_grep_defunct__7C_grep_-v_grep__7C_wc_-l" class="headerlink" title="ps -ef | grep defunct | grep -v grep | wc -l"></a>ps -ef | grep defunct | grep -v grep | wc -l</h1><p>175</p>
<h1 id="top__7C_head_-2"><a href="#top__7C_head_-2" class="headerlink" title="top | head -2"></a>top | head -2</h1><p>top - 15:05:54 up 97 days, 23:49, 4 users, load average: 0.66, 0.45, 0.39</p>
<p>Tasks: 829 total, 1 running, 479 sleeping, 174 stopped, 175 zombie</p>
<h1 id="ps_-ef__7C_grep_defunct__7C_grep_-v_grep"><a href="#ps_-ef__7C_grep_defunct__7C_grep_-v_grep" class="headerlink" title="ps -ef | grep defunct | grep -v grep"></a>ps -ef | grep defunct | grep -v grep</h1><p>2) 获得杀僵尸进程语句</p>
<h1 id="ps_-ef__7C_grep_defunct__7C_grep_-v_grep__7C_awk__u2018_7Bprint__u201Ckill_-9__u201C__242_2C_243_7D_u2019"><a href="#ps_-ef__7C_grep_defunct__7C_grep_-v_grep__7C_awk__u2018_7Bprint__u201Ckill_-9__u201C__242_2C_243_7D_u2019" class="headerlink" title="ps -ef | grep defunct | grep -v grep | awk ‘{print “kill -9 “ $2,$3}’"></a>ps -ef | grep defunct | grep -v grep | awk ‘{print “kill -9 “ $2,$3}’</h1><p>执行上面获得的语句即可, 使用信号量9, 僵尸进程数会大大减少.</p>
<p>3) 过一会儿检查当前僵尸进程信息</p>
<h1 id="ps_-ef__7C_grep_defunct__7C_grep_-v_grep__7C_wc_-l-1"><a href="#ps_-ef__7C_grep_defunct__7C_grep_-v_grep__7C_wc_-l-1" class="headerlink" title="ps -ef | grep defunct | grep -v grep | wc -l"></a>ps -ef | grep defunct | grep -v grep | wc -l</h1><p>125</p>
<h1 id="top__7C_head_-2-1"><a href="#top__7C_head_-2-1" class="headerlink" title="top | head -2"></a>top | head -2</h1><p>top - 15:29:26 up 98 days, 12 min, 7 users, load average: 0.27, 0.54, 0.56</p>
<p>Tasks: 632 total, 1 running, 381 sleeping, 125 stopped, 125 zombie</p>
<p>发现僵尸进程数减少了一些, 但还有不少啊.</p>
<p>4) 再次获得杀僵尸进程语句</p>
<h1 id="ps_-ef__7C_grep_defunct__7C_grep_-v_grep__7C_awk__u2018_7Bprint__u201Ckill_-18__u201C__243_7D_u2019"><a href="#ps_-ef__7C_grep_defunct__7C_grep_-v_grep__7C_awk__u2018_7Bprint__u201Ckill_-18__u201C__243_7D_u2019" class="headerlink" title="ps -ef | grep defunct | grep -v grep | awk ‘{print “kill -18 “ $3}’"></a>ps -ef | grep defunct | grep -v grep | awk ‘{print “kill -18 “ $3}’</h1><p>执行上面获得的语句即可, 这次使用信号量18杀其父进程, 僵尸进程应该会全部消失.</p>
<p>5) 过一会儿再检查当前僵尸进程信息</p>
<h1 id="ps_-ef__7C_grep_defunct__7C_grep_-v_grep__7C_wc_-l-2"><a href="#ps_-ef__7C_grep_defunct__7C_grep_-v_grep__7C_wc_-l-2" class="headerlink" title="ps -ef | grep defunct | grep -v grep | wc -l"></a>ps -ef | grep defunct | grep -v grep | wc -l</h1><p>0</p>
<h1 id="top__7C_head_-2-2"><a href="#top__7C_head_-2-2" class="headerlink" title="top | head -2"></a>top | head -2</h1><p>top - 15:39:46 up 98 days, 23 min, 7 users, load average: 5.46, 2.20, 1.12</p>
<p>Tasks: 134 total, 1 running, 133 sleeping, 0 stopped, 0 zombie</p>
<p>6) 清除ZOMBIE(僵尸)进程原理</p>
<h1 id="kill_-18_PPID"><a href="#kill_-18_PPID" class="headerlink" title="kill -18 PPID"></a>kill -18 PPID</h1><p>PPID是其父进程, 这个信号是告诉父进程, 该子进程已经死亡了, 请收回分配给他的资源. 如果还不行则看先看其父进程又无其他子进程, 如果有, 可能需要先kill其他子进程, 也就是兄弟进程.</p>
<p>方法是:</p>
<h1 id="kill_-15_PID1_PID2"><a href="#kill_-15_PID1_PID2" class="headerlink" title="kill -15 PID1 PID2"></a>kill -15 PID1 PID2</h1><p>PID1,PID2是僵尸进程的父进程的其它子进程.</p>
<p>然后再kill父进程:</p>
<h1 id="kill_-15_PPID"><a href="#kill_-15_PPID" class="headerlink" title="kill -15 PPID"></a>kill -15 PPID</h1><p>=======================2  Linux进程的Uninterruptible sleep(D)状态</p>
<p>D，往往是由于 I/O 资源得不到满足，而引发等待，在内核源码 fs/proc/array.c 里，其文字定义为“ “D (disk sleep)”, /<em> 2 </em>/ ”（由此可知 D 原是Disk的打头字母），对应着 include/linux/sched.h 里的“ #define TASK_UNINTERRUPTIBLE 2 ”。举个例子，当 NFS 服务端关闭之时，若未事先 umount 相关目录，在 NFS 客户端执行 df 就会挂住整个登录会话，按 Ctrl+C 、Ctrl+Z 都无济于事。断开连接再登录，执行 ps axf 则看到刚才的 df 进程状态位已变成了 D ，kill -9 无法杀灭。正确的处理方式，是马上恢复 NFS 服务端，再度提供服务，刚才挂起的 df 进程发现了其苦苦等待的资源，便完成任务，自动消亡。若 NFS 服务端无法恢复服务，在 reboot 之前也应将 /etc/mtab 里的相关 NFS mount 项删除，以免 reboot 过程例行调用 netfs stop 时再次发生等待资源，导致系统重启过程挂起。<br><img src="http://dl.iteye.com/upload/attachment/0079/8447/5f87764c-da7a-30bb-ac9e-5ad7c651c0b5.jpg" alt="" title="点击查看原始大小图片"></p>
<p>运行在KVM虚拟机里的一些进程突然出了问题，这些出了问题的进程无法用kill杀掉，使用ps可以看到这些进程处于D状 态：</p>
<h1 id="ps_-a_-ubuild_-o_pid_2Cppid_2Cstat_2Ccommand"><a href="#ps_-a_-ubuild_-o_pid_2Cppid_2Cstat_2Ccommand" class="headerlink" title="ps -a -ubuild -o pid,ppid,stat,command"></a>ps -a -ubuild -o pid,ppid,stat,command</h1><p>PID  PPID STAT COMMAND</p>
<p>17009     1 Ds   -bash</p>
<p>17065     1 D    ls –color=tty -al</p>
<p>17577     1 D    /usr/java/jdk1.5.0_17/bin/java -Xmx512m -classpath /usr/local/a</p>
<p>17629     1 D    /usr/java/jdk1.5.0_17/bin/java -Xmx512m -classpath /usr/local/a</p>
<p>ps 的手册里说D状态是uninterruptible sleep，Linux进程有两种睡眠状态，一种interruptible sleep，处在这种睡眠状态的进程是可以通过给它发信号来唤醒的，比如发HUP信号给nginx的master进程可以让nginx重新加载配置文件而 不需要重新启动nginx进程；另外一种睡眠状态是uninterruptible sleep，处在这种状态的进程不接受外来的任何信号，这也是为什么之前我无法用kill杀掉这些处于D状态的进程，无论是”kill”, “kill -9″还是”kill -15″，因为它们压根儿就不受这些信号的支配。</p>
<p>进程为什么会被置于uninterruptible sleep状态呢？处于uninterruptible sleep状态的进程通常是在等待IO，比如磁盘IO，网络IO，其他外设IO，如果进程正在等待的IO在较长的时间内都没有响应，那么就很会不幸地被 ps看到了，同时也就意味着很有可能有IO出了问题，可能是外设本身出了故障，也可能是比如挂载的远程文件系统已经不可访问了，我这里遇到的问题就是由 down掉的NFS服务器引起的。</p>
<p>正是因为得不到IO的相应，进程才进入了uninterruptible sleep状态，所以要想使进程从uninterruptible sleep状态恢复，就得使进程等待的IO恢复，比如如果是因为从远程挂载的NFS卷不可访问导致进程进入uninterruptible sleep状态的，那么可以通过恢复该NFS卷的连接来使进程的IO请求得到满足，除此之外，要想干掉处在D状态进程就只能重启整个Linux系统了。</p>
<p>看到有人说如果要想杀掉D状态的进程，通常可以去杀掉它的父进程（通常是shell，我理解的这种情况是在shell下直接运行的该进程，之后该进 程转入了D状态），于是我就照做了，之后就出现了上面的状态：他们的父进程被杀掉了，但是他们的父进程PID都变成了1，也就是init进程，这下可如何是好？此时我这些D状态的进程已经影响到其他一些进程的运行，而已经无法访问的NFS卷又在段时间内无法恢复，那么，只好重新启动了，root不是玉皇大 帝，也有无奈的时候。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>————- 1 关于ZOMBIE进程：</p>
<h1 id="ps_-el_7C_grep_Z"><a href="#ps_-el_7C_grep_Z" class="headerlink" title="ps -el| grep Z"></a>ps -el| grep ]]>
    </summary>
    
      <category term="Linux" scheme="http://blog.suzf.net/categories/Linux/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[ZooKeeper 概述]]></title>
    <link href="http://blog.suzf.net/2016/02/03/ZooKeeper_%E6%A6%82%E8%BF%B0/"/>
    <id>http://blog.suzf.net/2016/02/03/ZooKeeper_概述/</id>
    <published>2016-02-03T03:39:32.000Z</published>
    <updated>2016-03-31T05:38:36.000Z</updated>
    <content type="html"><![CDATA[<h2 id="1-_ZooKeeper_u6982_u8FF0"><a href="#1-_ZooKeeper_u6982_u8FF0" class="headerlink" title="1. ZooKeeper概述"></a>1. ZooKeeper概述</h2><p>hadoop的一个子项目，是对Google分布式同步系统 chubby 的开源实现。<br>针对大型分布式系统的可靠协调系统。包括 配置维护，名字服务，分布式同步，组服务 等在内的功能。<br>目标： 封装复杂，易出错的关键服务，将简单的易用的接口和性能高效，稳定的协同工作系统提供给用户。</p>
<h2 id="2-_ZK_u7684_u8BBE_u8BA1_u76EE_u6807"><a href="#2-_ZK_u7684_u8BBE_u8BA1_u76EE_u6807" class="headerlink" title="2. ZK的设计目标"></a>2. ZK的设计目标</h2><ul>
<li>最终一致性</li>
<li>可靠性</li>
<li>实时性</li>
<li>等待无关</li>
<li>原子性  ： 更新只能是成功或失败</li>
<li>顺序性</li>
</ul>
<h2 id="3-_ZK_u6570_u636E_u6A21_u578B"><a href="#3-_ZK_u6570_u636E_u6A21_u578B" class="headerlink" title="3. ZK数据模型"></a>3. ZK数据模型</h2><p>ZK实际上是一个小型的分布式文件系统，其维护一个层次化的树结构。树节点znode，用于存储数据(小数据文件，不能超过1M)。<br>ZK对数据的访问是原子性的，客户端每次读取都获取znode的全部数据，同样，ZK只提供覆盖和删除操作，不支持部分更新。<br>客户端通过文件路径访问znode（路径名师unicode字符串）。</p>
<p>属性：</p>
<ul>
<li>3.1   层次化目录结构</li>
<li>3.2   Ephemeral (短暂的)</li>
<li>3.3    Sequence  (序列)</li>
<li>3.4    Watch       (监控器)</li>
</ul>
<h2 id="4-_ZK_u5DE5_u4F5C_u539F_u7406"><a href="#4-_ZK_u5DE5_u4F5C_u539F_u7406" class="headerlink" title="4. ZK工作原理"></a>4. ZK工作原理</h2><p>从编程的角度，ZK设计类似于windows下的注册表，有名称，树结构，键值对的关系，看做一个树形结构的数据库，分布不同的机器做名称管理。</p>
<p>ZK分为客户端和服务端。客户端值连接到整个ZK服务的某个服务器上。客户端使用并维护一个TCP连接，通过这个连接发送请求，接受响应，获取观察的时间以及发送心跳。</p>
<p><a href="http://suzf.net/wp-content/uploads/2016/02/zk.jpg" target="_blank" rel="external"><img src="http://suzf.net/wp-content/uploads/2016/02/zk.jpg" alt="zk"></a></p>
<p>图：Zookeeper 系统模型图</p>
<p>工作模式： 启动集群后，多个zk server在工作前会选出一个Leader，在接下去的工作中，这个leader死了，剩下的服务器会知道这个leader死掉了，活着的ZK server会继续选出一个Leader，选举出Leader的目的是为了保证数据的一致性。</p>
<p>Watch  ： 客户端在每个znode节点上设置一个watch。如果znode节点有变更，watch就会被触发，watch所属的客户端就会接收通知。如果客户端和 所连接的ZK服务器断开连接时，其他客户端也会收到一个通知，也就是说一个ZK服务端可以对应多个客户端。</p>
<h2 id="5-_ZK_u5B9E_u73B0_u673A_u5236"><a href="#5-_ZK_u5B9E_u73B0_u673A_u5236" class="headerlink" title="5. ZK实现机制"></a>5. ZK实现机制</h2><ul>
<li>5.1 单机模式           一台zk服务器，适合测试用，不保证高可靠和靠性能</li>
<li>5.2 复制模式           ZK只需确保znode树的每次修改都被复制到机器的大部分机器上，这样就可以在部分机器故障时快速恢复ZK服务。<blockquote>
<p><em>a. 选举Leader:  一个Leader，其余都是Follower</em></p>
<p><em>b. 原子性广播:</em></p>
<p><em>所有的写请求都先被转发到Leader上，Leader将更新操作广播到Follower。当大多数成员持久化存储这个更新后，Leader提交更新，并 回复客户端写操作成功。 Leader失效，会选一个新leader。以前的leader恢复，将变成一个Follower。这个选举过程非常快，不会影响性能。集群所有的机器正 在更新内存数据到znode树前，都会在本地硬盘保存一个备份。读请求可被任何一个机器响应，读过程实际上对内存的查找过程是非常方便，快速的。</em></p>
</blockquote>
</li>
</ul>
<h2 id="6-_ZK_u7684_u7279_u6027"><a href="#6-_ZK_u7684_u7279_u6027" class="headerlink" title="6. ZK的特性"></a>6. ZK的特性</h2><ul>
<li>6.1  Paxos算法 ,ZK的灵魂</li>
<li><p>6.2  会话<br>客户端连接到ZK服务器时，建立一个会话(Session). 会话有一个有效时间，在这个时间范围内没有收到任何请求，会话则过期。过期的会话无法重新打开，所创建的短暂性的节点也被删除。真实的系统环境，可以靠 ping请求保持会话的有效性。</p>
</li>
<li><p>6.3  版本号：乐观加锁的机制，使客户端能够检测出对节点的修改冲突。</p>
</li>
<li>6.4 监控 ：节点发送变化，watch机制可以让客户端得到通知。<br>要实现watch机制必须实现 org.apache.zookeeper.Watcher的接口。如下：<pre class="csharpcode"><span class="kwrd">public</span> <span class="kwrd">void</span> process(WatchedEvent <span class="kwrd">event</span>)
{
<span class="kwrd">try</span>
{
    Stat stat = zooKeeper.exists(nodePath,<span class="kwrd">false</span>);
    <span class="kwrd">if</span>(stat != <span class="kwrd">null</span>)
    {
        zooKeeper.delete(nodePath,-1);
    }
}
<span class="kwrd">catch</span>(KeeperException e)
{
    e.printStackTrace();
}
<span class="kwrd">catch</span>(InterruptedException e)
{
    e.printStackTrace();
}
}</pre>

</li>
</ul>
<p><del>~EOF</del>~~</p>
<p>来源： <a href="http://www.wangyuxiong.com/archives/51895" target="_blank" rel="external">互联网</a></p>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="1-_ZooKeeper_u6982_u8FF0"><a href="#1-_ZooKeeper_u6982_u8FF0" class="headerlink" title="1. ZooKeeper概述"></a>1. ZooKeeper概述</h2><p>ha]]>
    </summary>
    
      <category term="ZK" scheme="http://blog.suzf.net/tags/ZK/"/>
    
      <category term="zookeeper" scheme="http://blog.suzf.net/tags/zookeeper/"/>
    
      <category term="Hadoop" scheme="http://blog.suzf.net/categories/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[How to create restore a slave using GTID replication in MySQL 5.6]]></title>
    <link href="http://blog.suzf.net/2016/02/02/How-to-create-restore-a-slave-using-GTID-replication-in-MySQL-5.6/"/>
    <id>http://blog.suzf.net/2016/02/02/How-to-create-restore-a-slave-using-GTID-replication-in-MySQL-5.6/</id>
    <published>2016-02-02T09:02:33.000Z</published>
    <updated>2016-02-02T09:31:24.000Z</updated>
    <content type="html"><![CDATA[<p>在 Mysql 5.6 中，里面有许多新的特性；我个人认为其中最有用的是在复制中支持 全局 事物 ID。<br>这篇文章不是用来介绍什么是GTID，关于它的工作原理这里有很多文章介绍：<br>  <a href="http://dev.mysql.com/doc/refman/5.6/en/replication-gtids-concepts.html" target="_blank" rel="external">http://dev.mysql.com/doc/refman/5.6/en/replication-gtids-concepts.html</a></p>
<p>这里值得一提的是，如果你想GTID支持log_slave_updates，需要启用从服务器和考虑到性能的影响。</p>
<p>还有，这篇文章更趋向于实用，我们将要看到如何使用 GTID 创建/恢复 新的slaves 从 master上。</p>
<p>如何创建一个新的 slave 节点<br>我们不需要知道的现在二进制日志和位置，当GTID启用的时候想，这些事不需要的。<br>相反，我们需要知道哪个GTID出现在master上并且在slave上设置。 MySQL与GTID相关的两个全局变量是：</p>
<p>gtid_executed：它包含了集合中的所有事务记录在二进制日志<br>gtid_purged：它包含从二进制日志中删除所有事务记录的集合</p>
<p>所以，现在，这个过程是这样的：<br>在master上做一个备份并记录 gtid_executed 的值<br>在slave上恢复备份并将 gtid_purged 设置成master上gtid_executed 的值</p>
<p>新的mysqldump 可以为我们做这些工作。让我们来看看如何在master上备份的并且在slave 上恢复它来建立一个新的 Replication Server的一个例子。<br>master &gt; show global variables like ‘gtid_executed’;<br>+—————+——————————————-+<br>| Variable_name | Value                                     |<br>+—————+——————————————-+<br>| gtid_executed | 9a511b7b-7059-11e2-9a24-08002762b8af:1-13 |<br>+—————+——————————————-+<br>master &gt; show global variables like ‘gtid_purged’;<br>+—————+——————————————+<br>| Variable_name | Value                                    |<br>+—————+——————————————+<br>| gtid_purged   | 9a511b7b-7059-11e2-9a24-08002762b8af:1-2 |<br>+—————+——————————————+</p>
<p>现在我们可以使用mysqldump 备份master:</p>
<h1 id="mysqldump__u2013all-databases__u2013single-transaction__u2013triggers__u2013routines__u2013host_3D127-0-0-1__u2013port_3D18675__u2013user_3Dmsandbox__u2013password_3Dmsandbox__26gt_3B_dump-sql"><a href="#mysqldump__u2013all-databases__u2013single-transaction__u2013triggers__u2013routines__u2013host_3D127-0-0-1__u2013port_3D18675__u2013user_3Dmsandbox__u2013password_3Dmsandbox__26gt_3B_dump-sql" class="headerlink" title="mysqldump –all-databases –single-transaction –triggers –routines –host=127.0.0.1 –port=18675 –user=msandbox –password=msandbox &gt; dump.sql"></a>mysqldump –all-databases –single-transaction –triggers –routines –host=127.0.0.1 –port=18675 –user=msandbox –password=msandbox &gt; dump.sql</h1><p>生成的备份文件将包括以下信息：</p>
<h1 id="grep_PURGED_dump-sql"><a href="#grep_PURGED_dump-sql" class="headerlink" title="grep PURGED dump.sql"></a>grep PURGED dump.sql</h1><p>SET @@GLOBAL.GTID_PURGED=’9a511b7b-7059-11e2-9a24-08002762b8af:1-13’;</p>
<p>因此，在slave上进行数据恢复的时候，它将设置GTID_PURGED为master上GTID_EXECUTED的值。<br>所以现在，我们需要恢复转储和启动复制：<br>slave1 &gt; show global variables like ‘gtid_executed’;<br>+—————+——-+<br>| Variable_name | Value |<br>+—————+——-+<br>| gtid_executed |       |<br>+—————+——-+<br>slave1 &gt; show global variables like ‘gtid_purged’;<br>+—————+——-+<br>| Variable_name | Value |<br>+—————+——-+<br>| gtid_purged   |       |<br>+—————+——-+<br>slave1 &gt; slave1&gt; source test.sql;<br>[…]<br>slave1 &gt; show global variables like ‘gtid_executed’;<br>+—————+——————————————-+<br>| Variable_name | Value                                     |<br>+—————+——————————————-+<br>| gtid_executed | 9a511b7b-7059-11e2-9a24-08002762b8af:1-13 |<br>+—————+——————————————-+<br>slave1 &gt; show global variables like ‘gtid_purged’;<br>+—————+——————————————-+<br>| Variable_name | Value                                     |<br>+—————+——————————————-+<br>| gtid_purged   | 9a511b7b-7059-11e2-9a24-08002762b8af:1-13 |<br>+—————+——————————————-+</p>
<p>最后一步是用GTID的自动配置方法配置slave：<br>slave1 &gt; CHANGE MASTER TO MASTER_HOST=”127.0.0.1”, MASTER_USER=”msandbox”, MASTER_PASSWORD=”msandbox”, MASTER_PORT=18675, MASTER_AUTO_POSITION = 1;</p>
<p>如何用快速的方法修复有问题的slave<br>让我们想象一下，我们的slave节点已经停止了好几天，并master二进制日志已被清除。这就是我们得到的错误：<br>Slave_IO_Running: No<br>Slave_SQL_Running: Yes<br>Last_IO_Error: Got fatal error 1236 from master when reading data from binary log: ‘The slave is connecting using CHANGE MASTER TO MASTER_AUTO_POSITION = 1, but the master has purged binary logs containing GTIDs that the slave requires.’</p>
<p>所以，让我们试着去解决它。首先，我们有一个不太好快速的方法，即，一点到另一点 GTID 在二进制日志中。首先，我们得得到 GTID_EXECUTED 在master上：<br>master &gt; show global variables like ‘GTID_EXECUTED’;<br>+—————+——————————————-+<br>| Variable_name | Value                                     |<br>+—————+——————————————-+<br>| gtid_executed | 9a511b7b-7059-11e2-9a24-08002762b8af:1-14 |<br>+—————+——————————————-+</p>
<p>我们在slave上设置它<br>slave&gt; set global GTID_EXECUTED=”9a511b7b-7059-11e2-9a24-08002762b8af:1-14”<br>ERROR 1238 (HY000): Variable ‘gtid_executed’ is a read only variable</p>
<p>错误！ 记住，我们从master上得到 GTID_EXECUTED 的值，之后子在slave上设置 GTID_PURGED<br>slave1 &gt; set global GTID_PURGED=”9a511b7b-7059-11e2-9a24-08002762b8af:1-14”;<br>ERROR 1840 (HY000): GTID_PURGED can only be set when GTID_EXECUTED is empty.</p>
<p>错误又出现了，GTID_EXECUTED 应该是空的在改变 GTID_PURGED 前，但是我们不能改变它使用 SET,<br>因为这是一个只读的变量。 这里唯一的方法是使用 reset master(是的，在slave节点上)<br>slave1&gt; reset master;<br>slave1 &gt; show global variables like ‘GTID_EXECUTED’;<br>+—————+——-+<br>| Variable_name | Value |<br>+—————+——-+<br>| gtid_executed |       |<br>+—————+——-+<br>slave1 &gt; set global GTID_PURGED=”9a511b7b-7059-11e2-9a24-08002762b8af:1-14”;<br>slave1&gt; start slave io_thread;<br>slave1&gt; show slave status\G<br>[…]<br>Slave_IO_Running: Yes<br>Slave_SQL_Running: Yes<br>[…]</p>
<p>现在，如果你没有见到类似的错误[primary/unique key duplication]，你可以使用 pt-table-checksum 和 pt-table-sync 来检查数据库的完整性。</p>
<p>如何使用一个好的方法修复slave节点 话费时间稍长<br>好的方法是使用mysqldump 再次在master上备份数据。<br>我们执行在master上执行dump并且在slave上恢复，就像上面看到的那样。<br>slave1 [localhost] {msandbox} ((none)) &gt; source test.sql;<br>[…]<br>ERROR 1840 (HY000): GTID_PURGED can only be set when GTID_EXECUTED is empty.<br>[…]</p>
<p>哦！这里很值得一提的是这种错误信息可以消失在执行完命令之后。<br>因为恢复数据的过程需要继续。 谨慎些。</p>
<p>同样的错误 同样的解决方法<br>slave1&gt; reset master;<br>slave1&gt; source test.sql;<br>slave1&gt; start slave;<br>slave1&gt; show slave status\G<br>[…]<br>Slave_IO_Running: Yes<br>Slave_SQL_Running: Yes<br>[…]</p>
<p>结论<br>我们需要改变我们的思想在新的 GTID 下。现在二进制日志和位置信息已经不再我们的考虑范围之内了。<br>gtid_executed和gtid_purged是我们的新朋友。新版本Xtrabackup都全力支持GTID的。您可以查看下面的文章：</p>
<p><a href="https://www.percona.com/blog/2013/05/09/how-to-create-a-new-or-repair-a-broken-gtid-based-slave-with-percona-xtrabackup/" target="_blank" rel="external">https://www.percona.com/blog/2013/05/09/how-to-create-a-new-or-repair-a-broken-gtid-based-slave-with-percona-xtrabackup/</a></p>
]]></content>
    <summary type="html">
    <![CDATA[<p>在 Mysql 5.6 中，里面有许多新的特性；我个人认为其中最有用的是在复制中支持 全局 事物 ID。<br>这篇文章不是用来介绍什么是GTID，关于它的工作原理这里有很多文章介绍：<br>  <a href="http://dev.mysql.com/doc/refma]]>
    </summary>
    
      <category term="Mysql" scheme="http://blog.suzf.net/tags/Mysql/"/>
    
      <category term="Mysql" scheme="http://blog.suzf.net/categories/Mysql/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Python 爬取中文网页乱码的通用解决办法]]></title>
    <link href="http://blog.suzf.net/2016/02/02/Python_%E7%88%AC%E5%8F%96%E4%B8%AD%E6%96%87%E7%BD%91%E9%A1%B5%E4%B9%B1%E7%A0%81%E7%9A%84%E9%80%9A%E7%94%A8%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/"/>
    <id>http://blog.suzf.net/2016/02/02/Python_爬取中文网页乱码的通用解决办法/</id>
    <published>2016-02-02T03:51:27.000Z</published>
    <updated>2016-03-31T05:38:36.000Z</updated>
    <content type="html"><![CDATA[<p>由于网页编码不统一，我们会遇到各式各样的网页编码格式。</p>
<p>那么问题来了，由于编码格式不统一，爬取的中文信息往往是不尽任意的， 那么如何处理它呢？</p>
<p>ENV: Python 2.7.x</p>
<p>如何取得网页的编码，用chardet库最方便(<a href="https://pypi.python.org/pypi/chardet/" target="_blank" rel="external">https://pypi.python.<wbr>org/pypi/chardet/)。</a></p>
<h1 id="pip_install_chardet"><a href="#pip_install_chardet" class="headerlink" title="pip install chardet"></a>pip install chardet</h1><p><pre class="lang:default decode:true ">#!/usr/bin/env python</pre></p>
<h1 id="encoding_3Autf-8"><a href="#encoding_3Autf-8" class="headerlink" title="encoding:utf-8"></a>encoding:utf-8</h1><p>import chardet<br>import urllib2</p>
<p>line = “<a href="http://suzf.net" target="_blank" rel="external">http://suzf.net</a>“<br>html_old = urllib2.urlopen(line, timeout=30).read()</p>
<p>mychar = chardet.detect(html_old)</p>
<p>coding = mychar[‘encoding’]<br>print coding</p>
<p>if coding == ‘utf-8’ or coding == ‘UTF-8’:<br>    html = html_old<br>elif coding == ‘gbk’ or coding == ‘GBK’:<br>    html = html_old.decode(‘gbk’, ‘ignore’).encode(‘utf-8’)<br>elif coding == ‘gb2312’:<br>    html = html_old.decode(‘gb2312’, ‘ignore’).encode(‘utf-8’)</p>
<p>print html<br><br>&nbsp;</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>由于网页编码不统一，我们会遇到各式各样的网页编码格式。</p>
<p>那么问题来了，由于编码格式不统一，爬取的中文信息往往是不尽任意的， 那么如何处理它呢？</p>
<p>ENV: Python 2.7.x</p>
<p>如何取得网页的编码，用chardet库最方便(<a ]]>
    </summary>
    
      <category term="Python" scheme="http://blog.suzf.net/tags/Python/"/>
    
      <category term="Python" scheme="http://blog.suzf.net/categories/Python/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Debian Fedora常用命令管理包]]></title>
    <link href="http://blog.suzf.net/2016/02/01/Debian_Fedora_common_commands_Management_Pack/"/>
    <id>http://blog.suzf.net/2016/02/01/Debian_Fedora_common_commands_Management_Pack/</id>
    <published>2016-02-01T02:16:33.000Z</published>
    <updated>2016-02-01T02:25:59.000Z</updated>
    <content type="html"><![CDATA[<div>

<p>对大家推荐很好使用的Debian Fedora命令系统，像让大家对Debian Fedora命令系统有所了解，然后对Debian Fedora命令统全面讲解介绍，Debian Fedora 的包管理命令。</p>
<p><strong>=== Debian Fedora 中dpkg命令 ===</strong><br>dpkg -i –install<em> dpkg –install w3m_0.5.2-2+b1_i386.deb<span class="Apple-converted-space"> </span><br>dpkg -r –remove</em> dpkg –remove w3m<br>dpkg -P –purge<em> dpkg –purge w3m<br>dpkg -l –list</em> 列出当前系统里安装好的包名<br>dpkg -L –listfiles<em> 列出已经安装好的包的文件</em> dpkg -L w3m<br>dpkg -s –status<em> 包的状态表示</em> dpkg –status w3m<br>dpkg -S –search<em> 查看一个系统文件归属于哪个包</em> dpkg –search /etc/ucf.conf<br>dpkg -c –contents<em> 显示包里内容</em> dpkg -c w3m_0.5.2-2+b1_i386.deb<br>dpkg –unpack<em> 解压包<br>dpkg –configure</em> 配置包<br>dpkg -R –recursive* 递归处理文件夹内的内容</p>
<p><strong>=== Debian Fedora 中apt-get命令 ===</strong><br>apt-get install <em> 安装一个包<br>apt-get remove </em> 删除一个包<br>apt-get update<em> 更新APT-GET数据库<br>apt-get dist-upgrade</em> 从APT-GET数据库里,所有组件更新到最新状态<br>apt-get upgrade* 更新一个包</p>
<p><strong>=== Debian Fedora 中apt-cache命令 ===</strong><br>apt-cache show<em> 显示一个包的信息<br>apt-cache showpkg</em> 显示一个包的详细信息<br>apt-cache depends<em> 显示当前包的依赖信息<br>apt-cache search</em> 通过一个关键字,去查询含有这个关键字的包</p>
<p><strong>=== Debian Fedora 中aptitude命令 ===</strong><br>这是一个CUI工具,可以人机交互的操作.<br>所以,没有具体的参数,选项.<br>里面还有扫雷游戏,真的很好玩.</p>
<p><strong>===Debian Fedora 中 rpm命令 ===</strong>rpm -i –install w3m_aa.rpm<em> 安装一个RPM包<br>rpm -F –freshen w3m_aa.rpm</em> 如果已经安装过的包,进行更新<br>rpm -U –upgrade w3m_aa.rpm<em> 如果没安装,就安装;如果已经安装,就更新;这个比较常用<br>rpm -e w3m</em> 删除一个已经安装的包<br>rpm -h<em> 显示安装进度条, 一般和其它安装选项一起使用<br>rpm -v </em> 显示详细信息<br>rpm –nodeps<em> 无视依赖,强制安装/删除<br>rpm –force</em> 强制执行安装,更新<br>rpm -qa<em> 显示所有已经安装的包名<br>rpm -qi w3m</em> 显示已经安装好的包的信息<br>rpm -ql w3m<em> 显示已经安装好的包的所有文件<br>rpm -qc w3m</em> 显示已经安装好的包的设定文件; 这个比较有用<br>rpm -qd w3m<em> 显示已经安装好的包的相关文档 就是/usr/share/doc下有哪些相关文件<br>rpm -q –changelog w3m</em> 显示包的版本变化履历,注意,-q –changelog 这是一个命令, 不是同义词.<br>rpm -qpi w3m_aa.rpm <em> 显示rpm包的信息<br>rpm -qpl w3m_aa.rpm</em> 显示rpm包里所包含的文件<br>rpm2cpio w3m_aa.rpm | cpio -id<em> 把RPM里的文件释放到当前文件夹下面<br>rpm -V w3m</em> 对于已经安装好的包的系统文件,进行更新检查.如有变化,会有提示<br>S:大小变化了.<br>5:MD5检查,就是内容变化了.<br>M:Permitt,变化了<br>U:User变了<br>G:Group变了<br>T:更改时间有变化</p>
<p><strong>=== Debian Fedora 中yum 命令===</strong><br>/etc/yum.conf<br>/etc/yum.repos.d/<br>yumdownloader –source w3m<em> 下载包的源代码<br>yum check-update</em> 查看系统里所有可更新的包<br>yum update<em> 所有可更新的包进行更新<br>yum clean all</em> clean : 清除CACHE里的数据,参数 all 表示所有种别的cache全部删除<br>yum insatll w3m<em> 安装包<br>yum update w3m</em> 在线更新包,如果原来没有安装的话,不会安装.<br>yum remove w3m<em> 删除包w3m<br>yum list</em> 列出所有包的安装与否信息及已经安装的版本<br>yum list w3m<em> 列出指定包的安装与否及版本信息<br>yum info w3m</em> 打出指定的包的相关信息<br>yum groupinstall prg-group<em> 安装一组程序,比如 “Chinese Support”<br>yum grouplist</em> 显示可用的 程序组<br>yum gorupinfo prg-group<em> 显示程序组的信息,并显示里面包含的所有包名<br>yum search keyword</em> 显示包含keyword 的包名</p>
<p></p></div><p></p>
<p><div></div></p>
<p><div></div></p>
<div>

<h1 id="Debian__u5FEB_u901F_u53C2_u8003_u624B_u518C"><a href="#Debian__u5FEB_u901F_u53C2_u8003_u624B_u518C" class="headerlink" title="Debian 快速参考手册"></a>Debian 快速参考手册</h1><p></p></div><p></p>
<p><div><a href="http://qref.sourceforge.net/Debian/quick-reference/index.zh-cn.html#contents" target="_blank" rel="external">http://qref.sourceforge.net/Debian/quick-reference/index.zh-cn.html#contents</a></div></p>
<p><div></div></p>
<div>

<h1 id="The_Debian_GNU/Linux_FAQ"><a href="#The_Debian_GNU/Linux_FAQ" class="headerlink" title="The Debian GNU/Linux FAQ"></a>The Debian GNU/Linux FAQ</h1><p><a href="https://www.debian.org/doc/manuals/debian-faq/index.zh-cn.html#contents" target="_blank" rel="external">https://www.debian.org/doc/manuals/debian-faq/index.zh-cn.html#contents</a></p></div><br><br>&nbsp;<p></p>
]]></content>
    <summary type="html">
    <![CDATA[<div>

<p>对大家推荐很好使用的Debian Fedora命令系统，像让大家对Debian Fedora命令系统有所了解，然后对Debian Fedora命令统全面讲解介绍，Debian Fedora 的包管理命令。</p>
<p><strong>=== Debian F]]>
    </summary>
    
      <category term="Debian" scheme="http://blog.suzf.net/tags/Debian/"/>
    
      <category term="Linux" scheme="http://blog.suzf.net/categories/Linux/"/>
    
  </entry>
  
</feed>

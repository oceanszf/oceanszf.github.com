<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[Suzf Blog]]></title>
  <subtitle><![CDATA[Life is short, We need smile.]]></subtitle>
  <link href="/atom.xml" rel="self"/>
  <link href="http://blog.suzf.net/"/>
  <updated>2016-04-29T12:43:02.000Z</updated>
  <id>http://blog.suzf.net/</id>
  
  <author>
    <name><![CDATA[Jeffrey Su]]></name>
    <email><![CDATA[i@suzf.net]]></email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title><![CDATA[MySQL mysqldump 数据导出详解]]></title>
    <link href="http://blog.suzf.net/2016/04/27/MySQL_mysqldump_%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%87%BA%E8%AF%A6%E8%A7%A3/"/>
    <id>http://blog.suzf.net/2016/04/27/MySQL_mysqldump_数据导出详解/</id>
    <published>2016-04-27T13:27:53.000Z</published>
    <updated>2016-04-29T12:43:02.000Z</updated>
    <content type="html"><![CDATA[<p>介绍<br>在日常维护工作当中经常会需要对数据进行导出操作，而mysqldump是导出数据过程中使用非常频繁的一个工具；它自带的功能参数非常多，文章中会列举出一些常用的操作，在文章末尾会将所有的参数详细说明列出来。</p>
<p>语法：<br>默认不带参数的导出，导出文本内容大概如下：创建数据库判断语句-删除表-创建表-锁表-禁用索引-插入数据-启用索引-解锁表。</p>
<p><pre class="lang:default decode:true ">Usage: mysqldump [OPTIONS] database [tables]<br>OR     mysqldump [OPTIONS] –databases [OPTIONS] DB1 [DB2 DB3…]<br>OR     mysqldump [OPTIONS] –all-databases [OPTIONS]</pre><a id="more"></a><br>插入测试数据</p>
<p><pre class="lang:default decode:true ">CREATE DATABASE db1 DEFAULT CHARSET utf8;<br>USE db1;<br>CREATE TABLE a1(id int);<br>insert into a1() values(1),(2);<br>CREATE TABLE a2(id int);<br>insert into a2() values(2);<br>CREATE TABLE a3(id int);<br>insert into a3() values(3);</pre></p>
<p>CREATE DATABASE db2 DEFAULT CHARSET utf8;<br>USE db2;<br>CREATE TABLE b1(id int);<br>insert into b1() values(1);<br>CREATE TABLE b2(id int);<br>insert into b2() values(2);<br>1. 导出所有数据库<br>该命令会导出包括系统数据库在内的所有数据库</p>
<p><pre class="lang:default decode:true ">mysqldump -uroot -proot –all-databases &gt;/tmp/all.sql</pre><br>2. 导出db1、db2两个数据库的所有数据</p>
<p><pre class="lang:default decode:true ">mysqldump -uroot -proot –databases db1 db2 &gt;/tmp/user.sql</pre><br>3. 导出db1中的a1、a2表<br>注意导出指定表只能针对一个数据库进行导出，且导出的内容中和导出数据库也不一样，导出指定表的导出文本中没有创建数据库的判断语句，只有删除表-创建表-导入数据</p>
<p><pre class="lang:default decode:true ">mysqldump -uroot -proot –databases db1 –tables a1 a2  &gt;/tmp/db1.sql</pre><br>4. 条件导出，导出db1表a1中id=1的数据<br>条件导出只能导出单个表</p>
<p><pre class="lang:default decode:true">mysqldump -uroot -proot –databases db1 –tables a1 –where=’id=1’  &gt;/tmp/a1.sql<br></pre><br>5. 生成新的binlog文件,-F<br>有时候会希望导出数据之后生成一个新的binlog文件,只需要加上-F参数即可</p>
<p><pre class="lang:default decode:true ">mysqldump -uroot -proot –databases db1 -F &gt;/tmp/db1.sql</pre><br>6. 只导出表结构不导出数据，–no-data</p>
<p><pre class="lang:default decode:true ">mysqldump -uroot -proot –no-data –databases db1 &gt;/tmp/db1.sql</pre><br>7. 跨服务器导出导入数据</p>
<p><pre class="lang:default decode:true">mysqldump –host=h1 -uroot -proot –databases db1 |mysql –host=h2 -uroot -proot db2</pre><br>将h1服务器中的db1数据库的所有数据导入到h2中的db2数据库中，db2的数据库必须存在否则会报错</p>
<p><pre class="lang:default decode:true ">mysqldump –host=192.168.80.137 -uroot -proot -C –databases test |mysql –host=192.168.80.133 -uroot -proot test</pre><br>加上-C参数可以启用压缩传递。</p>
<p>8. 将主库的binlog位置和文件名追加到导出数据的文件中，–dump-slave<br>该参数在在从服务器上执行，相当于执行show slave status。当设置为1时，将会以CHANGE MASTER命令输出到数据文件；设置为2时，会在change前加上注释。<br>该选项将会打开–lock-all-tables，除非–single-transaction被指定。<br>在执行完后会自动关闭–lock-tables选项。–dump-slave默认是1</p>
<p><pre class="lang:default decode:true ">mysqldump -uroot -proot –dump-slave=1 –database db1 &gt;/tmp/db1.sql<br>mysqldump -uroot -proot –dump-slave=2 –database db1 &gt;/tmp/db1.sql</pre><br>9. 将当前服务器的binlog的位置和文件名追加到输出文件，–master-data<br>改参数和–dump-slave方法一样，只是它是记录的是当前服务器的binlog，相当于执行show master status。</p>
<p>10. –opt<br>等同于–add-drop-table, –add-locks, –create-options, –quick, –extended-insert, –lock-tables, –set-charset, –disable-keys 该选项默认开启, 可以用–skip-opt禁用.</p>
<p><pre class="lang:default decode:true ">mysqldump -uroot -p –host=localhost –all-databases –opt</pre><br>11. 保证导出的一致性状态–single-transaction<br>该选项在导出数据之前提交一个BEGIN SQL语句，BEGIN 不会阻塞任何应用程序且能保证导出时数据库的一致性状态。它只适用于多版本存储引擎（它不显示加锁通过判断版本来对比数据），仅InnoDB。本选项和–lock-tables 选项是互斥的，因为LOCK TABLES 会使任何挂起的事务隐含提交。要想导出大表的话，应结合使用–quick 选项。<br>–quick, -q<br>不缓冲查询，直接导出到标准输出。默认为打开状态，使用–skip-quick取消该选项。</p>
<p>12. –lock-tables, -l<br>开始导出前，锁定所有表。用READ LOCAL锁定表以允许MyISAM表并行插入。对于支持事务的表例如InnoDB和BDB，–single-transaction是一个更好的选择，因为它根本不需要锁定表。</p>
<p>请注意当导出多个数据库时，–lock-tables分别为每个数据库锁定表。因此，该选项不能保证导出文件中的表在数据库之间的逻辑一致性。不同数据库表的导出状态可以完全不同。</p>
<p>13. 导出存储过程和自定义函数–routines, -R</p>
<p><pre class="lang:default decode:true ">mysqldump  -uroot -p –host=localhost –all-databases –routines</pre><br>参数说明:</p>
<p><pre class="lang:default decode:true ">–all-databases  , -A<br>导出全部数据库。<br>mysqldump  -uroot -p –all-databases<br>–all-tablespaces  , -Y<br>导出全部表空间。<br>mysqldump  -uroot -p –all-databases –all-tablespaces<br>–no-tablespaces  , -y<br>不导出任何表空间信息。<br>mysqldump  -uroot -p –all-databases –no-tablespaces<br>–add-drop-database<br>每个数据库创建之前添加drop数据库语句。<br>mysqldump  -uroot -p –all-databases –add-drop-database<br>–add-drop-table<br>每个数据表创建之前添加drop数据表语句。(默认为打开状态，使用–skip-add-drop-table取消选项)<br>mysqldump  -uroot -p –all-databases  (默认添加drop语句)<br>mysqldump  -uroot -p –all-databases –skip-add-drop-table  (取消drop语句)<br>–add-locks<br>在每个表导出之前增加LOCK TABLES并且之后UNLOCK  TABLE。(默认为打开状态，使用–skip-add-locks取消选项)<br>mysqldump  -uroot -p –all-databases  (默认添加LOCK语句)<br>mysqldump  -uroot -p –all-databases –skip-add-locks   (取消LOCK语句)<br>–allow-keywords<br>允许创建是关键词的列名字。这由表名前缀于每个列名做到。<br>mysqldump  -uroot -p –all-databases –allow-keywords<br>–apply-slave-statements<br>在’CHANGE MASTER’前添加’STOP SLAVE’，并且在导出的最后添加’START SLAVE’。<br>mysqldump  -uroot -p –all-databases –apply-slave-statements<br>–character-sets-dir<br>字符集文件的目录<br>mysqldump  -uroot -p –all-databases  –character-sets-dir=/usr/local/mysql/share/mysql/charsets<br>–comments<br>附加注释信息。默认为打开，可以用–skip-comments取消<br>mysqldump  -uroot -p –all-databases  (默认记录注释)<br>mysqldump  -uroot -p –all-databases –skip-comments   (取消注释)<br>–compatible<br>导出的数据将和其它数据库或旧版本的MySQL 相兼容。值可以为ansi、mysql323、mysql40、postgresql、oracle、mssql、db2、maxdb、no_key_options、no_tables_options、no_field_options等，<br>要使用几个值，用逗号将它们隔开。它并不保证能完全兼容，而是尽量兼容。<br>mysqldump  -uroot -p –all-databases –compatible=ansi<br>–compact<br>导出更少的输出信息(用于调试)。去掉注释和头尾等结构。可以使用选项：–skip-add-drop-table  –skip-add-locks –skip-comments –skip-disable-keys<br>mysqldump  -uroot -p –all-databases –compact<br>–complete-insert,  -c<br>使用完整的insert语句(包含列名称)。这么做能提高插入效率，但是可能会受到max_allowed_packet参数的影响而导致插入失败。<br>mysqldump  -uroot -p –all-databases –complete-insert<br>–compress, -C<br>在客户端和服务器之间启用压缩传递所有信息<br>mysqldump  -uroot -p –all-databases –compress<br>–create-options,  -a<br>在CREATE TABLE语句中包括所有MySQL特性选项。(默认为打开状态)<br>mysqldump  -uroot -p –all-databases<br>–databases,  -B<br>导出几个数据库。参数后面所有名字参量都被看作数据库名。<br>mysqldump  -uroot -p –databases test mysql<br>–debug<br>输出debug信息，用于调试。默认值为：d:t,/tmp/mysqldump.trace<br>mysqldump  -uroot -p –all-databases –debug<br>mysqldump  -uroot -p –all-databases –debug=” d:t,/tmp/debug.trace”<br>–debug-check<br>检查内存和打开文件使用说明并退出。<br>mysqldump  -uroot -p –all-databases –debug-check<br>–debug-info<br>输出调试信息并退出<br>mysqldump  -uroot -p –all-databases –debug-info<br>–default-character-set<br>设置默认字符集，默认值为utf8<br>mysqldump  -uroot -p –all-databases –default-character-set=utf8<br>–delayed-insert<br>采用延时插入方式（INSERT DELAYED）导出数据<br>mysqldump  -uroot -p –all-databases –delayed-insert<br>–delete-master-logs<br>master备份后删除日志. 这个参数将自动激活–master-data。<br>mysqldump  -uroot -p –all-databases –delete-master-logs<br>–disable-keys<br>对于每个表，用/<em>!40000 ALTER TABLE tbl_name DISABLE KEYS </em>/;和/<em>!40000 ALTER TABLE tbl_name ENABLE KEYS </em>/;语句引用INSERT语句。这样可以更快地导入dump出来的文件，因为它是在插入所有行后创建索引的。该选项只适合MyISAM表，默认为打开状态。<br>mysqldump  -uroot -p –all-databases<br>–dump-slave<br>该选项将主的binlog位置和文件名追加到导出数据的文件中(show slave status)。设置为1时，将会以CHANGE MASTER命令输出到数据文件；设置为2时，会在change前加上注释。该选项将会打开–lock-all-tables，除非–single-transaction被指定。该选项会自动关闭–lock-tables选项。默认值为0。<br>mysqldump  -uroot -p –all-databases –dump-slave=1<br>mysqldump  -uroot -p –all-databases –dump-slave=2</pre></p>
<p>–master-data<br>该选项将当前服务器的binlog的位置和文件名追加到输出文件中(show master status)。如果为1，将会输出CHANGE MASTER 命令；如果为2，输出的CHANGE  MASTER命令前添加注释信息。该选项将打开–lock-all-tables 选项，除非–single-transaction也被指定（在这种情况下，全局读锁在开始导出时获得很短的时间；其他内容参考下面的–single-transaction选项）。该选项自动关闭–lock-tables选项。<br>mysqldump  -uroot -p –host=localhost –all-databases –master-data=1;<br>mysqldump  -uroot -p –host=localhost –all-databases –master-data=2;</p>
<p>–events, -E<br>导出事件。<br>mysqldump  -uroot -p –all-databases –events<br>–extended-insert,  -e<br>使用具有多个VALUES列的INSERT语法。这样使导出文件更小，并加速导入时的速度。默认为打开状态，使用–skip-extended-insert取消选项。<br>mysqldump  -uroot -p –all-databases<br>mysqldump  -uroot -p –all-databases–skip-extended-insert   (取消选项)<br>–fields-terminated-by<br>导出文件中忽略给定字段。与–tab选项一起使用，不能用于–databases和–all-databases选项<br>mysqldump  -uroot -p test test –tab=”/home/mysql” –fields-terminated-by=”#”<br>–fields-enclosed-by<br>输出文件中的各个字段用给定字符包裹。与–tab选项一起使用，不能用于–databases和–all-databases选项<br>mysqldump  -uroot -p test test –tab=”/home/mysql” –fields-enclosed-by=”#”<br>–fields-optionally-enclosed-by<br>输出文件中的各个字段用给定字符选择性包裹。与–tab选项一起使用，不能用于–databases和–all-databases选项<br>mysqldump  -uroot -p test test –tab=”/home/mysql”  –fields-enclosed-by=”#” –fields-optionally-enclosed-by  =”#”<br>–fields-escaped-by<br>输出文件中的各个字段忽略给定字符。与–tab选项一起使用，不能用于–databases和–all-databases选项<br>mysqldump  -uroot -p mysql user –tab=”/home/mysql” –fields-escaped-by=”#”<br>–flush-logs<br>开始导出之前刷新日志。<br>请注意：假如一次导出多个数据库(使用选项–databases或者–all-databases)，将会逐个数据库刷新日志。除使用–lock-all-tables或者–master-data外。在这种情况下，日志将会被刷新一次，相应的所以表同时被锁定。因此，如果打算同时导出和刷新日志应该使用–lock-all-tables 或者–master-data 和–flush-logs。<br>mysqldump  -uroot -p –all-databases –flush-logs<br>–flush-privileges<br>在导出mysql数据库之后，发出一条FLUSH  PRIVILEGES 语句。为了正确恢复，该选项应该用于导出mysql数据库和依赖mysql数据库数据的任何时候。<br>mysqldump  -uroot -p –all-databases –flush-privileges<br>–force<br>在导出过程中忽略出现的SQL错误。<br>mysqldump  -uroot -p –all-databases –force<br>–help<br>显示帮助信息并退出。<br>mysqldump  –help<br>–hex-blob<br>使用十六进制格式导出二进制字符串字段。如果有二进制数据就必须使用该选项。影响到的字段类型有BINARY、VARBINARY、BLOB。<br>mysqldump  -uroot -p –all-databases –hex-blob<br>–host, -h<br>需要导出的主机信息<br>mysqldump  -uroot -p –host=localhost –all-databases<br>–ignore-table<br>不导出指定表。指定忽略多个表时，需要重复多次，每次一个表。每个表必须同时指定数据库和表名。例如：–ignore-table=database.table1 –ignore-table=database.table2 ……<br>mysqldump  -uroot -p –host=localhost –all-databases –ignore-table=mysql.user<br>–include-master-host-port<br>在–dump-slave产生的’CHANGE  MASTER TO..’语句中增加’MASTER_HOST=&lt;host&gt;，MASTER_PORT=&lt;port&gt;’<br>mysqldump  -uroot -p –host=localhost –all-databases –include-master-host-port<br>–insert-ignore<br>在插入行时使用INSERT IGNORE语句.<br>mysqldump  -uroot -p –host=localhost –all-databases –insert-ignore<br>–lines-terminated-by<br>输出文件的每行用给定字符串划分。与–tab选项一起使用，不能用于–databases和–all-databases选项。<br>mysqldump  -uroot -p –host=localhost test test –tab=”/tmp/mysql”  –lines-terminated-by=”##”<br>–lock-all-tables,  -x<br>提交请求锁定所有数据库中的所有表，以保证数据的一致性。这是一个全局读锁，并且自动关闭–single-transaction 和–lock-tables 选项。<br>mysqldump  -uroot -p –host=localhost –all-databases –lock-all-tables<br>–lock-tables,  -l<br>开始导出前，锁定所有表。用READ  LOCAL锁定表以允许MyISAM表并行插入。对于支持事务的表例如InnoDB和BDB，–single-transaction是一个更好的选择，因为它根本不需要锁定表。<br>请注意当导出多个数据库时，–lock-tables分别为每个数据库锁定表。因此，该选项不能保证导出文件中的表在数据库之间的逻辑一致性。不同数据库表的导出状态可以完全不同。<br>mysqldump  -uroot -p –host=localhost –all-databases –lock-tables<br>–log-error<br>附加警告和错误信息到给定文件<br>mysqldump  -uroot -p –host=localhost –all-databases  –log-error=/tmp/mysqldump_error_log.err<br>–max_allowed_packet<br>服务器发送和接受的最大包长度。<br>mysqldump  -uroot -p –host=localhost –all-databases –max_allowed_packet=10240<br>–net_buffer_length<br>TCP/IP和socket连接的缓存大小。<br>mysqldump  -uroot -p –host=localhost –all-databases –net_buffer_length=1024<br>–no-autocommit<br>使用autocommit/commit 语句包裹表。<br>mysqldump  -uroot -p –host=localhost –all-databases –no-autocommit<br>–no-create-db,  -n<br>只导出数据，而不添加CREATE DATABASE 语句。<br>mysqldump  -uroot -p –host=localhost –all-databases –no-create-db<br>–no-create-info,  -t<br>只导出数据，而不添加CREATE TABLE 语句。<br>mysqldump  -uroot -p –host=localhost –all-databases –no-create-info<br>–no-data, -d<br>不导出任何数据，只导出数据库表结构。<br>mysqldump  -uroot -p –host=localhost –all-databases –no-data<br>–no-set-names,  -N<br>等同于–skip-set-charset<br>mysqldump  -uroot -p –host=localhost –all-databases –no-set-names<br>–opt<br>等同于–add-drop-table,  –add-locks, –create-options, –quick, –extended-insert, –lock-tables,  –set-charset, –disable-keys 该选项默认开启,  可以用–skip-opt禁用.<br>mysqldump  -uroot -p –host=localhost –all-databases –opt<br>–order-by-primary<br>如果存在主键，或者第一个唯一键，对每个表的记录进行排序。在导出MyISAM表到InnoDB表时有效，但会使得导出工作花费很长时间。<br>mysqldump  -uroot -p –host=localhost –all-databases –order-by-primary<br>–password, -p<br>连接数据库密码<br>–pipe(windows系统可用)<br>使用命名管道连接mysql<br>mysqldump  -uroot -p –host=localhost –all-databases –pipe<br>–port, -P<br>连接数据库端口号<br>–protocol<br>使用的连接协议，包括：tcp, socket, pipe, memory.<br>mysqldump  -uroot -p –host=localhost –all-databases –protocol=tcp<br>–quick, -q<br>不缓冲查询，直接导出到标准输出。默认为打开状态，使用–skip-quick取消该选项。<br>mysqldump  -uroot -p –host=localhost –all-databases<br>mysqldump  -uroot -p –host=localhost –all-databases –skip-quick<br>–quote-names,-Q<br>使用（`）引起表和列名。默认为打开状态，使用–skip-quote-names取消该选项。<br>mysqldump  -uroot -p –host=localhost –all-databases<br>mysqldump  -uroot -p –host=localhost –all-databases –skip-quote-names<br>–replace<br>使用REPLACE INTO 取代INSERT INTO.<br>mysqldump  -uroot -p –host=localhost –all-databases –replace<br>–result-file,  -r<br>直接输出到指定文件中。该选项应该用在使用回车换行对（\r\n）换行的系统上（例如：DOS，Windows）。该选项确保只有一行被使用。<br>mysqldump  -uroot -p –host=localhost –all-databases –result-file=/tmp/mysqldump_result_file.txt<br>–routines, -R<br>导出存储过程以及自定义函数。<br>mysqldump  -uroot -p –host=localhost –all-databases –routines<br>–set-charset<br>添加’SET NAMES  default_character_set’到输出文件。默认为打开状态，使用–skip-set-charset关闭选项。<br>mysqldump  -uroot -p –host=localhost –all-databases<br>mysqldump  -uroot -p –host=localhost –all-databases –skip-set-charset<br>–single-transaction<br>该选项在导出数据之前提交一个BEGIN SQL语句，BEGIN 不会阻塞任何应用程序且能保证导出时数据库的一致性状态。它只适用于多版本存储引擎，仅InnoDB。本选项和–lock-tables 选项是互斥的，因为LOCK  TABLES 会使任何挂起的事务隐含提交。要想导出大表的话，应结合使用–quick 选项。<br>mysqldump  -uroot -p –host=localhost –all-databases –single-transaction<br>–dump-date<br>将导出时间添加到输出文件中。默认为打开状态，使用–skip-dump-date关闭选项。<br>mysqldump  -uroot -p –host=localhost –all-databases<br>mysqldump  -uroot -p –host=localhost –all-databases –skip-dump-date<br>–skip-opt<br>禁用–opt选项.<br>mysqldump  -uroot -p –host=localhost –all-databases –skip-opt<br>–socket,-S<br>指定连接mysql的socket文件位置，默认路径/tmp/mysql.sock<br>mysqldump  -uroot -p –host=localhost –all-databases –socket=/tmp/mysqld.sock<br>–tab,-T<br>为每个表在给定路径创建tab分割的文本文件。注意：仅仅用于mysqldump和mysqld服务器运行在相同机器上。<br>mysqldump  -uroot -p –host=localhost test test –tab=”/home/mysql”<br>–tables<br>覆盖–databases (-B)参数，指定需要导出的表名。<br>mysqldump  -uroot -p –host=localhost –databases test –tables test<br>–triggers<br>导出触发器。该选项默认启用，用–skip-triggers禁用它。<br>mysqldump  -uroot -p –host=localhost –all-databases –triggers<br>–tz-utc<br>在导出顶部设置时区TIME_ZONE=’+00:00’ ，以保证在不同时区导出的TIMESTAMP 数据或者数据被移动其他时区时的正确性。<br>mysqldump  -uroot -p –host=localhost –all-databases –tz-utc<br>–user, -u<br>指定连接的用户名。<br>–verbose, –v<br>输出多种平台信息。<br>–version, -V<br>输出mysqldump版本信息并退出<br>–where, -w<br>只转储给定的WHERE条件选择的记录。请注意如果条件包含命令解释符专用空格或字符，一定要将条件引用起来。<br>mysqldump  -uroot -p –host=localhost –all-databases –where=” user=’root’”<br>–xml, -X<br>导出XML格式.<br>mysqldump  -uroot -p –host=localhost –all-databases –xml<br>–plugin_dir<br>客户端插件的目录，用于兼容不同的插件版本。<br>mysqldump  -uroot -p –host=localhost –all-databases –plugin_dir=”/usr/local/lib/plugin”<br>–default_auth<br>客户端插件默认使用权限。<br>mysqldump  -uroot -p –host=localhost –all-databases –default-auth=”/usr/local/lib/plugin/&lt;PLUGIN&gt;”<br>总结<br>文章中列举了一些常用的导出操作，还有很多其它的参数也会经常用到，包括“–add-drop-database”，“–apply-slave-statements”，“–triggers”等。</p>
<blockquote>
<p><em>源文： <a href="http://www.cnblogs.com/chenmh/p/5300370.html" target="_blank" rel="external">http://www.cnblogs.com/chenmh/p/5300370.html</a></em></p>
<p><em>作者： <a href="http://www.cnblogs.com/chenmh/" title="点击跳转到原文" target="_blank" rel="external">pursuer.chen</a></em></p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<p>介绍<br>在日常维护工作当中经常会需要对数据进行导出操作，而mysqldump是导出数据过程中使用非常频繁的一个工具；它自带的功能参数非常多，文章中会列举出一些常用的操作，在文章末尾会将所有的参数详细说明列出来。</p>
<p>语法：<br>默认不带参数的导出，导出文本内容大概如下：创建数据库判断语句-删除表-创建表-锁表-禁用索引-插入数据-启用索引-解锁表。</p>
<p><pre class="lang:default decode:true ">Usage: mysqldump [OPTIONS] database [tables]<br>OR     mysqldump [OPTIONS] –databases [OPTIONS] DB1 [DB2 DB3…]<br>OR     mysqldump [OPTIONS] –all-databases [OPTIONS]</pre>]]>
    
    </summary>
    
      <category term="Mysql" scheme="http://blog.suzf.net/tags/Mysql/"/>
    
      <category term="Mysql" scheme="http://blog.suzf.net/categories/Mysql/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Python Re module learn]]></title>
    <link href="http://blog.suzf.net/2016/04/24/Python_Re_module_learn/"/>
    <id>http://blog.suzf.net/2016/04/24/Python_Re_module_learn/</id>
    <published>2016-04-24T09:15:46.000Z</published>
    <updated>2016-04-29T12:43:02.000Z</updated>
    <content type="html"><![CDATA[<p>上篇文章 <a href="http://suzf.net/thread-0422-806.html" target="_blank" rel="external">Python正则表达式操作指南 </a>已经对正则表达式做出了详细的介绍。<br>下面只对 re 模块做出简要的说明。</p>
<p>元字符说明</p>
<p><pre class="lang:default decode:true ">.    匹配除换行符以外的任意字符<br>^    匹配字符串的开始<br>$    匹配字符串的结束<br>[]   用来匹配一个指定的字符类别<br>？   对于前一个字符字符重复0次到1次</pre></p>
<ul>
<li>对于前一个字符重复0次到无穷次<br>{}   对于前一个字符重复m次<br>{m，n} 对前一个字符重复为m到n次<br>\d   匹配数字，相当于[0-9]<br>\D   匹配任何非数字字符，相当于[^0-9]<br>\s   匹配任意的空白符，相当于[ fv]<br>\S   匹配任何非空白字符，相当于[^ fv]<br>\w   匹配任何字母数字字符，相当于[a-zA-Z0-9<em>]<br>\W   匹配任何非字母数字字符，相当于[^a-zA-Z0-9</em>]<br>\b   匹配单词的开始或结束<a id="more"></a>
模块导入 查看方法<br><pre class="lang:default decode:true ">import re<br>dir(re)<br>[‘DEBUG’, ‘DOTALL’, ‘I’, ‘IGNORECASE’, ‘L’, ‘LOCALE’, ‘M’, ‘MULTILINE’, ‘S’, ‘Scanner’, ‘T’, ‘TEMPLATE’, ‘U’, ‘UNICODE’, ‘VERBOSE’, ‘X’, ‘_MAXCACHE’, ‘<strong>all</strong>‘, ‘<strong>builtins</strong>‘, ‘<strong>doc</strong>‘, ‘<strong>file</strong>‘, ‘<strong>name</strong>‘, ‘<strong>package</strong>‘, ‘<strong>version</strong>‘, ‘_alphanum’, ‘_cache’, ‘_cache_repl’, ‘_compile’, ‘_compile_repl’, ‘_expand’, ‘_pattern_type’, ‘_pickle’, ‘_subx’, ‘compile’, ‘copy_reg’, ‘error’, ‘escape’, ‘findall’, ‘finditer’, ‘match’, ‘purge’, ‘search’, ‘split’, ‘sre_compile’, ‘sre_parse’, ‘sub’, ‘subn’, ‘sys’, ‘template’]</pre><br>常用的方法函数<br><pre class="lang:default decode:true"># 以下为匹配所用函数<br>re.match(pattern, string[, flags])<br>re.search(pattern, string[, flags])<br>re.split(pattern, string[, maxsplit])<br>re.findall(pattern, string[, flags])<br>re.finditer(pattern, string[, flags])<br>re.sub(pattern, repl, string[, count])<br>re.subn(pattern, repl, string[, count])</pre></li>
</ul>
<h1 id="u8FD4_u56DE_pattern__u5BF9_u8C61"><a href="#u8FD4_u56DE_pattern__u5BF9_u8C61" class="headerlink" title="返回 pattern 对象"></a>返回 pattern 对象</h1><p>re.compile(string[,flag]) </p>
<p>参数 flag 是匹配模式，取值可以使用按位或运算符’|’表示同时生效。<br>      比如 re.I | re.M。</p>
<p>可选值有：<br>    re.I(I –&gt; IGNORECASE): 忽略大小写（括号内是完整写法，下同）<br>    re.M(M –&gt; MULTILINE): 多行模式，改变’^’和’$’的行为（参见上图）<br>    re.S(S –&gt; DOTALL): 点任意匹配模式，改变’.’的行为<br>    re.L(L –&gt; LOCALE): 使预定字符类 \w \W \b \B \s \S 取决于当前区域设定<br>    re.U(U –&gt; UNICODE): 使预定字符类 \w \W \b \B \s \S \d \D 取决于unicode定义的字符属性<br>    re.X(X –&gt; VERBOSE): 详细模式。这个模式下正则表达式可以是多行，忽略空白字符，并可以加入注释。<br>Match</p>
<p>尝试从字符串的起始位置匹配一个模式，如果不是起始位置匹配成功的话，match()就返回none。</p>
<p><pre class="lang:default decode:true">语法格式<br>re.match(pattern, string[, flags])</pre></p>
<p>匹配对象方法    描述<br>group(num=0)    匹配的整个表达式的字符串，group() 可以一次输入多个组号，<br>                在这种情况下它将返回一个包含那些组所对应值的元组。<br>groups()    返回一个包含所有小组字符串的元组，从 1 到 所含的小组号。<br>举个栗子</p>
<p><pre class="lang:default decode:true">#!/usr/bin/env python</pre></p>
<h1 id="encoding_3A_utf-8"><a href="#encoding_3A_utf-8" class="headerlink" title="-- encoding: utf-8 --"></a>-<em>- encoding: utf-8 -</em>-</h1><p>import re</p>
<h1 id="u5728_u5F00_u59CB_u4F4D_u7F6E_u5339_u914D"><a href="#u5728_u5F00_u59CB_u4F4D_u7F6E_u5339_u914D" class="headerlink" title="在开始位置匹配"></a>在开始位置匹配</h1><p>print (re.match(‘www’, ‘www.suzf.net’).span())</p>
<h1 id="u4E0D_u5728_u5F00_u59CB_u4F4D_u7F6E_u5339_u914D"><a href="#u4E0D_u5728_u5F00_u59CB_u4F4D_u7F6E_u5339_u914D" class="headerlink" title="不在开始位置匹配"></a>不在开始位置匹配</h1><p>print (re.match(‘net’, ‘www.suzf.net’))</p>
<h1 id="u6267_u884C_u7ED3_u679C"><a href="#u6267_u884C_u7ED3_u679C" class="headerlink" title="执行结果"></a>执行结果</h1><p>(0, 3)<br>None</p>
<p>line = ‘Welcome to access my blog —&gt; <a href="http://suzf.net" target="_blank" rel="external">http://suzf.net</a>‘<br>matchObj = re.match(r’(.<em>) -{2,}. (.</em>)’, line, re.M|re.I)</p>
<p>if matchObj:<br>    print “matchObj.group():”, matchObj.group()<br>    print “matchObj.group(1):”, matchObj.group(1)<br>    print “matchObj.group(2):”, matchObj.group(2)</p>
<p>else:<br>    print “Sorry! No match!”</p>
<h1 id="u6267_u884C_u7ED3_u679C-1"><a href="#u6267_u884C_u7ED3_u679C-1" class="headerlink" title="执行结果"></a>执行结果</h1><p>matchObj.group(): Welcome to access my blog –&gt; <a href="http://suzf.net" target="_blank" rel="external">http://suzf.net</a><br>matchObj.group(1): Welcome to access my blog<br>matchObj.group(2): <a href="http://suzf.net" target="_blank" rel="external">http://suzf.net</a><br><br>Search</p>
<p>re.search 扫描整个字符串并返回第一个成功的匹配，匹配失败返回None。。</p>
<p><pre class="lang:default decode:true">语法格式<br>re.search(pattern, string, flags=0)</pre><br>举个栗子</p>
<p><pre class="lang:default decode:true">import re</pre></p>
<p>print (re.search(‘www’, ‘www.suzf.net’).span())<br>print (re.search(‘net’, ‘www.suzf.net’).span())</p>
<p>line = ‘Welcome to access my blog —&gt; <a href="http://suzf.net" target="_blank" rel="external">http://suzf.net</a>‘<br>matchObj = re.search(r’(.<em>) -{2,}. (.</em>)’, line, re.M|re.I)</p>
<p>if matchObj:<br>    print “matchObj.group():”, matchObj.group()<br>    print “matchObj.group(1):”, matchObj.group(1)<br>    print “matchObj.group(2):”, matchObj.group(2)</p>
<p>else:<br>    print “Sorry! No match!”</p>
<h1 id="u8FD0_u884C_u7ED3_u679C"><a href="#u8FD0_u884C_u7ED3_u679C" class="headerlink" title="运行结果"></a>运行结果</h1><p>(0, 3)<br>(9, 12)<br>matchObj.group(): Welcome to access my blog —&gt; <a href="http://suzf.net" target="_blank" rel="external">http://suzf.net</a><br>matchObj.group(1): Welcome to access my blog<br>matchObj.group(2): <a href="http://suzf.net" target="_blank" rel="external">http://suzf.net</a><br>re.match与re.search的区别<br>re.match只匹配字符串的开始，如果字符串开始不符合正则表达式，则匹配失败，函数返回None；而re.search匹配整个字符串，直到找到一个匹配。</p>
<p>Split</p>
<p>通过正则表达式将字符串分离。如果用括号将正则表达式括起来，那么匹配的字符串也会被列入到list中返回。maxsplit是分离的次数，maxsplit=1分离一次，默认为0，不限制次数。</p>
<p><pre class="lang:default decode:true"><strong>语法格式<br>re.split(pattern, string[, maxsplit]) | split(string[, maxsplit])</strong></pre><br>举个栗子</p>
<p><pre class="lang:default decode:true ">import re</pre></p>
<p>test=”Trouble is a friend, yeah trouble is a friend of mine.”<br>print re.split(r”\s+”, test)</p>
<h1 id="u5206_u5272_u524D_u4E09_u4E2A"><a href="#u5206_u5272_u524D_u4E09_u4E2A" class="headerlink" title="分割前三个"></a>分割前三个</h1><p>print re.split(r”\s+”, test, 3)</p>
<h1 id="u4E0D_u5339_u914D_u9ED8_u8BA4__u6253_u5370_u6240_u6709"><a href="#u4E0D_u5339_u914D_u9ED8_u8BA4__u6253_u5370_u6240_u6709" class="headerlink" title="不匹配默认 打印所有"></a>不匹配默认 打印所有</h1><p>print re.split(“AAA”, “158158”) </p>
<h1 id="u8FD0_u884C_u7ED3_u679C-1"><a href="#u8FD0_u884C_u7ED3_u679C-1" class="headerlink" title="运行结果"></a>运行结果</h1><p>[‘Trouble’, ‘is’, ‘a’, ‘friend,’, ‘yeah’, ‘trouble’, ‘is’, ‘a’, ‘friend’, ‘of’, ‘mine.’]<br>[‘Trouble’, ‘is’, ‘a’, ‘friend, yeah trouble is a friend of mine.’]<br>[‘158158’]<br>Findall</p>
<p>搜索string，以列表形式返回全部能匹配的子串。</p>
<p><pre class="lang:default decode:true ">语法格式<br>re.findall(pattern, string[, flags]) | findall(string[, pos[, endpos]])</pre><br>举个栗子</p>
<p><pre class="lang:default decode:true">import re</pre></p>
<p>num = re.compile(r’\d+’)<br>print num.findall(‘one1two2three3’)</p>
<h1 id="u8FD0_u884C_u7ED3_u679C-2"><a href="#u8FD0_u884C_u7ED3_u679C-2" class="headerlink" title="运行结果"></a>运行结果</h1><p>[‘1’, ‘2’, ‘3’]<br>Finditer</p>
<p>搜索string，返回一个顺序访问每一个匹配结果（Match对象）的迭代器。</p>
<p><pre class="lang:default decode:true ">语法格式<br>re.finditer(pattern, string[, flags]) | finditer(string[, pos[, endpos]])</pre><br>举个栗子</p>
<p><pre class="lang:default decode:true ">import re</pre></p>
<p>num = re.compile(r’\d+’)</p>
<p>for item in num.finditer(‘one1two2three3’):<br>    print item.group(),</p>
<h1 id="u8FD0_u884C_u7ED3_u679C-3"><a href="#u8FD0_u884C_u7ED3_u679C-3" class="headerlink" title="运行结果"></a>运行结果</h1><p>1 2 3<br>Sub</p>
<p>返回的字符串是在字符串中用 RE 最左边不重复的匹配来替换。如果模式没有发现，字符将被没有改变地返回。</p>
<p>可选参数 count 是模式匹配后替换的最大次数；count 必须是非负整数。缺省值是 0 表示替换所有的匹配。</p>
<p><pre class="lang:default decode:true ">语法格式<br>re.sub(pattern, repl, string, count=0, flags=0)</pre><br>举个栗子</p>
<p><pre class="lang:default decode:true">import re</pre></p>
<p>phone = “6666-666-666 # This is Phone Number”</p>
<h1 id="Delete_comments"><a href="#Delete_comments" class="headerlink" title="Delete comments"></a>Delete comments</h1><p>num = re.sub(r’#.*$’, “”, phone)<br>print “Phone Num:”, num</p>
<h1 id="Remove_anything_other_than_digits"><a href="#Remove_anything_other_than_digits" class="headerlink" title="Remove anything other than digits"></a>Remove anything other than digits</h1><p>num = re.sub(r’\D’, “”, phone)<br>print “Phone Num:”, num</p>
<h1 id="u6267_u884C_u7ED3_u679C-2"><a href="#u6267_u884C_u7ED3_u679C-2" class="headerlink" title="执行结果"></a>执行结果</h1><p>Phone Num: 6666-666-666<br>Phone Num: 6666666666<br>Subn</p>
<p>与re.sub方法作用一样，但返回的是包含新字符串和替换执行次数的两元组。</p>
<p><pre class="lang:default decode:true ">语法格式<br>re.subn(pattern, repl, string, count=0, flags=0)</pre><br>举个栗子</p>
<p><pre class="lang:default decode:true ">import re</pre></p>
<p>phone = “6666-666-666 # This is Phone Number”</p>
<h1 id="Delete_comments-1"><a href="#Delete_comments-1" class="headerlink" title="Delete comments"></a>Delete comments</h1><p>num = re.subn(r’#.*$’, “”, phone)<br>print “Phone Num:”, num</p>
<h1 id="Remove_anything_other_than_digits-1"><a href="#Remove_anything_other_than_digits-1" class="headerlink" title="Remove anything other than digits"></a>Remove anything other than digits</h1><p>num = re.subn(r’\D’, “”, phone)<br>print “Phone Num:”, num</p>
<h1 id="u6267_u884C_u7ED3_u679C-3"><a href="#u6267_u884C_u7ED3_u679C-3" class="headerlink" title="执行结果"></a>执行结果</h1><p>Phone Num: (‘6666-666-666 ‘, 1)<br>Phone Num: (‘6666666666’, 25)<br>Compile</p>
<p>compile 函数根据一个模式字符串和可选的标志参数生成一个正则表达式对象。该对象拥有一系列方法用于正则表达式匹配和替换。</p>
<p><pre class="lang:default decode:true ">help(re.compile)<br>compile(pattern, flags=0)<br>    Compile a regular expression pattern, returning a pattern object.</pre><br>举个栗子</p>
<p><pre class="lang:default decode:true ">import os,re</pre></p>
<p>data_file = ‘/tmp/disk_info.csv.tmp’</p>
<p>with open(data_file, ‘w’) as f:<br>  for row in disk_info:<br>    spacetab = re.compile(“ +”)<br>    item = re.sub(spacetab, ‘,’, row)<br>    f.write(item)<br>f.close()<br>&nbsp;</p>
<blockquote>
<p><em>Notice</em></p>
<p><em>prog = re.compile(pattern)</em></p>
<p><em>result = prog.match(string)</em></p>
<p><em>与</em></p>
<p><em>result = re.match(pattern, string)</em></p>
<p><em>是等价的。</em></p>
<p><em>第一种方式能实现正则表达式的重用。</em><br>好了就啰嗦这么多吧。</p>
</blockquote>
<p>更多详细内容 请移步 <a href="https://docs.python.org/3/library/re.html?highlight=re#" target="_blank" rel="external">Python Standard Library</a></p>
<p>&nbsp;</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>上篇文章 <a href="http://suzf.net/thread-0422-806.html">Python正则表达式操作指南 </a>已经对正则表达式做出了详细的介绍。<br>下面只对 re 模块做出简要的说明。</p>
<p>元字符说明</p>
<p><pre class="lang:default decode:true ">.    匹配除换行符以外的任意字符<br>^    匹配字符串的开始<br>$    匹配字符串的结束<br>[]   用来匹配一个指定的字符类别<br>？   对于前一个字符字符重复0次到1次</p>
<ul>
<li>对于前一个字符重复0次到无穷次<br>{}   对于前一个字符重复m次<br>{m，n} 对前一个字符重复为m到n次<br>\d   匹配数字，相当于[0-9]<br>\D   匹配任何非数字字符，相当于[^0-9]<br>\s   匹配任意的空白符，相当于[ fv]<br>\S   匹配任何非空白字符，相当于[^ fv]<br>\w   匹配任何字母数字字符，相当于[a-zA-Z0-9<em>]<br>\W   匹配任何非字母数字字符，相当于[^a-zA-Z0-9</em>]<br>\b   匹配单词的开始或结束</pre>]]>
    
    </summary>
    
      <category term="Python" scheme="http://blog.suzf.net/tags/Python/"/>
    
      <category term="Re" scheme="http://blog.suzf.net/tags/Re/"/>
    
      <category term="Python" scheme="http://blog.suzf.net/categories/Python/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Python正则表达式操作指南]]></title>
    <link href="http://blog.suzf.net/2016/04/22/Python%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%93%8D%E4%BD%9C%E6%8C%87%E5%8D%97/"/>
    <id>http://blog.suzf.net/2016/04/22/Python正则表达式操作指南/</id>
    <published>2016-04-22T04:53:10.000Z</published>
    <updated>2016-04-29T12:43:02.000Z</updated>
    <content type="html"><![CDATA[<p><strong> 摘要</strong><br>本文是通过Python的 re 模块来使用正则表达式的一个入门教程，和库参考手册的对应章节相比，更为浅显易懂、循序渐进。</p>
<h3 id="u7B80_u4ECB"><a href="#u7B80_u4ECB" class="headerlink" title="简介"></a><span class="mw-headline">简介 </span></h3><p>Python 自1.5版本起增加了re 模块，它提供 Perl 风格的正则表达式模式。Python 1.5之前版本则是通过 regex 模块提供 Emacs 风格的模式。Emacs 风格模式可读性稍差些，而且功能也不强，因此编写新代码时尽量不要再使用 regex 模块，当然偶尔你还是可能在老代码里发现其踪影。<br>就其本质而言，正则表达式（或 RE）是一种小型的、高度专业化的编程语言，（在Python中）它内嵌在Python中，并通过 re 模块实现。使用这个小型语言，你可以为想要匹配的相应字符串集指定规则；该字符串集可能包含英文语句、e-mail地址、TeX命令或任何你想搞定的东 西。然后你可以问诸如“这个字符串匹配该模式吗？”或“在这个字符串中是否有部分匹配该模式呢？”。你也可以使用 RE 以各种方式来修改或分割字符串。<br>正则表达式模式被编译成一系列的字节码，然后由用 C 编写的匹配引擎执行。在高级用法中，也许还要仔细留意引擎是如何执行给定 RE ，如何以特定方式编写 RE 以令生产的字节码运行速度更快。本文并不涉及优化，因为那要求你已充分掌握了匹配引擎的内部机制。<br>正则表达式语言相对小型和受限（功能有限），因此并非所有字符串处理都能用正则表达式完成。当然也有些任务可以用正则表达式完成，不过最终表达式会变得异 常复杂。碰到这些情形时，编写 Python 代码进行处理可能反而更好；尽管 Python 代码比一个精巧的正则表达式要慢些，但它更易理解。</p>
<p>&nbsp;</p>
<h3 id="u7B80_u5355_u6A21_u5F0F"><a href="#u7B80_u5355_u6A21_u5F0F" class="headerlink" title="简单模式"></a><span class="mw-headline">简单模式 </span></h3><p>我们将从最简单的正则表达式学习开始。由于正则表达式常用于字符串操作，那我们就从最常见的任务：字符匹配 下手。<br>有关正则表达式底层的计算机科学上的详细解释（确定性和非确定性有限自动机），你可以查阅编写编译器相关的任何教科书。</p>
<p>&nbsp;</p>
<h4 id="u5B57_u7B26_u5339_u914D"><a href="#u5B57_u7B26_u5339_u914D" class="headerlink" title="字符匹配"></a><span class="mw-headline"> 字符匹配 </span></h4><p>大多数字母和字符一般都会和自身匹配。例如，正则表达式 test 会和字符串“test”完全匹配。（你也可以使用大小写不敏感模式，它还能让这个 RE 匹配“Test”或“TEST”；稍后会有更多解释。）</p>
<p>这个规则当然会有例外；有些字符比较特殊，它们和自身并不匹配，而是会表明应和一些特殊的东西匹配，或者它们会影响到 RE 其它部分的重复次数。本文很大篇幅专门讨论了各种元字符及其作用。</p>
<p>这里有一个元字符的完整列表；其含义会在本指南余下部分进行讨论。<a id="more"></a></p>
<pre class="">. ^ $ * + ? { [ ] \ | ( )</pre>
我们首先考察的元字符是"[" 和 "]"。它们常用来指定一个字符类别，所谓字符类别就是你想匹配的一个字符集。字符可以单个列出，也可以用“-”号分隔的两个给定字符来表示一个字符区 间。例如，[abc] 将匹配"a", "b", 或 "c"中的任意一个字符；也可以用区间[a-c]来表示同一字符集，和前者效果一致。如果你只想匹配小写字母，那么 RE 应写成 [a-z].

元字符在类别里并不起作用。例如，[akm$]将匹配字符"a", "k", "m", 或 "$" 中的任意一个；"$"通常用作元字符，但在字符类别里，其特性被除去，恢复成普通字符。

你可以用补集来匹配不在区间范围内的字符。其做法是把"^"作为类别的首个字符；其它地方的"^"只会简单匹配 "^"字符本身。例如，[^5] 将匹配除 "5" 之外的任意字符。

也许最重要的元字符是反斜杠"\"。 做为 Python 中的字符串字母，反斜杠后面可以加不同的字符以表示不同特殊意义。它也可以用于取消所有的元字符，这样你就可以在模式中匹配它们了。举个例子，如果你需要 匹配字符 "[" 或 "\"，你可以在它们之前用反斜杠来取消它们的特殊意义： \[ 或 \\。

一些用 "\" 开始的特殊字符所表示的预定义字符集通常是很有用的，象数字集，字母集，或其它非空字符集。下列是可用的预设特殊字符：
<pre class="">\d  匹配任何十进制数；它相当于类 [0-9]。
\D  匹配任何非数字字符；它相当于类 [^0-9]。
\s  匹配任何空白字符；它相当于类  [ \t\n\r\f\v]。
\S  匹配任何非空白字符；它相当于类 [^ \t\n\r\f\v]。
\w  匹配任何字母数字字符；它相当于类 [a-zA-Z0-9_]。
\W  匹配任何非字母数字字符；它相当于类 [^a-zA-Z0-9_]。
</pre>
这样特殊字符都可以包含在一个字符类中。如，[\s,.]字符类将匹配任何空白字符或","或"."。

本节最后一个元字符是 . 。它匹配除了换行字符外的任何字符，在 alternate 模式（re.DOTALL）下它甚至可以匹配换行。"." 通常被用于你想匹配“任何字符”的地方。

&nbsp;

#### <span class="mw-headline">重复 </span>

正则表达式第一件能做的事是能够匹配不定长的字符集，而这是其它能作用在字符串上的方法所不能做到的。 不过，如果那是正则表达式唯一的附加功能的话，那么它们也就不那么优秀了。它们的另一个功能就是你可以指定正则表达式的一部分的重复次数。

我们讨论的第一个重复功能的元字符是 *。* 并不匹配字母字符 "*"；相反，它指定前一个字符可以被匹配零次或更多次，而不是只有一次。

举个例子，ca*t 将匹配 "ct" (0 个 "a" 字符), "cat" (1 个 "a"), "caaat" (3 个 "a" 字符)等等。RE 引擎有各种来自 C 的整数类型大小的内部限制，以防止它匹配超过20亿个 "a" 字符；你也许没有足够的内存去建造那么大的字符串，所以将不会累计到那个限制。

象 * 这样地重复是“贪婪的”；当重复一个 RE 时，匹配引擎会试着重复尽可能多的次数。如果模式的后面部分没有被匹配，匹配引擎将退回并再次尝试更小的重复。
一步步的示例可以使它更加清晰。让我们考虑表达式 a[bcd]*b。它匹配字母 "a"，零个或更多个来自类 [bcd]中的字母，最后以 "b" 结尾。现在想一想该 RE 对字符串 "abcbd" 的匹配。
<table border="1" cellspacing="0">
<tbody>
<tr>
<td>Step</td>
<td>Matched</td>
<td>Explanation</td>
</tr>
<tr>
<td>1</td>
<td>a</td>
<td>a 匹配模式</td>
</tr>
<tr>
<td>2</td>
<td>abcbd</td>
<td>引擎匹配 [bcd]*，并尽其所能匹配到字符串的结尾</td>
</tr>
<tr>
<td>3</td>
<td>Failure</td>
<td>引擎尝试匹配 b，但当前位置已经是字符的最后了，所以失败</td>
</tr>
<tr>
<td>4</td>
<td>abcb</td>
<td>退回，[bcd]*尝试少匹配一个字符。</td>
</tr>
<tr>
<td>5</td>
<td>Failure</td>
<td>再次尝次b，但在当前最后一位字符是"d"。</td>
</tr>
<tr>
<td>6</td>
<td>abc</td>
<td>再次退回，[bcd]*只匹配 "bc"。</td>
</tr>
<tr>
<td>7</td>
<td>abcb</td>
<td>再次尝试 b ，这次当前位上的字符正好是 "b"</td>
</tr>
</tbody>
</table>
RE 的结尾部分现在可以到达了，它匹配 "abcb"。这证明了匹配引擎一开始会尽其所能进行匹配，如果没有匹配然后就逐步退回并反复尝试 RE 剩下来的部分。直到它退回尝试匹配 [bcd] 到零次为止，如果随后还是失败，那么引擎就会认为该字符串根本无法匹配 RE 。
另一个重复元字符是 +，表示匹配一或更多次。请注意 * 和 + 之间的不同；* 匹配零或更多次，所以可以根本就不出现，而 + 则要求至少出现一次。用同一个例子，ca+t 就可以匹配 "cat" (1 个 "a")， "caaat" (3 个 "a")， 但不能匹配 "ct"。
还有更多的限定符。问号 ? 匹配一次或零次；你可以认为它用于标识某事物是可选的。例如：home-?brew 匹配 "homebrew" 或 "home-brew"。
最复杂的重复限定符是 {m,n}(注意m,n之间不能有空格)，其中 m 和 n 是十进制整数。该限定符的意思是至少有 m 个重复，至多到 n 个重复。举个例子，a/{1,3}b 将匹配 "a/b"，"a//b" 和 "a///b"。它不能匹配 "ab" 因为没有斜杠，也不能匹配 "a////b" ，因为有四个。
你可以忽略 m 或 n；因为会为缺失的值假设一个合理的值。忽略 m 会认为下边界是 0，而忽略 n 的结果将是上边界为无穷大 -- 实际上是先前我们提到的20亿，但这也许同无穷大一样。
细心的读者也许注意到其他三个限定符都可以用这样方式来表示。 {0,} 等同于 *，{1,} 等同于 +，而{0,1}则与 ? 相同。如果可以的话，最好使用 *，+，或?。很简单因为它们更短也更容易懂。

&nbsp;

### <span class="mw-headline">使用正则表达式 </span>

现在我们已经看了一些简单的正则表达式，那么我们实际在 Python 中是如何使用它们的呢？ re 模块提供了一个正则表达式引擎的接口，可以让你将 REs 编译成对象并用它们来进行匹配。

&nbsp;

#### <span class="mw-headline">编译正则表达式 </span>

正则表达式被编译成 `RegexObject` 实例，可以为不同的操作提供方法，如模式匹配搜索或字符串替换。
<pre class="lang:default decode:true ">#python
&gt;&gt;&gt; import re
&gt;&gt;&gt; p = re.compile('ab*')
&gt;&gt;&gt; print p
&lt;_sre.SRE_Pattern object at 0xb76e1a70&gt;</pre>
re.compile() 也接受可选的标志参数，常用来实现不同的特殊功能和语法变更。我们稍后将查看所有可用的设置，但现在只举一个例子：
<pre class="lang:default decode:true">#!python
&gt;&gt;&gt; p = re.compile('ab*', re.IGNORECASE)</pre>
RE 被做为一个字符串发送给 re.compile()。REs 被处理成字符串是因为正则表达式不是 Python 语言的核心部分，也没有为它创建特定的语法。（应用程序根本就不需要 REs，因此没必要包含它们去使语言说明变得臃肿不堪。）而 re 模块则只是以一个 C 扩展模块的形式来被 Python 包含，就象 socket 或 zlib 模块一样
将 REs 作为字符串以保证 Python 语言的简洁，但这样带来的一个麻烦就是象下节标题所讲的。

&nbsp;

#### <span class="mw-headline">反斜杠的麻烦 </span>

在早期规定中，正则表达式用反斜杠字符 ("\") 来表示特殊格式或允许使用特殊字符而不调用它的特殊用法。这就与 Python 在字符串中的那些起相同作用的相同字符产生了冲突。
让我们举例说明，你想写一个 RE 以匹配字符串 "\section"，可能是在一个 LATEX 文件查找。为了要在程序代码中判断，首先要写出想要匹配的字符串。接下来你需要在所有反斜杠和其它元字符前加反斜杠来取消其特殊意义，结果要匹配的字符串 就成了"\\section"。 当把这个字符串传递给re.compile()时必须还是"\\section"。然而，作为Python的字符串实值(string literals)来表示的话，"\\section"中两个反斜杠还要再次取消特殊意义，最后结果就变成了"\\\\section"。
<table border="1" cellspacing="0">
<tbody>
<tr>
<td>字符</td>
<td>阶段</td>
</tr>
<tr>
<td>\section</td>
<td>要匹配的字符串</td>
</tr>
<tr>
<td>\\section</td>
<td>为 re.compile 取消反斜杠的特殊意义</td>
</tr>
<tr>
<td>"\\\\section"</td>
<td>为"\\section"的字符串实值(string literals)取消反斜杠的特殊意义</td>
</tr>
</tbody>
</table>
简单地说，为了匹配一个反斜杠，不得不在 RE 字符串中写 '\\\\'，因为正则表达式中必须是 "\\"，而每个反斜杠在常规的 Python 字符串实值中必须表示成 "\\"。在 REs 中反斜杠的这个重复特性会导致大量重复的反斜杠，而且所生成的字符串也很难懂。

解决的办法就是为正则表达式使用 Python 的 raw 字符串表示；在字符串前加个 "r" 反斜杠就不会被任何特殊方式处理，所以 r"\n" 就是包含"\" 和 "n" 的两个字符，而 "\n" 则是一个字符，表示一个换行。正则表达式通常在 Python 代码中都是用这种 raw 字符串表示。
<table border="1" cellspacing="0">
<tbody>
<tr>
<td>常规字符串</td>
<td>Raw 字符串</td>
</tr>
<tr>
<td>"ab*"</td>
<td>r"ab*"</td>
</tr>
<tr>
<td>"\\\\section"</td>
<td>r"\\section"</td>
</tr>
<tr>
<td>"\\w+\\s+\\1"</td>
<td>r"\w+\s+\1"</td>
</tr>
</tbody>
</table>
&nbsp;

#### <span class="mw-headline"> 执行匹配 </span>

一旦你有了已经编译了的正则表达式的对象，你要用它做什么呢？`RegexObject` 实例有一些方法和属性。这里只显示了最重要的几个，如果要看完整的列表请查阅 Python Library Reference
<table border="1" cellspacing="0">
<tbody>
<tr>
<td>方法/属性</td>
<td>作用</td>
</tr>
<tr>
<td>match()</td>
<td>决定 RE 是否在字符串刚开始的位置匹配</td>
</tr>
<tr>
<td>search()</td>
<td>扫描字符串，找到这个 RE 匹配的位置</td>
</tr>
<tr>
<td>findall()</td>
<td>找到 RE 匹配的所有子串，并把它们作为一个列表返回</td>
</tr>
<tr>
<td>finditer()</td>
<td>找到 RE 匹配的所有子串，并把它们作为一个迭代器返回</td>
</tr>
</tbody>
</table>
如果没有匹配到的话，match() 和 search() 将返回 None。如果成功的话，就会返回一个 `MatchObject` 实例，其中有这次匹配的信息：它是从哪里开始和结束，它所匹配的子串等等。

你可以用采用人机对话并用 re 模块实验的方式来学习它。如果你有 Tkinter 的话，你也许可以考虑参考一下 Tools/scripts/redemo.py，一个包含在 Python 发行版里的示范程序。

首先，运行 Python 解释器，导入 re 模块并编译一个 RE：
<pre class="lang:default decode:true">#!python
Python 2.2.2 (#1, Feb 10 2003, 12:57:01)
&gt;&gt;&gt; import re
&gt;&gt;&gt; p = re.compile('[a-z]+')
&gt;&gt;&gt; p
&lt;_sre.SRE_Pattern object at 80c3c28&gt;</pre>
现在，你可以试着用 RE 的 [a-z]+ 去匹配不同的字符串。一个空字符串将根本不能匹配，因为 + 的意思是 “一个或更多的重复次数”。 在这种情况下 match() 将返回 None，因为它使解释器没有输出。你可以明确地打印出 match() 的结果来弄清这一点。
<pre class="lang:default decode:true">#!python
&gt;&gt;&gt; p.match("")
&gt;&gt;&gt; print p.match("")
None</pre>
现在，让我们试着用它来匹配一个字符串，如 "tempo"。这时，match() 将返回一个 MatchObject。因此你可以将结果保存在变量里以便後面使用。
<pre class="lang:default decode:true">#!python
&gt;&gt;&gt; m = p.match( 'tempo')
&gt;&gt;&gt; print m
&lt;_sre.SRE_Match object at 80c4f68&gt;</pre>
现在你可以查询 `MatchObject` 关于匹配字符串的相关信息了。MatchObject 实例也有几个方法和属性；最重要的那些如下所示：
<table border="1" cellspacing="0">
<tbody>
<tr>
<td>方法/属性</td>
<td>作用</td>
</tr>
<tr>
<td>group()</td>
<td>返回被 RE 匹配的字符串</td>
</tr>
<tr>
<td>start()</td>
<td>返回匹配开始的位置</td>
</tr>
<tr>
<td>end()</td>
<td>返回匹配结束的位置</td>
</tr>
<tr>
<td>span()</td>
<td>返回一个元组包含匹配 (开始,结束) 的位置</td>
</tr>
</tbody>
</table>
试试这些方法不久就会清楚它们的作用了：
<pre class="lang:default decode:true">#!python
&gt;&gt;&gt; m.group()
'tempo'
&gt;&gt;&gt; m.start(), m.end()
(0, 5)
&gt;&gt;&gt; m.span()
(0, 5)</pre>
group() 返回 RE 匹配的子串。start() 和 end() 返回匹配开始和结束时的索引。span() 则用单个元组把开始和结束时的索引一起返回。因为匹配方法检查到如果 RE 在字符串开始处开始匹配，那么 start() 将总是为零。然而， `RegexObject` 实例的 search 方法扫描下面的字符串的话，在这种情况下，匹配开始的位置就也许不是零了。
<pre class="lang:default decode:true">#!python
&gt;&gt;&gt; print p.match('::: message')
None
&gt;&gt;&gt; m = p.search('::: message') ; print m
&lt;re.MatchObject instance at 80c9650&gt;
&gt;&gt;&gt; m.group()
'message'
&gt;&gt;&gt; m.span()
(4, 11)</pre>
在实际程序中，最常见的作法是将 `MatchObject` 保存在一个变量里，然後检查它是否为 None，通常如下所示：
<pre class="lang:default decode:true">#!python
p = re.compile( ... )
m = p.match( 'string goes here' )
if m:
print 'Match found: ', m.group()
else:
print 'No match'</pre>
两个 `RegexObject` 方法返回所有匹配模式的子串。findall()返回一个匹配字符串行表：
<pre class="lang:default decode:true">#!python
&gt;&gt;&gt; p = re.compile('\d+')
&gt;&gt;&gt; p.findall('12 drummers drumming, 11 pipers piping, 10 lords a-leaping')
['12', '11', '10']</pre>
findall() 在它返回结果时不得不创建一个列表。在 Python 2.2中，也可以用 finditer() 方法。
<pre class="lang:default decode:true">#!python
&gt;&gt;&gt; iterator = p.finditer('12 drummers drumming, 11 ... 10 ...')
&gt;&gt;&gt; iterator
&lt;callable-iterator object at 0x401833ac&gt;
&gt;&gt;&gt; for match in iterator:
...     print match.span()
...
(0, 2)
(22, 24)
(29, 31)</pre>

<h4 id="u6A21_u5757_u7EA7_u51FD_u6570"><a href="#u6A21_u5757_u7EA7_u51FD_u6570" class="headerlink" title="模块级函数"></a><span class="mw-headline">模块级函数 </span></h4><p>你不一定要产生一个 <code>RegexObject</code> 对象然后再调用它的方法；re 模块也提供了顶级函数调用如 match()、search()、sub() 等等。这些函数使用 RE 字符串作为第一个参数，而后面的参数则与相应 <code>RegexObject</code> 的方法参数相同，返回则要么是 None 要么就是一个 <code>MatchObject</code> 的实例。</p>
<p><pre class="lang:default decode:true">#!python<br>&gt;&gt;&gt; print re.match(r’From\s+’, ‘Fromage amk’)<br>None<br>&gt;&gt;&gt; re.match(r’From\s+’, ‘From amk Thu May 14 19:12:10 1998’)<br>&lt;re.MatchObject instance at 80c5978&gt;</pre><br>Under the hood, 这些函数简单地产生一个 RegexOject 并在其上调用相应的方法。它们也在缓存里保存编译后的对象，因此在将来调用用到相同 RE 时就会更快。<br>你将使用这些模块级函数，还是先得到一个 <code>RegexObject</code> 再调用它的方法呢？如何选择依赖于怎样用 RE 更有效率以及你个人编码风格。如果一个 RE 在代码中只做用一次的话，那么模块级函数也许更方便。如果程序包含很多的正则表达式，或在多处复用同一个的话，那么将全部定义放在一起，在一段代码中提前 编译所有的 REs 更有用。从标准库中看一个例子，这是从 xmllib.py 文件中提取出来的：</p>
<p><pre class="lang:default decode:true">#!python<br>ref = re.compile( … )<br>entityref = re.compile( … )<br>charref = re.compile( … )<br>starttagopen = re.compile( … )</pre><br>我通常更喜欢使用编译对象，甚至它只用一次，但很少人会像我这样做(如同一个纯粹主义者)。</p>
<p>&nbsp;</p>
<h4 id="u7F16_u8BD1_u6807_u5FD7"><a href="#u7F16_u8BD1_u6807_u5FD7" class="headerlink" title="编译标志"></a><span class="mw-headline">编译标志 </span></h4><p>编译标志让你可以修改正则表达式的一些运行方式。在 re 模块中标志可以使用两个名字，一个是全名如 IGNORECASE，一个是缩写，一字母形式如 I。（如果你熟悉 Perl 的模式修改，一字母形式使用同样的字母；例如 re.VERBOSE的缩写形式是 re.X。）多个标志可以通过按位 OR-ing 它们来指定。如 re.I | re.M 被设置成 I 和 M 标志：<br>这有个可用标志表，对每个标志后面都有详细的说明。</p>
<p><table border="1" cellspacing="0"></table></p>
<p><tbody></tbody></p>
<p><tr></tr></p>
<p><td>标志</td></p>
<p><td>含义</td><br></p>
<p><tr></tr></p>
<p><td>DOTALL, S</td></p>
<p><td>使 . 匹配包括换行在内的所有字符</td><br></p>
<p><tr></tr></p>
<p><td>IGNORECASE, I</td></p>
<p><td>使匹配对大小写不敏感</td><br></p>
<p><tr></tr></p>
<p><td>LOCALE, L</td></p>
<p><td>做本地化识别（locale-aware）匹配</td><br></p>
<p><tr></tr></p>
<p><td>MULTILINE, M</td></p>
<p><td>多行匹配，影响 ^ 和 $</td><br></p>
<p><tr></tr></p>
<p><td>VERBOSE, X</td></p>
<p><td>能够使用 REs 的 verbose 状态，使之被组织得更清晰易懂</td><br><br><br><br><strong>I</strong><br><strong>IGNORECASE</strong></p>
<p>使匹配对大小写不敏感；字符类和字符串匹配字母时忽略大小写。举个例子，[A-Z]也可以匹配小写字母，Spam 可以匹配 “Spam”, “spam”, 或 “spAM”。这个小写字母并不考虑当前位置。</p>
<p><strong>L</strong><br><strong>LOCALE</strong></p>
<p>影响 \w, \W, \b, 和 \B，这取决于当前的本地化设置。</p>
<p>locales 是 C 语言库中的一项功能，是用来为需要考虑不同语言的编程提供帮助的。举个例子，如果你正在处理法文文本，你想用 \w+ 来匹配文字，但 \w 只匹配字符类 [A-Za-z]；它并不能匹配 “é” 或 “ç”。如果你的系统配置适当且本地化设置为法语，那么内部的 C 函数将告诉程序 “é” 也应该被认为是一个字母。当在编译正则表达式时使用 LOCALE 标志会得到用这些 C 函数来处理 \w 后的编译对象；这会更慢，但也会象你希望的那样可以用 \w+ 来匹配法文文本。</p>
<p><strong>M</strong><br><strong>MULTILINE</strong><br>(此时 ^ 和 $ 不会被解释; 它们将在 4.1 节被介绍.)<br>使用 “^” 只匹配字符串的开始，而 $ 则只匹配字符串的结尾和直接在换行前（如果有的话）的字符串结尾。当本标志指定后， “^” 匹配字符串的开始和字符串中每行的开始。同样的， $ 元字符匹配字符串结尾和字符串中每行的结尾（直接在每个换行之前）。</p>
<p><strong>S</strong><br><strong>DOTALL</strong></p>
<p>使 “.” 特殊字符完全匹配任何字符，包括换行；没有这个标志， “.” 匹配除了换行外的任何字符。</p>
<p><strong>X</strong><br><strong>VERBOSE</strong><br>该标志通过给予你更灵活的格式以便你将正则表达式写得更易于理解。当该标志被指定时，在 RE 字符串中的空白符被忽略，除非该空白符在字符类中或在反斜杠之后；这可以让你更清晰地组织和缩进 RE。它也可以允许你将注释写入 RE，这些注释会被引擎忽略；注释用 “#”号 来标识，不过该符号不能在字符串或反斜杠之后。<br>举个例子，这里有一个使用 re.VERBOSE 的 RE；看看读它轻松了多少？</p>
<p><pre class="lang:default decode:true">#!python<br>charref = re.compile(r”””&amp;[[]]           # Start of a numeric entity reference|||here has wrong.i can’t fix<br>(<br>[0-9]+[^0-9]      # Decimal form<br>| 0[0-7]+[^0-7]   # Octal form<br>| x[0-9a-fA-F]+[^0-9a-fA-F] # Hexadecimal form<br>)<br>“””, re.VERBOSE)</pre><br>没有 verbose 设置， RE 会看起来象这样：</p>
<p><pre class="lang:default decode:true">#!python<br>charref = re.compile(“&amp;#([0-9]+[^0-9]”<br>“|0[0-7]+[^0-7]”<br>“|x[0-9a-fA-F]+[^0-9a-fA-F])”)</pre><br>在上面的例子里，Python 的字符串自动连接可以用来将 RE 分成更小的部分，但它比用 re.VERBOSE 标志时更难懂</p>
<p>&nbsp;</p>
<h3 id="u66F4_u591A_u6A21_u5F0F_u529F_u80FD"><a href="#u66F4_u591A_u6A21_u5F0F_u529F_u80FD" class="headerlink" title="更多模式功能"></a><span class="mw-headline">更多模式功能 </span></h3><p>到目前为止，我们只展示了正则表达式的一部分功能。在本节，我们将展示一些新的元字符和如何使用组来检索被匹配的文本部分。</p>
<p>== ==</p>
<p>&nbsp;</p>
<h4 id="u66F4_u591A_u7684_u5143_u5B57_u7B26"><a href="#u66F4_u591A_u7684_u5143_u5B57_u7B26" class="headerlink" title="更多的元字符"></a><span class="mw-headline">更多的元字符 </span></h4><p><strong>粗体文字</strong><a href="http://www.example.com" title="http://www.example.com" target="_blank" rel="external">链接标题</a>还有一些我们还没展示的元字符，其中的大部分将在本节展示。<br>剩下来要讨论的一部分元字符是零宽界定符（zero-width assertions）。它们并不会使引擎在处理字符串时更快;相反，它们根本就没有对应任何字符，只是简单的成功或失败。举个例子， \b 是一个在单词边界定位当前位置的界定符（assertions），这个位置根本就不会被 \b 改变。这意味着零宽界定符（zero-width assertions）将永远不会被重复，因为如果它们在给定位置匹配一次，那么它们很明显可以被匹配无数次。</p>
<p><strong>|</strong><br>可选项，或者 “or” 操作符。如果 A 和 B 是正则表达式，A|B 将匹配任何匹配了 “A” 或 “B” 的字符串。| 的优先级非常低，是为了当你有多字符串要选择时能适当地运行。Crow|Servo 将匹配”Crow” 或 “Servo”, 而不是 “Cro”, 一个 “w” 或 一个 “S”, 和 “ervo”。<br>为了匹配字母 “|”，可以用 |，或将其包含在字符类中，如[|]。</p>
<p><strong>^</strong><br>匹配行首。除非设置 MULTILINE 标志，它只是匹配字符串的开始。在 MULTILINE 模式里，它也可以直接匹配字符串中的每个换行。<br>例如，如果你只希望匹配在行首单词 “From”，那么 RE 将用 ^From。</p>
<p><pre class="lang:default decode:true">#!python<br>&gt;&gt;&gt; print re.search(‘^From’, ‘From Here to Eternity’)<br>&lt;re.MatchObject instance at 80c1520&gt;<br>&gt;&gt;&gt; print re.search(‘^From’, ‘Reciting From Memory’)<br>None</pre><br><strong>$</strong><br>匹配行尾，行尾被定义为要么是字符串尾，要么是一个换行字符后面的任何位置。</p>
<p><pre class="lang:default decode:true">#!python<br>&gt;&gt;&gt; print re.search(‘}$’, ‘{block}’)<br>&lt;re.MatchObject instance at 80adfa8&gt;<br>&gt;&gt;&gt; print re.search(‘}$’, ‘{block} ‘)<br>None<br>&gt;&gt;&gt; print re.search(‘}$’, ‘{block}\n’)<br>&lt;re.MatchObject instance at 80adfa8&gt;</pre><br>匹配一个 “$”，使用 \$ 或将其包含在字符类中，如[$]。</p>
<p><strong>\A</strong><br>只匹配字符串首。当不在 MULTILINE 模式，\A 和 ^ 实际上是一样的。然而，在 MULTILINE 模式里它们是不同的；\A 只是匹配字符串首，而 ^ 还可以匹配在换行符之后字符串的任何位置。</p>
<p><strong>\Z</strong></p>
<p>Matches only at the end of the string.<br>只匹配字符串尾。</p>
<p><strong>\b</strong></p>
<p>单词边界。这是个零宽界定符（zero-width assertions）只用以匹配单词的词首和词尾。单词被定义为一个字母数字序列，因此词尾就是用空白符或非字母数字符来标示的。<br>下面的例子只匹配 “class” 整个单词；而当它被包含在其他单词中时不匹配。</p>
<p><pre class="lang:default decode:true">#!python<br>&gt;&gt;&gt; p = re.compile(r’\bclass\b’)<br>&gt;&gt;&gt; print p.search(‘no class at all’)<br>&lt;re.MatchObject instance at 80c8f28&gt;<br>&gt;&gt;&gt; print p.search(‘the declassified algorithm’)<br>None<br>&gt;&gt;&gt; print p.search(‘one subclass is’)<br>None</pre><br>当用这个特殊序列时你应该记住这里有两个微妙之处。第一个是 Python 字符串和正则表达式之间最糟的冲突。在 Python 字符串里，”\b” 是反斜杠字符，ASCII值是8。如果你没有使用 raw 字符串时，那么 Python 将会把 “\b” 转换成一个回退符，你的 RE 将无法象你希望的那样匹配它了。下面的例子看起来和我们前面的 RE 一样，但在 RE 字符串前少了一个 “r” 。</p>
<p><pre class="lang:default decode:true">#!python<br>&gt;&gt;&gt; p = re.compile(‘\bclass\b’)<br>&gt;&gt;&gt; print p.search(‘no class at all’)<br>None<br>&gt;&gt;&gt; print p.search(‘\b’ + ‘class’ + ‘\b’)<br>&lt;re.MatchObject instance at 80c3ee0&gt;</pre><br>第二个在字符类中，这个限定符（assertion）不起作用，\b 表示回退符，以便与 Python 字符串兼容。</p>
<p><strong>\B</strong><br>另一个零宽界定符（zero-width assertions），它正好同 \b 相反，只在当前位置不在单词边界时匹配。</p>
<p>&nbsp;</p>
<h4 id="u5206_u7EC4"><a href="#u5206_u7EC4" class="headerlink" title="分组"></a><span class="mw-headline">分组 </span></h4><p>你经常需要得到比 RE 是否匹配还要多的信息。正则表达式常常用来分析字符串，编写一个 RE 匹配感兴趣的部分并将其分成几个小组。举个例子，一个 RFC-822 的头部用 “:” 隔成一个头部名和一个值，这就可以通过编写一个正则表达式匹配整个头部，用一组匹配头部名，另一组匹配头部值的方式来处理。<br>组是通过 “(“ 和 “)” 元字符来标识的。 “(“ 和 “)” 有很多在数学表达式中相同的意思；它们一起把在它们里面的表达式组成一组。举个例子，你可以用重复限制符，象 <em>, +, ?, 和 {m,n}，来重复组里的内容，比如说(ab)</em> 将匹配零或更多个重复的 “ab”。</p>
<p><pre class="lang:default decode:true">#!python<br>&gt;&gt;&gt; p = re.compile(‘(ab)*’)<br>&gt;&gt;&gt; print p.match(‘ababababab’).span()<br>(0, 10)</pre><br>组用 “(“ 和 “)” 来指定，并且得到它们匹配文本的开始和结尾索引；这就可以通过一个参数用 group()、start()、end() 和 span() 来进行检索。组是从 0 开始计数的。组 0 总是存在；它就是整个 RE，所以 <code>MatchObject</code> 的方法都把组 0 作为它们缺省的参数。稍后我们将看到怎样表达不能得到它们所匹配文本的 span。</p>
<p><pre class="lang:default decode:true">#!python<br>&gt;&gt;&gt; p = re.compile(‘(a)b’)<br>&gt;&gt;&gt; m = p.match(‘ab’)<br>&gt;&gt;&gt; m.group()<br>‘ab’<br>&gt;&gt;&gt; m.group(0)<br>‘ab’</pre><br>小组是从左向右计数的，从1开始。组可以被嵌套。计数的数值可以通过从左到右计算打开的括号数来确定。</p>
<p><pre class="lang:default decode:true">#!python<br>&gt;&gt;&gt; p = re.compile(‘(a(b)c)d’)<br>&gt;&gt;&gt; m = p.match(‘abcd’)<br>&gt;&gt;&gt; m.group(0)<br>‘abcd’<br>&gt;&gt;&gt; m.group(1)<br>‘abc’<br>&gt;&gt;&gt; m.group(2)<br>‘b’</pre><br>group() 可以一次输入多个组号，在这种情况下它将返回一个包含那些组所对应值的元组。</p>
<p><pre class="lang:default decode:true">#!python<br>&gt;&gt;&gt; m.group(2,1,2)<br>(‘b’, ‘abc’, ‘b’)</pre><br>The groups() 方法返回一个包含所有小组字符串的元组，从 1 到 所含的小组号。</p>
<p><pre class="lang:default decode:true">#!python<br>&gt;&gt;&gt; m.groups()<br>(‘abc’, ‘b’)</pre><br>模式中的逆向引用允许你指定先前捕获组的内容，该组也必须在字符串当前位置被找到。举个例子，如果组 1 的内容能够在当前位置找到的话，\1 就成功否则失败。记住 Python 字符串也是用反斜杠加数据来允许字符串中包含任意字符的，所以当在 RE 中使用逆向引用时确保使用 raw 字符串。<br>例如，下面的 RE 在一个字符串中找到成双的词。</p>
<p><pre class="lang:default decode:true">#!python<br>&gt;&gt;&gt; p = re.compile(r’(\b\w+)\s+\1’)<br>&gt;&gt;&gt; p.search(‘Paris in the the spring’).group()<br>‘the the’</pre><br>象这样只是搜索一个字符串的逆向引用并不常见 – 用这种方式重复数据的文本格式并不多见 – 但你不久就可以发现它们用在字符串替换上非常有用。</p>
<p>&nbsp;</p>
<h4 id="u65E0_u6355_u83B7_u7EC4_u548C_u547D_u540D_u7EC4"><a href="#u65E0_u6355_u83B7_u7EC4_u548C_u547D_u540D_u7EC4" class="headerlink" title="无捕获组和命名组"></a><span class="mw-headline">无捕获组和命名组 </span></h4><p>精心设计的 REs 也许会用很多组，既可以捕获感兴趣的子串，又可以分组和结构化 RE 本身。在复杂的 REs 里，追踪组号变得困难。有两个功能可以对这个问题有所帮助。它们也都使用正则表达式扩展的通用语法，因此我们来看看第一个。<br>Perl 5 对标准正则表达式增加了几个附加功能，Python 的 re 模块也支持其中的大部分。选择一个新的单按键元字符或一个以 “\” 开始的特殊序列来表示新的功能，而又不会使 Perl 正则表达式与标准正则表达式产生混乱是有难度的。如果你选择 “&amp;” 做为新的元字符，举个例子，老的表达式认为 “&amp;” 是一个正常的字符，而不会在使用 \&amp; 或 [&amp;] 时也不会转义。<br>Perl 开发人员的解决方法是使用 (?…) 来做为扩展语法。”?” 在括号后面会直接导致一个语法错误，因为 “?” 没有任何字符可以重复，因此它不会产生任何兼容问题。紧随 “?” 之后的字符指出扩展的用途，因此 (?=foo)<br>Python 新增了一个扩展语法到 Perl 扩展语法中。如果在问号后的第一个字符是 “P”，你就可以知道它是针对 Python 的扩展。目前有两个这样的扩展: (?P&lt;name&gt;…) 定义一个命名组，(?P=name) 则是对命名组的逆向引用。如果 Perl 5 的未来版本使用不同的语法增加了相同的功能，那么 re 模块也将改变以支持新的语法，与此同时为了兼容性的目的而继续保持的 Python 专用语法。<br>现在我们看一下普通的扩展语法，我们回过头来简化在复杂 REs 中使用组运行的特性。因为组是从左到右编号的，而且一个复杂的表达式也许会使用许多组，它可以使跟踪当前组号变得困难，而修改如此复杂的 RE 是十分麻烦的。在开始时插入一个新组，你可以改变它之后的每个组号。<br>首先，有时你想用一个组去收集正则表达式的一部分，但又对组的内容不感兴趣。你可以用一个无捕获组: (?:…) 来实现这项功能，这样你可以在括号中发送任何其他正则表达式。</p>
<p><pre class="lang:default decode:true">#!python<br>&gt;&gt;&gt; m = re.match(“([abc])+”, “abc”)<br>&gt;&gt;&gt; m.groups()<br>(‘c’,)<br>&gt;&gt;&gt; m = re.match(“(?:[abc])+”, “abc”)<br>&gt;&gt;&gt; m.groups()<br>()</pre><br>除了捕获匹配组的内容之外，无捕获组与捕获组表现完全一样；你可以在其中放置任何字符，可以用重复元字符如 “*” 来重复它，可以在其他组（无捕获组与捕获组）中嵌套它。(?:…) 对于修改已有组尤其有用，因为你可以不用改变所有其他组号的情况下添加一个新组。捕获组和无捕获组在搜索效率方面也没什么不同，没有哪一个比另一个更快。<br>其次，更重要和强大的是命名组；与用数字指定组不同的是，它可以用名字来指定。<br>命令组的语法是 Python 专用扩展之一： (?P&lt;name&gt;…)。名字很明显是组的名字。除了该组有个名字之外，命名组也同捕获组是相同的。<code>MatchObject</code> 的方法处理捕获组时接受的要么是表示组号的整数，要么是包含组名的字符串。命名组也可以是数字，所以你可以通过两种方式来得到一个组的信息：</p>
<p><pre class="lang:default decode:true">#!python<br>&gt;&gt;&gt; p = re.compile(r’(?P&lt;word&gt;\b\w+\b)’)<br>&gt;&gt;&gt; m = p.search( ‘(((( Lots of punctuation )))’ )<br>&gt;&gt;&gt; m.group(‘word’)<br>‘Lots’<br>&gt;&gt;&gt; m.group(1)<br>‘Lots’</pre><br>命名组是便于使用的，因为它可以让你使用容易记住的名字来代替不得不记住的数字。这里有一个来自 imaplib 模块的 RE 示例：</p>
<p><pre class="lang:default decode:true">#!python<br>InternalDate = re.compile(r’INTERNALDATE “‘<br>r’(?P&lt;day&gt;[ 123][0-9])-(?P&lt;mon&gt;[A-Z][a-z][a-z])-‘<br>  r’(?P&lt;year&gt;[0-9][0-9][0-9][0-9])’<br>r’ (?P&lt;hour&gt;[0-9][0-9]):(?P&lt;min&gt;[0-9][0-9]):(?P&lt;sec&gt;[0-9][0-9])’<br>r’ (?P&lt;zonen&gt;[-+])(?P&lt;zoneh&gt;[0-9][0-9])(?P&lt;zonem&gt;[0-9][0-9])’<br>r’”‘)</pre><br>很明显，得到 m.group(‘zonem’) 要比记住得到组 9 要容易得多。<br>因为逆向引用的语法，象 (…)\1 这样的表达式所表示的是组号，这时用组名代替组号自然会有差别。还有一个 Python 扩展：(?P=name) ，它可以使叫 name 的组内容再次在当前位置发现。正则表达式为了找到重复的单词，(\b\w+)\s+\1 也可以被写成 (?P&lt;word&gt;\b\w+)\s+(?P=word)：</p>
<p><pre class="lang:default decode:true">#!python<br>&gt;&gt;&gt; p = re.compile(r’(?P&lt;word&gt;\b\w+)\s+(?P=word)’)<br>&gt;&gt;&gt; p.search(‘Paris in the the spring’).group()<br>‘the the’</pre><br>&nbsp;</p>
<h4 id="u524D_u5411_u754C_u5B9A_u7B26"><a href="#u524D_u5411_u754C_u5B9A_u7B26" class="headerlink" title="前向界定符"></a><span class="mw-headline">前向界定符 </span></h4><p>另一个零宽界定符（zero-width assertion）是前向界定符。前向界定符包括前向肯定界定符和前项否定界定符，如下所示：</p>
<p><strong>(?=…)</strong></p>
<p>前向肯定界定符。如果所含正则表达式，以 … 表示，在当前位置成功匹配时成功，否则失败。但一旦所含表达式已经尝试，匹配引擎根本没有提高；模式的剩余部分还要尝试界定符的右边。</p>
<p><strong>(?!…)</strong></p>
<p>前向否定界定符。与肯定界定符相反；当所含表达式不能在字符串当前位置匹配时成功<br>通过示范在哪前向可以成功有助于具体实现。考虑一个简单的模式用于匹配一个文件名，并将其通过 “.” 分成基本名和扩展名两部分。如在 “news.rc” 中，”news” 是基本名，”rc” 是文件的扩展名。<br>匹配模式非常简单：</p>
<p><pre>.<em>[.].</em>$<br></pre><br>注意 “.” 需要特殊对待，因为它是一个元字符；我把它放在一个字符类中。另外注意后面的 $; 添加这个是为了确保字符串所有的剩余部分必须被包含在扩展名中。这个正则表达式匹配 “foo.bar”、”autoexec.bat”、 “sendmail.cf” 和 “printers.conf”。<br>现在，考虑把问题变得复杂点；如果你想匹配的扩展名不是 “bat” 的文件名？一些不正确的尝试：</p>
<p><pre>.<em>[.][^b].</em>$<br></pre><br>上面的第一次去除 “bat” 的尝试是要求扩展名的第一个字符不是 “b”。这是错误的，因为该模式也不能匹配 “foo.bar”。</p>
<p><pre>.*<a href="/[^b]..|.[^a].|..[^t]">.</a>$<br></pre><br>当你试着修补第一个解决方法而要求匹配下列情况之一时表达式更乱了：扩展名的第一个字符不是 “b”; 第二个字符不是 “a”；或第三个字符不是 “t”。这样可以接受 “foo.bar” 而拒绝 “autoexec.bat”，但这要求只能是三个字符的扩展名而不接受两个字符的扩展名如 “sendmail.cf”。我们将在努力修补它时再次把该模式变得复杂。</p>
<p><pre>.*<a href="/[^b].?.?|.[^a]?.?|..?[^t]?">.</a>$<br></pre><br>在第三次尝试中，第二和第三个字母都变成可选，为的是允许匹配比三个字符更短的扩展名，如 “sendmail.cf”。<br>该模式现在变得非常复杂，这使它很难读懂。更糟的是，如果问题变化了，你想扩展名不是 “bat” 和 “exe”，该模式甚至会变得更复杂和混乱。<br>前向否定把所有这些裁剪成：</p>
<p><pre>.<em><a href="/?!bat$">.</a>.</em>$<br></pre><br>前向的意思：如果表达式 bat 在这里没有匹配，尝试模式的其余部分；如果 bat$ 匹配，整个模式将失败。后面的 $ 被要求是为了确保象 “sample.batch” 这样扩展名以 “bat” 开头的会被允许。<br>将另一个文件扩展名排除在外现在也容易；简单地将其做为可选项放在界定符中。下面的这个模式将以 “bat” 或 “exe” 结尾的文件名排除在外。</p>
<p><pre>.<em><a href="/?!bat$|exe$">.</a>.</em>$<br></pre><br>&nbsp;</p>
<h3 id="u4FEE_u6539_u5B57_u7B26_u4E32"><a href="#u4FEE_u6539_u5B57_u7B26_u4E32" class="headerlink" title="修改字符串"></a><span class="mw-headline">修改字符串 </span></h3><p>到目前为止，我们简单地搜索了一个静态字符串。正则表达式通常也用不同的方式，通过下面的 <code>RegexObject</code> 方法，来修改字符串。</p>
<p><table border="1" cellspacing="0"></table></p>
<p><tbody></tbody></p>
<p><tr></tr></p>
<p><td>方法/属性</td></p>
<p><td>作用</td><br></p>
<p><tr></tr></p>
<p><td>split()</td></p>
<p><td>将字符串在 RE 匹配的地方分片并生成一个列表，</td><br></p>
<p><tr></tr></p>
<p><td>sub()</td></p>
<p><td>找到 RE 匹配的所有子串，并将其用一个不同的字符串替换</td><br></p>
<p><tr></tr></p>
<p><td>subn()</td></p>
<p><td>与 sub() 相同，但返回新的字符串和替换次数</td><br><br><br><br>&nbsp;</p>
<h4 id="u5C06_u5B57_u7B26_u4E32_u5206_u7247"><a href="#u5C06_u5B57_u7B26_u4E32_u5206_u7247" class="headerlink" title="将字符串分片"></a><span class="mw-headline">将字符串分片 </span></h4><p><code>RegexObject</code> 的 split() 方法在 RE 匹配的地方将字符串分片，将返回列表。它同字符串的 split() 方法相似但提供更多的定界符；split()只支持空白符和固定字符串。就象你预料的那样，也有一个模块级的 re.split() 函数。</p>
<p><pre>split(string [, maxsplit = 0])<br></pre><br>通过正则表达式将字符串分片。如果捕获括号在 RE 中使用，那么它们的内容也会作为结果列表的一部分返回。如果 maxsplit 非零，那么最多只能分出 maxsplit 个分片。<br>你可以通过设置 maxsplit 值来限制分片数。当 maxsplit 非零时，最多只能有 maxsplit 个分片，字符串的其余部分被做为列表的最后部分返回。在下面的例子中，定界符可以是非数字字母字符的任意序列。</p>
<p><pre class="lang:default decode:true">#!python<br>&gt;&gt;&gt; p = re.compile(r’\W+’)<br>&gt;&gt;&gt; p.split(‘This is a test, short and sweet, of split().’)<br>[‘This’, ‘is’, ‘a’, ‘test’, ‘short’, ‘and’, ‘sweet’, ‘of’, ‘split’, ‘’]<br>&gt;&gt;&gt; p.split(‘This is a test, short and sweet, of split().’, 3)<br>[‘This’, ‘is’, ‘a’, ‘test, short and sweet, of split().’]</pre><br>有时，你不仅对定界符之间的文本感兴趣，也需要知道定界符是什么。如果捕获括号在 RE 中使用，那么它们的值也会当作列表的一部分返回。比较下面的调用：</p>
<p><pre class="lang:default decode:true">#!python<br>&gt;&gt;&gt; p = re.compile(r’\W+’)<br>&gt;&gt;&gt; p2 = re.compile(r’(\W+)’)<br>&gt;&gt;&gt; p.split(‘This… is a test.’)<br>[‘This’, ‘is’, ‘a’, ‘test’, ‘’]<br>&gt;&gt;&gt; p2.split(‘This… is a test.’)<br>[‘This’, ‘… ‘, ‘is’, ‘ ‘, ‘a’, ‘ ‘, ‘test’, ‘.’, ‘’]</pre><br>模块级函数 re.split() 将 RE 作为第一个参数，其他一样。</p>
<p><pre class="lang:default decode:true">#!python<br>&gt;&gt;&gt; re.split(‘[\W]+’, ‘Words, words, words.’)<br>[‘Words’, ‘words’, ‘words’, ‘’]<br>&gt;&gt;&gt; re.split(‘([\W]+)’, ‘Words, words, words.’)<br>[‘Words’, ‘, ‘, ‘words’, ‘, ‘, ‘words’, ‘.’, ‘’]<br>&gt;&gt;&gt; re.split(‘[\W]+’, ‘Words, words, words.’, 1)<br>[‘Words’, ‘words, words.’]</pre><br>&nbsp;</p>
<h4 id="u641C_u7D22_u548C_u66FF_u6362"><a href="#u641C_u7D22_u548C_u66FF_u6362" class="headerlink" title="搜索和替换"></a><span class="mw-headline">搜索和替换 </span></h4><p>其他常见的用途就是找到所有模式匹配的字符串并用不同的字符串来替换它们。sub() 方法提供一个替换值，可以是字符串或一个函数，和一个要被处理的字符串。</p>
<p><pre>sub(replacement, string[, count = 0])<br></pre><br>返回的字符串是在字符串中用 RE 最左边不重复的匹配来替换。如果模式没有发现，字符将被没有改变地返回。<br>可选参数 count 是模式匹配后替换的最大次数；count 必须是非负整数。缺省值是 0 表示替换所有的匹配。<br>这里有个使用 sub() 方法的简单例子。它用单词 “colour” 替换颜色名。</p>
<p><pre class="lang:default decode:true">#!python<br>&gt;&gt;&gt; p = re.compile( ‘(blue|white|red)’)<br>&gt;&gt;&gt; p.sub( ‘colour’, ‘blue socks and red shoes’)<br>‘colour socks and colour shoes’<br>&gt;&gt;&gt; p.sub( ‘colour’, ‘blue socks and red shoes’, count=1)<br>‘colour socks and red shoes’</pre><br>subn() 方法作用一样，但返回的是包含新字符串和替换执行次数的两元组。</p>
<p><pre class="lang:default decode:true">#!python<br>&gt;&gt;&gt; p = re.compile( ‘(blue|white|red)’)<br>&gt;&gt;&gt; p.subn( ‘colour’, ‘blue socks and red shoes’)<br>(‘colour socks and colour shoes’, 2)<br>&gt;&gt;&gt; p.subn( ‘colour’, ‘no colours at all’)<br>(‘no colours at all’, 0)</pre><br>空匹配只有在它们没有紧挨着前一个匹配时才会被替换掉。</p>
<p><pre class="lang:default decode:true">#!python<br>&gt;&gt;&gt; p = re.compile(‘x*’)<br>&gt;&gt;&gt; p.sub(‘-‘, ‘abxd’)<br>‘-a-b-d-‘</pre><br>如果替换的是一个字符串，任何在其中的反斜杠都会被处理。”\n” 将会被转换成一个换行符，”\r”转换成回车等等。未知的转义如 “\j” 则保持原样。逆向引用，如 “\6”，被 RE 中相应的组匹配而被子串替换。这使你可以在替换后的字符串中插入原始文本的一部分。<br>这个例子匹配被 “{“ 和 “}” 括起来的单词 “section”，并将 “section” 替换成 “subsection”。</p>
<p><pre class="lang:default decode:true">#!python<br>&gt;&gt;&gt; p = re.compile(‘section{ ( [^}]* ) }’, re.VERBOSE)<br>&gt;&gt;&gt; p.sub(r’subsection{\1}’,’section{First} section{second}’)<br>‘subsection{First} subsection{second}’</pre><br>还可以指定用 (?P&lt;name&gt;…) 语法定义的命名组。”\g&lt;name&gt;” 将通过组名 “name” 用子串来匹配，并且 “\g&lt;number&gt;” 使用相应的组号。所以 “\g&lt;2&gt;” 等于 “\2”，但能在替换字符串里含义不清，如 “\g&lt;2&gt;0”。（”\20” 被解释成对组 20 的引用，而不是对后面跟着一个字母 “0” 的组 2 的引用。）</p>
<p><pre class="lang:default decode:true">#!python<br>&gt;&gt;&gt; p = re.compile(‘section{ (?P&lt;name&gt; [^}]* ) }’, re.VERBOSE)<br>&gt;&gt;&gt; p.sub(r’subsection{\1}’,’section{First}’)<br>‘subsection{First}’<br>&gt;&gt;&gt; p.sub(r’subsection{\g&lt;1&gt;}’,’section{First}’)<br>‘subsection{First}’<br>&gt;&gt;&gt; p.sub(r’subsection{\g&lt;name&gt;}’,’section{First}’)<br>‘subsection{First}’</pre><br>替换也可以是一个甚至给你更多控制的函数。如果替换是个函数，该函数将会被模式中每一个不重复的匹配所调用。在每次调用时，函数会被传入一个 <code>MatchObject</code> 的对象作为参数，因此可以用这个对象去计算出替换字符串并返回它。<br>在下面的例子里，替换函数将十进制翻译成十六进制：</p>
<p><pre class="lang:default decode:true">#!python<br>&gt;&gt;&gt; def hexrepl( match ):<br>…     “Return the hex string for a decimal number”<br>…     value = int( match.group() )<br>…     return hex(value)<br>…<br>&gt;&gt;&gt; p = re.compile(r’\d+’)<br>&gt;&gt;&gt; p.sub(hexrepl, ‘Call 65490 for printing, 49152 for user code.’)<br>‘Call 0xffd2 for printing, 0xc000 for user code.’</pre><br>当使用模块级的 re.sub() 函数时，模式作为第一个参数。模式也许是一个字符串或一个 <code>RegexObject</code>；如果你需要指定正则表达式标志，你必须要么使用 <code>RegexObject</code> 做第一个参数，或用使用模式内嵌修正器，如 sub(“(?i)b+”, “x”, “bbbb BBBB”) returns ‘x x’。</p>
<p>&nbsp;</p>
<h3 id="u5E38_u89C1_u95EE_u9898"><a href="#u5E38_u89C1_u95EE_u9898" class="headerlink" title="常见问题"></a><span class="mw-headline">常见问题 </span></h3><p>正则表达式对一些应用程序来说是一个强大的工具，但在有些时候它并不直观而且有时它们不按你期望的运行。本节将指出一些最容易犯的常见错误。</p>
<p>&nbsp;</p>
<h4 id="u4F7F_u7528_u5B57_u7B26_u4E32_u65B9_u5F0F"><a href="#u4F7F_u7528_u5B57_u7B26_u4E32_u65B9_u5F0F" class="headerlink" title="使用字符串方式"></a><span class="mw-headline">使用字符串方式 </span></h4><p>有时使用 re 模块是个错误。如果你匹配一个固定的字符串或单个的字符类，并且你没有使用 re 的任何象 IGNORECASE 标志的功能，那么就没有必要使用正则表达式了。字符串有一些方法是对固定字符串进行操作的，它们通常快很多，因为它们都是一个个经过优化的 C 小循环，用以代替大的、更具通用性的正则表达式引擎。<br>举个 用一个固定字符串替换另一个 的例子，如：你可以把 “deed” 替换成 “word”。re.sub() 似乎正是胜任这个工作的函数，但还是考虑考虑 replace() 方法吧。注意 replace() 也可以在单词里面进行替换，可以把 “swordfish” 变成 “sdeedfish”。不过 RE 也是可以做到的。（为了避免替换单词的一部分，模式将写成 \bword\b，这是为了要求 “word” 两边有一个单词边界。这是个超出 replace 能力的工作）。<br>另一个常见任务是从一个字符串中删除单个字符或用另一个字符来替代它。你也许可以用 re.sub(‘\n’,’ ‘, s) 这样来实现，但 translate() 能够实现这两个任务，而且比任何正则表达式操作起来更快。 （translate 需要配合 string.maketrans 使用。例如：import string 后 ‘a1b3’.translate(string.maketrans(‘ab’, ‘cd’)) ）</p>
<p>总之，在使用 re 模块之前，先考虑一下你的问题是否可以用更快、更简单的字符串方法来解决。</p>
<p>&nbsp;</p>
<h4 id="match_28_29_vs_search_28_29"><a href="#match_28_29_vs_search_28_29" class="headerlink" title="match() vs search()"></a><span class="mw-headline">match() vs search() </span></h4><p>match() 函数只检查 RE 是否在字符串开始处匹配，而 search() 则是扫描整个字符串。记住这一区别是重要的。记住，match() 只报告一次成功的匹配，它将从 0 处开始；如果匹配不是从 0 开始的，match() 将不会报告它。</p>
<p><pre class="lang:default decode:true">#!python<br>&gt;&gt;&gt; print re.match(‘super’, ‘superstition’).span()<br>(0, 5)<br>&gt;&gt;&gt; print re.match(‘super’, ‘insuperable’)<br>None</pre><br>另一方面，search() 将扫描整个字符串，并报告它找到的第一个匹配。</p>
<p><pre class="lang:default decode:true">#!python<br>&gt;&gt;&gt; print re.search(‘super’, ‘superstition’).span()<br>(0, 5)<br>&gt;&gt;&gt; print re.search(‘super’, ‘insuperable’).span()<br>(2, 7)</pre><br>有时你可能倾向于使用 re.match()，只在RE的前面部分添加 .* 。请尽量不要这么做，最好采用 re.search() 代替之。正则表达式编译器会对 REs 做一些分析以便可以在查找匹配时提高处理速度。一个那样的分析机会指出匹配的第一个字符是什么；举个例子，模式 Crow 必须从 “C” 开始匹配。分析机可以让引擎快速扫描字符串以找到开始字符，并只在 “C” 被发现后才开始全部匹配。</p>
<p>添加 .* 会使这个优化失败，这就要扫描到字符串尾部，然后回溯以找到 RE 剩余部分的匹配。使用 re.search() 代替。</p>
<p>&nbsp;</p>
<h4 id="u8D2A_u5A6A_vs__u4E0D_u8D2A_u5A6A"><a href="#u8D2A_u5A6A_vs__u4E0D_u8D2A_u5A6A" class="headerlink" title="贪婪 vs 不贪婪"></a><span class="mw-headline">贪婪 vs 不贪婪 </span></h4><p>当重复一个正则表达式时，如用 a<em>，操作结果是尽可能多地匹配模式。当你试着匹配一对对称的定界符，如 HTML 标志中的尖括号时这个事实经常困扰你。匹配单个 HTML 标志的模式不能正常工作，因为 .</em> 的本质是“贪婪”的</p>
<p><pre class="lang:default decode:true">#!python<br>&gt;&gt;&gt; s = ‘&lt;html&gt;&lt;head&gt;&lt;title&gt;Title&lt;/title&gt;’<br>&gt;&gt;&gt; len(s)<br>32<br>&gt;&gt;&gt; print re.match(‘&lt;.<em>&gt;’, s).span()<br>(0, 32)<br>&gt;&gt;&gt; print re.match(‘&lt;.</em>&gt;’, s).group()<br>&lt;html&gt;&lt;head&gt;&lt;title&gt;Title&lt;/title&gt;</pre><br>RE 匹配 在 “<code>&amp;lt;html&amp;gt;</code>“ 中的 “&lt;”，.<em> 消耗掉字符串的剩余部分。在 RE 中保持更多的左，虽然 &gt; 不能匹配在字符串结尾，因此正则表达式必须一个字符一个字符地回溯，直到它找到 &gt; 的匹配。最终的匹配从 “&lt;html” 中的 “&lt;” 到 “&lt;/title&gt;” 中的 “&gt;”,这并不是你所想要的结果。<br>在这种情况下，解决方案是使用不贪婪的限定符 </em>?、+?、?? 或 {m,n}?，尽可能匹配小的文本。在上面的例子里， “&gt;” 在第一个 “&lt;” 之后被立即尝试，当它失败时，引擎一次增加一个字符，并在每步重试 “&gt;”。这个处理将得到正确的结果：</p>
<p><pre class="lang:default decode:true ">#!python<br>&gt;&gt;&gt; print re.match(‘&lt;.*?&gt;’, s).group()<br>&lt;html&gt;</pre><br>注意用正则表达式分析 HTML 或 XML 是痛苦的。变化混乱的模式将处理常见情况，但 HTML 和 XML 则是明显会打破正则表达式的特殊情况；当你编写一个正则表达式去处理所有可能的情况时，模式将变得非常复杂。象这样的任务用 HTML 或 XML 解析器。</p>
<p><em><strong>粗体文字</strong></em>粗体文字’</p>
<p>&nbsp;</p>
<h4 id="u4E0D_u7528_re-VERBOSE"><a href="#u4E0D_u7528_re-VERBOSE" class="headerlink" title="不用 re.VERBOSE"></a><span class="mw-headline">不用 re.VERBOSE</span></h4><p>现在你可能注意到正则表达式的表示是十分紧凑，但它们非常不好读。中度复杂的 REs 可以变成反斜杠、圆括号和元字符的长长集合，以致于使它们很难读懂。<br>在这些 REs 中，当编译正则表达式时指定 re.VERBOSE 标志是有帮助的，因为它允许你可以编辑正则表达式的格式使之更清楚。<br>re.VERBOSE 标志有这么几个作用。在正则表达式中不在字符类中的空白符被忽略。这就意味着象 dog | cat 这样的表达式和可读性差的 dog|cat 相同，但 [a b] 将匹配字符 “a”、”b” 或 空格。另外，你也可以把注释放到 RE 中；注释是从 “#” 到下一行。当使用三引号字符串时，可以使 REs 格式更加干净：</p>
<p><pre>#!python<br>pat = re.compile(r”””<br>\s<em>                 # Skip leading whitespace<br>(?P&lt;header&gt;[^:]+)   # Header name<br>\s</em> :               # Whitespace, and a colon<br>(?P&lt;value&gt;.<em>?)      # The header’s value – </em>? used to</pre></p>
<h1 id="lose_the_following_trailing_whitespace"><a href="#lose_the_following_trailing_whitespace" class="headerlink" title="lose the following trailing whitespace"></a>lose the following trailing whitespace</h1><p>\s*$                # Trailing whitespace to end-of-line<br>“””, re.VERBOSE)<br><br>这个要难读得多：</p>
<p><pre>#!python<br>pat = re.compile(r”\s<em>(?P&lt;header&gt;[^:]+)\s</em>:(?P&lt;value&gt;.<em>?)\s</em>$”)<br></pre></p>
<blockquote>
<p><em>原文出处：<a href="http://www.amk.ca/python/howto/regex/" title="http://www.amk.ca/python/howto/regex/" target="_blank" rel="external">http://www.amk.ca/python/howto/regex/</a></em></p>
<p><em>原文作者：A.M. Kuchling （amk@amk.ca）</em></p>
<p><em>授权许可：<a href="http://www.creativecommons.cn/licenses/by-nc-sa/1.0/" title="http://www.creativecommons.cn/licenses/by-nc-sa/1.0/" target="_blank" rel="external">创作共用协议</a></em></p>
<p><em>翻译人员：FireHare</em></p>
<p><em>校对人员：<a href="https://wiki.ubuntu.org.cn/Leal" title="Leal" target="_blank" rel="external">Leal</a></em></p>
<p><em>适用版本：Python 1.5 及后续版本</em></p>
<p><em>相关链接：</em></p>
<p><a href="http://www.cnblogs.com/huxi/archive/2010/07/04/1771073.html" target="_blank" rel="external">   <em>   Python正则表达式指南</em></a></p>
<p><em><a href="http://cuiqingcai.com/977.html" target="_blank" rel="external">      Python爬虫入门七之正则表达式</a></em></p>
<p><em><a href="http://www.runoob.com/python/python-reg-expressions.html" target="_blank" rel="external">      Python正则表达式</a></em></p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<p><strong> 摘要</strong><br>本文是通过Python的 re 模块来使用正则表达式的一个入门教程，和库参考手册的对应章节相比，更为浅显易懂、循序渐进。</p>
<h3 id="u7B80_u4ECB"><a href="#u7B80_u4ECB" class="headerlink" title="简介"></a><span class="mw-headline">简介 </span></h3><p>Python 自1.5版本起增加了re 模块，它提供 Perl 风格的正则表达式模式。Python 1.5之前版本则是通过 regex 模块提供 Emacs 风格的模式。Emacs 风格模式可读性稍差些，而且功能也不强，因此编写新代码时尽量不要再使用 regex 模块，当然偶尔你还是可能在老代码里发现其踪影。<br>就其本质而言，正则表达式（或 RE）是一种小型的、高度专业化的编程语言，（在Python中）它内嵌在Python中，并通过 re 模块实现。使用这个小型语言，你可以为想要匹配的相应字符串集指定规则；该字符串集可能包含英文语句、e-mail地址、TeX命令或任何你想搞定的东 西。然后你可以问诸如“这个字符串匹配该模式吗？”或“在这个字符串中是否有部分匹配该模式呢？”。你也可以使用 RE 以各种方式来修改或分割字符串。<br>正则表达式模式被编译成一系列的字节码，然后由用 C 编写的匹配引擎执行。在高级用法中，也许还要仔细留意引擎是如何执行给定 RE ，如何以特定方式编写 RE 以令生产的字节码运行速度更快。本文并不涉及优化，因为那要求你已充分掌握了匹配引擎的内部机制。<br>正则表达式语言相对小型和受限（功能有限），因此并非所有字符串处理都能用正则表达式完成。当然也有些任务可以用正则表达式完成，不过最终表达式会变得异 常复杂。碰到这些情形时，编写 Python 代码进行处理可能反而更好；尽管 Python 代码比一个精巧的正则表达式要慢些，但它更易理解。</p>
<p>&nbsp;</p>
<h3 id="u7B80_u5355_u6A21_u5F0F"><a href="#u7B80_u5355_u6A21_u5F0F" class="headerlink" title="简单模式"></a><span class="mw-headline">简单模式 </span></h3><p>我们将从最简单的正则表达式学习开始。由于正则表达式常用于字符串操作，那我们就从最常见的任务：字符匹配 下手。<br>有关正则表达式底层的计算机科学上的详细解释（确定性和非确定性有限自动机），你可以查阅编写编译器相关的任何教科书。</p>
<p>&nbsp;</p>
<h4 id="u5B57_u7B26_u5339_u914D"><a href="#u5B57_u7B26_u5339_u914D" class="headerlink" title="字符匹配"></a><span class="mw-headline"> 字符匹配 </span></h4><p>大多数字母和字符一般都会和自身匹配。例如，正则表达式 test 会和字符串“test”完全匹配。（你也可以使用大小写不敏感模式，它还能让这个 RE 匹配“Test”或“TEST”；稍后会有更多解释。）</p>
<p>这个规则当然会有例外；有些字符比较特殊，它们和自身并不匹配，而是会表明应和一些特殊的东西匹配，或者它们会影响到 RE 其它部分的重复次数。本文很大篇幅专门讨论了各种元字符及其作用。</p>
<p>这里有一个元字符的完整列表；其含义会在本指南余下部分进行讨论。]]>
    
    </summary>
    
      <category term="Python" scheme="http://blog.suzf.net/tags/Python/"/>
    
      <category term="Re" scheme="http://blog.suzf.net/tags/Re/"/>
    
      <category term="Python" scheme="http://blog.suzf.net/categories/Python/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Hello Kafka]]></title>
    <link href="http://blog.suzf.net/2016/04/18/Hello_Kafka/"/>
    <id>http://blog.suzf.net/2016/04/18/Hello_Kafka/</id>
    <published>2016-04-18T06:11:46.000Z</published>
    <updated>2016-04-29T12:43:02.000Z</updated>
    <content type="html"><![CDATA[<p>Kafka Setup</p>
<p>Kafka 是一种高吞吐的分布式发布订阅消息系统，能够替代传统的消息队列用于解耦合数据处理，缓存未处理消息等，同时具有更高的吞吐率，支持分区、多副本、冗余，因此被广泛用于大规模消息数据处理应用。Kafka 支持Java 及多种其它语言客户端，可与Hadoop、Storm、Spark等其它大数据工具结合使用。</p>
<p>本教程主要介绍Kafka 在Centos 6上的安装和使用，包括功能验证和集群的简单配置。</p>
<p>kafka docs &amp; download<br>– <a href="http://kafka.apache.org/documentation.html" target="_blank" rel="external">http://kafka.apache.org/documentation.html</a><br>– <a href="http://kafka.apache.org/downloads.html" target="_blank" rel="external">http://kafka.apache.org/downloads.html</a></p>
<p>1. 安装 zk &amp; java<br>请参考 <a href="http://suzf.net/thread-0329-671.html" target="_blank" rel="external">[译] zookeeper 入门教程</a></p>
<p>2. 运行zk<br>bin/zkServer.sh  start</p>
<p>3. 安装 kafka<br>下载 kafka 并配置</p>
<p><pre class="lang:default decode:true">wget <a href="http://apache.fayea.com/kafka/0.9.0.1/kafka_2.11-0.9.0.1.tgz" target="_blank" rel="external">http://apache.fayea.com/kafka/0.9.0.1/kafka_2.11-0.9.0.1.tgz</a><br>tar xf kafka_2.11-0.9.0.1.tgz<br>mv kafka_2.11-0.9.0.1 /usr/loca/kafka</pre><br>配置 server.properties 文件中的 zookeeper.connect，设置为 2 中的IP 和端口<br>创建多 broker</p>
<p><pre class="lang:default decode:true">@_@[11:59:56][root@suzf.net kafka]#diff -ruN config/server.properties  config/server-1.properties |grep “^[-+@]”<br>— config/server.properties  2016-02-12 08:37:25.000000000 +0800<br>+++ config/server-1.properties  2016-04-18 11:54:34.011797645 +0800<br>@@ -17,14 +17,14 @@<br>-broker.id=0<br>+broker.id=1<br>-#port=9092<br>+port=9093<br>@@ -57,7 +57,7 @@<br>-log.dirs=/tmp/kafka-logs<br>+log.dirs=/tmp/kafka-logs-1</pre><br>4. 运行 kafka</p>
<p><pre class="lang:default decode:true">bin/kafka-server-start.sh  -daemon config/server.properties<br>bin/kafka-server-start.sh  -daemon config/server-1.properties</pre><br>停止</p>
<p><pre class="lang:default decode:true">bin/kafka-server-stop.sh<br>pkill -9 -f config/server.properties</pre><br>5. 创建Topic<br>创建一个名为“test”只有一个分区，只有一个副本的Topic：</p>
<p><pre class="lang:default decode:true">bin/kafka-topics.sh –create –zookeeper localhost:2181 \<br>–replication-factor 1 –partitions 1 –topic lucy<br>Created topic “lucy”.</pre><br>如果你用的是Kafka 8.x之前版本，请用以下的命令创建topic</p>
<p><pre class="lang:default decode:true">bin/kafka-create-topic.sh –zookeeper  localhost:2181 \<br>–replica 1 –partition 1 –topic lucy</pre><br>运行list topic命令，可以看到Topic列表</p>
<p><pre class="lang:default decode:true">bin/kafka-topics.sh –describe  –zookeeper localhost:2181<br>Topic:lucy  PartitionCount:1  ReplicationFactor:1 Configs:<br>Topic: lucy Partition: 0  Leader: 1 Replicas: 1 Isr: 1</pre><br>6. 发送消息<br>kafka自带的一个命令行客户端，运行后可以输入消息，kafka会将其发送到kafka进群进行消息消费。默认情况下，每一行数据被作为一个消息进行发送。<br>接下来我们运行producer试试</p>
<p><pre class="lang:default decode:true">^_^[12:02:21][root@suzf.net kafka]#bin/kafka-console-producer.sh –broker-list localhost:9092 –topic lucy<br>Hello Kafka<br>My name is jeffrey<br>This is test on lab.suzf.net</pre><br>7. 启动消费者(consumer)<br>上面我们通过kafka自带的命令行输入了消息，那么我们现在启动消费者看看是否会接收到。</p>
<p><pre class="lang:default decode:true">@_@[12:03:22][root@suzf.net kafka]#bin/kafka-console-consumer.sh  –zookeeper localhost:2181 –topic lucy –from-beginning<br>Hello Kafka<br>My name is jeffrey<br>This is test on lab.suzf.net<br>^CProcessed a total of 3 messages</pre><br>可以看到消费者已经对我们上面输入的数据进行处理了.</p>
<ol>
<li>删除无用的topic<br><pre class="lang:default decode:true">bin/kafka-topics.sh –delete –zookeeper localhost:2181 –topic test<br>Topic test is already marked for deletion.</pre></li>
</ol>
<p>bin/kafka-topics.sh –list –zookeeper localhost:2181<br>lucy<br>test - marked for deletion<br>并没有真正删除，如果要真正删除,配置 delete.topic.enable=true.</p>
<p>配置文件在kafka/config目录</p>
<p><pre class="lang:default decode:true ">vim config/server.properties</pre></p>
<h1 id="Whether_topic_deletion_should_be_allowed-_Requires_kafka__26gt_3B_3D_0-8-2"><a href="#Whether_topic_deletion_should_be_allowed-_Requires_kafka__26gt_3B_3D_0-8-2" class="headerlink" title="Whether topic deletion should be allowed. Requires kafka &gt;= 0.8.2"></a>Whether topic deletion should be allowed. Requires kafka &gt;= 0.8.2</h1><p>delete.topic.enable=true</p>
<h1 id="bin/kafka-topics-sh__u2013create__u2013zookeeper_localhost_3A2181__5C"><a href="#bin/kafka-topics-sh__u2013create__u2013zookeeper_localhost_3A2181__5C" class="headerlink" title="bin/kafka-topics.sh –create –zookeeper localhost:2181 \"></a>bin/kafka-topics.sh –create –zookeeper localhost:2181 \</h1><p>–replication-factor 1 –partitions 1 –topic test2<br>Created topic “test2”.</p>
<h1 id="bin/kafka-topics-sh__u2013list__u2013zookeeper_localhost_3A2181"><a href="#bin/kafka-topics-sh__u2013list__u2013zookeeper_localhost_3A2181" class="headerlink" title="bin/kafka-topics.sh –list –zookeeper localhost:2181"></a>bin/kafka-topics.sh –list –zookeeper localhost:2181</h1><p>lucy<br>test - marked for deletion<br>test2</p>
<h1 id="bin/kafka-topics-sh__u2013delete__u2013zookeeper_localhost_3A2181__u2013topic_test2"><a href="#bin/kafka-topics-sh__u2013delete__u2013zookeeper_localhost_3A2181__u2013topic_test2" class="headerlink" title="bin/kafka-topics.sh –delete –zookeeper localhost:2181 –topic test2"></a>bin/kafka-topics.sh –delete –zookeeper localhost:2181 –topic test2</h1><p>Topic test2 is marked for deletion.<br>Note: This will have no impact if delete.topic.enable is not set to true.<br>^_^[13:55:46][root@suzf.net kafka]#  bin/kafka-topics.sh –list –zookeeper localhost:2181<br>lucy<br>test - marked for deletion<br>&nbsp;</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>Kafka Setup</p>
<p>Kafka 是一种高吞吐的分布式发布订阅消息系统，能够替代传统的消息队列用于解耦合数据处理，缓存未处理消息等，同时具有更高的吞吐率，支持分区、多副本、冗余，因此被广泛用于大规模消息数据处理应用。Kafka 支持Java 及多种其它语言客]]>
    </summary>
    
      <category term="kafka" scheme="http://blog.suzf.net/tags/kafka/"/>
    
      <category term="Hadoop" scheme="http://blog.suzf.net/categories/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[[译] Moving a Volume Group to Another System]]></title>
    <link href="http://blog.suzf.net/2016/04/14/'%5B%E8%AF%91%5D_Moving_a_Volume_Group_to_Another_System'/"/>
    <id>http://blog.suzf.net/2016/04/14/'[译]_Moving_a_Volume_Group_to_Another_System'/</id>
    <published>2016-04-14T07:21:56.000Z</published>
    <updated>2016-04-29T12:43:02.000Z</updated>
    <content type="html"><![CDATA[<p>您可以将整个LVM卷组移动到另一个系统。建议您在执行此操作时使用 vgexport 和 vgimport 命令。</p>
<p>vgexport：使非活动卷组无法访问系统，它允许你分离物理卷。<br>vgimport：在执行vgexport命令使其禁用之后，再次使机器可以访问卷组。</p>
<p>一个系统卷组移动到另一个系统，请执行下列步骤：<a id="more"></a></p>
<p>1. 确保现在没有用户正在访问卷组中活动卷上的文件，然后卸载逻辑卷。</p>
<p>2. 使用vgchange命令的-a n 标记卷组为无效，以防止卷组上的任何进一步的活动。</p>
<p>3. 使用vgexport命令导出卷组。这可以防止由要从中删除它在系统被访问。</p>
<p>当您导出卷组后，在你执行pvscan命令时，物理卷将显示为导出卷组。如下面的例子。</p>
<p><pre class="lang:default decode:true  "># pvscan<br>PV /dev/sda1    is in exported VG myvg [17.15 GB / 7.15 GB free]<br>PV /dev/sdc1    is in exported VG myvg [17.15 GB / 15.15 GB free]<br>PV /dev/sdd1   is in exported VG myvg [17.15 GB / 15.15 GB free]<br>…</pre><br>当系统下一次关机，就可以拔下构成卷组的磁盘，并将它们连接到新的系统。</p>
<p>4. 当这些磁盘被插入到新的系统之后， 使用 vgexport 命令导入，使得新的系统可以访问它。</p>
<p>5. 激活卷组 使用 vgchange -ay volune-group</p>
<p>6. 挂载文件系统，使其可用。</p>
<p>源文：<a href="https://www.centos.org/docs/5/html/Cluster_Logical_Volume_Manager/VG_move.html" target="_blank" rel="external">Moving a Volume Group to Another System</a></p>
]]></content>
    <summary type="html">
    <![CDATA[<p>您可以将整个LVM卷组移动到另一个系统。建议您在执行此操作时使用 vgexport 和 vgimport 命令。</p>
<p>vgexport：使非活动卷组无法访问系统，它允许你分离物理卷。<br>vgimport：在执行vgexport命令使其禁用之后，再次使机器可以访问卷组。</p>
<p>一个系统卷组移动到另一个系统，请执行下列步骤：]]>
    
    </summary>
    
      <category term="lvm" scheme="http://blog.suzf.net/tags/lvm/"/>
    
      <category term="Linux" scheme="http://blog.suzf.net/categories/Linux/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[dokuwiki 重置管理员密码]]></title>
    <link href="http://blog.suzf.net/2016/04/14/dokuwiki_%E9%87%8D%E7%BD%AE%E7%AE%A1%E7%90%86%E5%91%98%E5%AF%86%E7%A0%81/"/>
    <id>http://blog.suzf.net/2016/04/14/dokuwiki_重置管理员密码/</id>
    <published>2016-04-14T05:58:11.000Z</published>
    <updated>2016-04-29T12:43:02.000Z</updated>
    <content type="html"><![CDATA[<p>一直觉得如果写成系列的技术文章，用 wp 显得有点力不从心。最近 <a href="https://www.gitbook.com/" target="_blank" rel="external">GitBook</a> 也是不错的。<br>翻到一年多前，茫然想起自己曾经耍过 <a href="https://www.dokuwiki.org/" target="_blank" rel="external">DokuWiki</a>, 那么便拿出来耍耍吧。毕竟时间太久远了。<br>自己设置的密码已经抛在脑后了。也懒得想了，重置密码吧。简单粗暴有疗效。</p>
<p>后期会在网站中考虑 加入 wiki 或者 gitbooks, 欢迎小伙伴们前来围观。<a id="more"></a></p>
<p>dokuwiki 管理员默认用户名: admin<br>如果采用简单验证方法，用资料存储在文件中，第二列即为密码的 hash值.</p>
<p><pre class="lang:default decode:true">cat conf/users.auth.php</pre></p>
<h1 id="users-auth-php"><a href="#users-auth-php" class="headerlink" title="users.auth.php"></a>users.auth.php</h1><h1 id="26lt_3B_3Fphp_exit_28_29_3F_26gt_3B"><a href="#26lt_3B_3Fphp_exit_28_29_3F_26gt_3B" class="headerlink" title="&lt;?php exit()?&gt;"></a>&lt;?php exit()?&gt;</h1><h1 id="Don_u2019t_modify_the_lines_above"><a href="#Don_u2019t_modify_the_lines_above" class="headerlink" title="Don’t modify the lines above"></a>Don’t modify the lines above</h1><p>#</p>
<h1 id="Userfile"><a href="#Userfile" class="headerlink" title="Userfile"></a>Userfile</h1><p>#</p>
<h1 id="Format_3A"><a href="#Format_3A" class="headerlink" title="Format:"></a>Format:</h1><p>#</p>
<h1 id="login_3Apasswordhash_3AReal_Name_3Aemail_3Agroups_2Ccomma_2Cseperated"><a href="#login_3Apasswordhash_3AReal_Name_3Aemail_3Agroups_2Ccomma_2Cseperated" class="headerlink" title="login:passwordhash:Real Name:email:groups,comma,seperated"></a>login:passwordhash:Real Name:email:groups,comma,seperated</h1><p>lucy:$6$hdLEXRS9$X4lQKUDKoCnk9ubS.XPKR1:Lucy:lucy@suzf.net:admin,user</p>
<p>^_^[13:38:12][root@lab.suzf.net tmp]#cat crypt_test.php<br>&lt;?php<br>// 设置密码<br>$password = ‘yourpassword’;</p>
<p>// 获取散列值,使用自动盐值<br>$hash = crypt($password);<br>echo “password: $password\n”;<br>echo “hash: $hash\n”;</p>
<p>?&gt;</p>
<p>^_^[13:38:16][root@lab.suzf.net tmp]php crypt_test.php<br>password: yourpassword<br>hash: $1$rtfdScJg$uQh7Dl6bFFwgtI6iWDkcv.<br><br>将旧的hash 值替换为新的hash 就可以从新登录了。<br>同级目录下有 ./conf/acl.auth.php 文件是用来控访问权限的。</p>
<p>&nbsp;</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>一直觉得如果写成系列的技术文章，用 wp 显得有点力不从心。最近 <a href="https://www.gitbook.com/">GitBook</a> 也是不错的。<br>翻到一年多前，茫然想起自己曾经耍过 <a href="https://www.dokuwiki.org/">DokuWiki</a>, 那么便拿出来耍耍吧。毕竟时间太久远了。<br>自己设置的密码已经抛在脑后了。也懒得想了，重置密码吧。简单粗暴有疗效。</p>
<p>后期会在网站中考虑 加入 wiki 或者 gitbooks, 欢迎小伙伴们前来围观。]]>
    
    </summary>
    
      <category term="wiki" scheme="http://blog.suzf.net/tags/wiki/"/>
    
      <category term="Linux" scheme="http://blog.suzf.net/categories/Linux/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[密码散列安全]]></title>
    <link href="http://blog.suzf.net/2016/04/13/%E5%AF%86%E7%A0%81%E6%95%A3%E5%88%97%E5%AE%89%E5%85%A8/"/>
    <id>http://blog.suzf.net/2016/04/13/密码散列安全/</id>
    <published>2016-04-13T09:00:09.000Z</published>
    <updated>2016-04-29T12:43:02.000Z</updated>
    <content type="html"><![CDATA[<p>节选自<a href="http://php.net/manual/zh/faq.passwords.php" target="_blank" rel="external"> PHP manual</a></p>
<p>相关链接 <a href="http://drops.wooyun.org/papers/1066" target="_blank" rel="external"> Wooyun</a></p>
<p>本部分解释使用散列函数对密码进行安全处理背后的原因， 以及如何有效的进行密码散列处理。</p>
<div class="qandaset">

<ol>
<li><a href="http://php.net/manual/zh/faq.passwords.php#faq.passwords.hashing" target="_blank" rel="external"> 为什么需要把应用程序中用户的密码进行散列化？ </a></li>
<li><a href="http://php.net/manual/zh/faq.passwords.php#faq.passwords.fasthash" target="_blank" rel="external"> 为何诸如 md5 和 sha1 这样的常见散列函数不适合用在密码保护场景？ </a></li>
<li><a href="http://php.net/manual/zh/faq.passwords.php#faq.passwords.bestpractice" target="_blank" rel="external"> 如果不建议使用常用散列函数保护密码， 那么我应该如何对密码进行散列处理？ </a></li>
<li><a href="http://php.net/manual/zh/faq.passwords.php#faq.passwords.salt" target="_blank" rel="external"> “盐”是什么？ </a></li>
<li><a href="http://php.net/manual/zh/faq.passwords.php#faq.password.storing-salts" target="_blank" rel="external"> 我应该如何保存“盐”？ </a><br></li></ol></div><a id="more"></a><br><dl id="faq.passwords.hashing" class="qandaentry"><dt><strong> 为什么需要把应用程序中用户的密码进行散列化？ </strong></dt><dd class="answer">

<p>当设计一个需要接受用户密码的应用时， 对密码进行散列是最基本的，也是必需的安全考虑。 如果不对密码进行散列处理，那么一旦应用的数据库受到攻击， 那么用户的密码将被窃取。 同时，窃取者也可以使用用户账号和密码去尝试其他的应用， 如果用户没有为每个应用单独设置密码，那么将面临风险。</p>
<p>通过对密码进行散列处理，然后再保存到数据库中， 这样就使得攻击者无法直接获取原始密码， 同时还可以保证你的应用可以对原始密码进行相同的散列处理， 然后比对散列结果。</p>
<p>需要着重提醒的是，密码散列只能保护密码 不会被从数据库中直接窃取， 但是无法保证注入到应用中的 恶意代码拦截到原始密码。</p>
<p></p></dd></dl><dl id="faq.passwords.fasthash" class="qandaentry"><dt><strong> 为何诸如 <span class="function"><a href="http://php.net/manual/zh/function.md5.php" target="_blank" rel="external">md5()</a></span> 和 <span class="function"><a href="http://php.net/manual/zh/function.sha1.php" target="_blank" rel="external">sha1()</a></span> 这样的常见散列函数不适合用在密码保护场景？ </strong></dt><dd class="answer"><p></p>
<p>MD5，SHA1 以及 SHA256 这样的散列算法是面向快速、高效 进行散列处理而设计的。随着技术进步和计算机硬件的提升， 破解者可以使用“暴力”方式来寻找散列码 所对应的原始数据。</p>
<p>因为现代化计算机可以快速的“反转”上述散列算法的散列值， 所以很多安全专家都强烈建议 不要在密码散列中使用这些散列算法。</p>
<p></p></dd></dl><dl id="faq.passwords.bestpractice" class="qandaentry"><dt><strong> 如果不建议使用常用散列函数保护密码， 那么我应该如何对密码进行散列处理？ </strong></dt><dd class="answer"><p></p>
<p>当进行密码散列处理的时候，有两个必须考虑的因素： 计算量以及“盐”。 散列算法的计算量越大， 暴力破解所需的时间就越长。</p>
<p>PHP 5.5 提供了 <a href="http://php.net/manual/zh/book.password.php" target="_blank" rel="external">一个原生密码散列 API</a>， 它提供一种安全的方式来完成密码 <a href="http://php.net/manual/zh/function.password-hash.php" target="_blank" rel="external">散列</a>和 <a href="http://php.net/manual/zh/function.password-verify.php" target="_blank" rel="external">验证</a>。 PHP 5.3.7 及后续版本中都提供了一个 <a href="https://github.com/ircmaxell/password_compat" target="_blank" rel="external">» 纯 PHP 的兼容库</a>。</p>
<p>PHP 5.3 及后续版本中，还可以使用 <span class="function"><a href="http://php.net/manual/zh/function.crypt.php" target="_blank" rel="external">crypt()</a></span> 函数， 它支持多种散列算法。 针对每种受支持的散列算法，PHP 都提供了对应的原生实现， 所以在使用此函数的时候， 你需要保证所选的散列算法是你的系统所能够支持的。</p>
<p>当对密码进行散列处理的时候，建议采用 Blowfish 算法， 这是密码散列 API 的默认算法。 相比 MD5 或者 SHA1，这个算法提供了更高的计算量， 同时还有具有良好的伸缩性。</p>
<p>如果使用 <span class="function"><a href="http://php.net/manual/zh/function.crypt.php" target="_blank" rel="external">crypt()</a></span> 函数来进行密码验证， 那么你需要选择一种耗时恒定的字符串比较算法来避免时序攻击。 （译注：就是说，字符串比较所消耗的时间恒定， 不随输入数据的多少变化而变化） PHP 中的 <a href="http://php.net/manual/zh/language.operators.comparison.php" target="_blank" rel="external">== 和 === 操作符</a> 和 <span class="function"><a href="http://php.net/manual/zh/function.strcmp.php" target="_blank" rel="external">strcmp()</a></span> 函数都不是耗时恒定的字符串比较， 但是 <span class="function"><a href="http://php.net/manual/zh/function.password-verify.php" target="_blank" rel="external">password_verify()</a></span> 可以帮你完成这项工作。 我们鼓励你尽可能的使用 <a href="http://php.net/manual/zh/book.password.php" target="_blank" rel="external">原生密码散列 API</a>。</p>
<p></p></dd></dl><dl id="faq.passwords.salt" class="qandaentry"><dt><strong> “盐”是什么？ </strong></dt><dd class="answer"><p></p>
<p>加解密领域中的“盐”是指在进行散列处理的过程中 加入的一些数据，用来避免从已计算的散列值表 （被称作“彩虹表”）中 对比输出数据从而获取明文密码的风险。</p>
<p>简单而言，“盐”就是为了提高散列值被破解的难度 而加入的少量数据。 现在有很多在线服务都能够提供 计算后的散列值以及其对应的原始输入的清单， 并且数据量极其庞大。 通过加“盐”就可以避免直接从清单中查找到对应明文的风险。</p>
<p>如果不提供“盐”，<span class="function"><a href="http://php.net/manual/zh/function.password-hash.php" target="_blank" rel="external">password_hash()</a></span> 函数会随机生成“盐”。 非常简单，行之有效。</p>
<p></p></dd></dl><dl id="faq.password.storing-salts" class="qandaentry"><dt><strong> 我应该如何保存“盐”？ </strong></dt><dd class="answer"><p></p>
<p>当使用 <span class="function"><a href="http://php.net/manual/zh/function.password-hash.php" target="_blank" rel="external">password_hash()</a></span> 或者 <span class="function"><a href="http://php.net/manual/zh/function.crypt.php" target="_blank" rel="external">crypt()</a></span> 函数时， “盐”会被作为生成的散列值的一部分返回。 你可以直接把完整的返回值存储到数据库中， 因为这个返回值中已经包含了足够的信息， 可以直接用在 <span class="function"><a href="http://php.net/manual/zh/function.password-verify.php" target="_blank" rel="external">password_verify()</a></span> 或 <span class="function"><a href="http://php.net/manual/zh/function.crypt.php" target="_blank" rel="external">crypt()</a></span> 函数来进行密码验证。</p>
<p>下图展示了 <span class="function"><a href="http://php.net/manual/zh/function.crypt.php" target="_blank" rel="external">crypt()</a></span> 或 <span class="function"><a href="http://php.net/manual/zh/function.password-hash.php" target="_blank" rel="external">password_hash()</a></span> 函数返回值的结构。 如你所见，算法的信息以及“盐”都已经包含在返回值中， 在后续的密码验证中将会用到这些信息。</p>
<p><a href="http://suzf.net/wp-content/uploads/2016/04/crypt-text-rendered.png" target="_blank" rel="external"><img src="http://suzf.net/wp-content/uploads/2016/04/crypt-text-rendered.png" alt="crypt-text-rendered"></a></p>
<p></p></dd></dl><p></p>
]]></content>
    <summary type="html">
    <![CDATA[<p>节选自<a href="http://php.net/manual/zh/faq.passwords.php"> PHP manual</a></p>
<p>相关链接 <a href="http://drops.wooyun.org/papers/1066"> Wooyun</a></p>
<p>本部分解释使用散列函数对密码进行安全处理背后的原因， 以及如何有效的进行密码散列处理。</p>
<div class="qandaset">

<ol>
<li><a href="http://php.net/manual/zh/faq.passwords.php#faq.passwords.hashing"> 为什么需要把应用程序中用户的密码进行散列化？ </a></li>
<li><a href="http://php.net/manual/zh/faq.passwords.php#faq.passwords.fasthash"> 为何诸如 md5 和 sha1 这样的常见散列函数不适合用在密码保护场景？ </a></li>
<li><a href="http://php.net/manual/zh/faq.passwords.php#faq.passwords.bestpractice"> 如果不建议使用常用散列函数保护密码， 那么我应该如何对密码进行散列处理？ </a></li>
<li><a href="http://php.net/manual/zh/faq.passwords.php#faq.passwords.salt"> “盐”是什么？ </a></li>
<li><a href="http://php.net/manual/zh/faq.passwords.php#faq.password.storing-salts"> 我应该如何保存“盐”？ </a><br></div>]]>
    
    </summary>
    
      <category term="PHP" scheme="http://blog.suzf.net/tags/PHP/"/>
    
      <category term="PHP" scheme="http://blog.suzf.net/categories/PHP/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Tcpdump notes]]></title>
    <link href="http://blog.suzf.net/2016/04/06/Tcpdump_notes/"/>
    <id>http://blog.suzf.net/2016/04/06/Tcpdump_notes/</id>
    <published>2016-04-06T09:16:32.000Z</published>
    <updated>2016-04-29T12:43:02.000Z</updated>
    <content type="html"><![CDATA[<p><strong>tcpdump</strong> 是一个运行在<a href="https://zh.wikipedia.org/wiki/%E5%91%BD%E4%BB%A4%E8%A1%8C" title="命令行" target="_blank" rel="external">命令行</a>下的<a href="https://zh.wikipedia.org/wiki/%E5%97%85%E6%8E%A2" title="嗅探" target="_blank" rel="external">嗅探</a>工具。它允许用户拦截和显示发送或收到过<a href="https://zh.wikipedia.org/wiki/%E7%BD%91%E7%BB%9C" title="网络" target="_blank" rel="external">网络</a>连接到该计算机的<a href="https://zh.wikipedia.org/wiki/TCP/IP" title="TCP/IP" target="_blank" rel="external">TCP/IP</a>和其他<a href="https://zh.wikipedia.org/wiki/%E6%95%B0%E6%8D%AE%E5%8C%85" title="数据包" target="_blank" rel="external">数据包</a>。tcpdump 是一个在<a href="https://zh.wikipedia.org/wiki/BSD%E8%AE%B8%E5%8F%AF%E8%AF%81" title="BSD许可证" target="_blank" rel="external">BSD许可证</a>下发布<sup id="cite_ref-2" class="reference"><a href="https://zh.wikipedia.org/wiki/Tcpdump#cite_note-2" target="_blank" rel="external">[2]</a></sup>的<a href="https://zh.wikipedia.org/wiki/%E8%87%AA%E7%94%B1%E8%BD%AF%E4%BB%B6" title="自由软件" target="_blank" rel="external">自由软件</a>。</p>
<p>tcpdump 适用于大多数的<a href="https://zh.wikipedia.org/wiki/%E7%B1%BBUnix%E7%B3%BB%E7%BB%9F" title="类Unix系统" target="_blank" rel="external">类Unix系统</a> <a href="https://zh.wikipedia.org/wiki/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F" title="操作系统" target="_blank" rel="external">操作系统</a>：包括<a href="https://zh.wikipedia.org/wiki/Linux" title="Linux" target="_blank" rel="external">Linux</a>、<a href="https://zh.wikipedia.org/wiki/Solaris" title="Solaris" target="_blank" rel="external">Solaris</a>、<a href="https://zh.wikipedia.org/wiki/BSD" title="BSD" target="_blank" rel="external">BSD</a>、<a href="https://zh.wikipedia.org/wiki/Mac_OS_X" title="Mac OS X" target="_blank" rel="external">Mac OS X</a>、<a href="https://zh.wikipedia.org/wiki/HP-UX" title="HP-UX" target="_blank" rel="external">HP-UX</a>和<a href="https://zh.wikipedia.org/wiki/AIX" title="AIX" target="_blank" rel="external">AIX</a> 等等。在这些系统中，tcpdump 需要使用<a href="https://zh.wikipedia.org/w/index.php?title=Libpcap&amp;action=edit&amp;redlink=1" title="Libpcap（页面不存在）" target="_blank" rel="external">libpcap</a>这个捕捉数据的<a href="https://zh.wikipedia.org/wiki/%E5%BA%93" title="库" target="_blank" rel="external">库</a>。其在<a href="https://zh.wikipedia.org/wiki/Microsoft_Windows" title="Microsoft Windows" target="_blank" rel="external">Windows</a>下的版本称为<a href="https://zh.wikipedia.org/w/index.php?title=WinDump&amp;action=edit&amp;redlink=1" title="WinDump（页面不存在）" target="_blank" rel="external">WinDump</a>；它需要<a href="https://zh.wikipedia.org/w/index.php?title=WinPcap&amp;action=edit&amp;redlink=1" title="WinPcap（页面不存在）" target="_blank" rel="external">WinPcap</a>驱动，相当于在<a href="https://zh.wikipedia.org/wiki/Linux" title="Linux" target="_blank" rel="external">Linux</a>平台下的<a href="https://zh.wikipedia.org/w/index.php?title=Libpcap&amp;action=edit&amp;redlink=1" title="Libpcap（页面不存在）" target="_blank" rel="external">libpcap</a>.</p>
<h2 id="u7528_u9014"><a href="#u7528_u9014" class="headerlink" title="用途"></a><span id=".E7.94.A8.E9.80.94" class="mw-headline">用途</span></h2><p>tcpdump能够分析网络行为，性能和应用产生或接收网络流量。它支持针对网络层、协议、主机、网络或端口的过滤，并提供and、or、not等逻辑语句来帮助你去掉无用的信息，从而使用户能够进一步找出问题的根源。<a id="more"></a></p>
<p>也可以使用 tcpdump 的实现特定目的，例如在<a href="https://zh.wikipedia.org/wiki/%E8%B7%AF%E7%94%B1%E5%99%A8" title="路由器" target="_blank" rel="external">路由器</a>和<a href="https://zh.wikipedia.org/wiki/%E7%BD%91%E5%85%B3" title="网关" target="_blank" rel="external">网关</a>之间拦截并显示其他用户或计算机通信。通过 tcpdump 分析非加密的流量，如<a href="https://zh.wikipedia.org/wiki/Telnet" title="Telnet" target="_blank" rel="external">Telnet</a>或<a href="https://zh.wikipedia.org/wiki/HTTP" title="HTTP" target="_blank" rel="external">HTTP</a>的数据包，查看登录的用户名、密码、网址、正在浏览的网站内容，或任何其他信息。因此系统中存在网络分析工具主要不是对本机安全的威胁，而是对网络上的其他计算机的安全存在威胁。<sup id="cite_ref-3" class="reference"><a href="https://zh.wikipedia.org/wiki/Tcpdump#cite_note-3" target="_blank" rel="external">[3]</a></sup></p>
<p>有很多用户喜欢使用<a href="https://zh.wikipedia.org/wiki/BPF" title="BPF" target="_blank" rel="external">柏克莱数据包过滤器</a>来限制 tcpdump 产生的数据包数量，这样BPF会只把“感兴趣”的数据包到上层软件，可以避免从<a href="https://zh.wikipedia.org/wiki/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F" title="操作系统" target="_blank" rel="external">操作系统</a> <a href="https://zh.wikipedia.org/wiki/%E5%86%85%E6%A0%B8" title="内核" target="_blank" rel="external">内核</a>向用户态复制其他数据包，降低抓包的<a href="https://zh.wikipedia.org/wiki/CPU" title="CPU" target="_blank" rel="external">CPU</a>的负担以及所需的缓冲区空间，从而减少丢包率。</p>
<h2 id="u6743_u9650_u8981_u6C42"><a href="#u6743_u9650_u8981_u6C42" class="headerlink" title="权限要求"></a><span id=".E6.9D.83.E9.99.90.E8.A6.81.E6.B1.82" class="mw-headline">权限要求</span></h2><p>一些<a href="https://zh.wikipedia.org/wiki/%E7%B1%BBUnix%E7%B3%BB%E7%BB%9F" title="类Unix系统" target="_blank" rel="external">类Unix</a><a href="https://zh.wikipedia.org/wiki/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F" title="操作系统" target="_blank" rel="external">操作系统</a>，用户有必须拥有<a href="https://zh.wikipedia.org/wiki/%E8%B6%85%E7%BA%A7%E7%94%A8%E6%88%B7" title="超级用户" target="_blank" rel="external">超级用户</a>权限方可使用 tcpdump，因为在这些系统需要使用<a href="https://zh.wikipedia.org/wiki/%E8%B6%85%E7%BA%A7%E7%94%A8%E6%88%B7" title="超级用户" target="_blank" rel="external">超级用户</a>权限将网络界面设置为<a href="https://zh.wikipedia.org/wiki/%E6%B7%B7%E6%9D%82%E6%A8%A1%E5%BC%8F" target="_blank" rel="external">混杂模式</a>。然而，可以通过使用 -Z 选项在完成嗅探之后站即下降到一个特定的非特权用户的权限。在某一些类Unix操作系统，数据包嗅探机制可以配置为允许非特权用户可以使用它，如果做到这一点，就不需要超级用户权限。</p>
<h2 id="u547D_u4EE4_u4F7F_u7528"><a href="#u547D_u4EE4_u4F7F_u7528" class="headerlink" title="命令使用"></a>命令使用</h2><p>tcpdump采用命令行方式，它的命令格式为：</p>
<pre class="lang:default decode:true">tcpdump  --help
tcpdump version 4.1-PRE-CVS_2015_07_23
libpcap version 1.4.0
Usage: tcpdump [-aAdDefhIJKlLnNOpqRStuUvxX] [ -B size ] [ -c count ]
        [ -C file_size ] [ -E algo:secret ] [ -F file ] [ -G seconds ]
        [ -i interface ] [ -j tstamptype ] [ -M secret ]
        [ -P in|out|inout ]
        [ -r file ] [ -s snaplen ] [ -T type ] [ -w file ]
        [ -W filecount ] [ -y datalinktype ] [ -z command ]
        [ -Z user ] [ expression ]
</pre>

<h2 id="tcpdump_u7684_u7B80_u5355_u9009_u9879_u4ECB_u7ECD"><a href="#tcpdump_u7684_u7B80_u5355_u9009_u9879_u4ECB_u7ECD" class="headerlink" title="tcpdump的简单选项介绍"></a>tcpdump的简单选项介绍</h2><p>-A  以ASCII码方式显示每一个数据包(不会显示数据包中链路层头部信息). 在抓取包含网页数据的数据包时, 可方便查看数据(nt: 即Handy for capturing web pages).</p>
<p>-c  count<br>tcpdump将在接受到count个数据包后退出.</p>
<p>-C  file-size (nt: 此选项用于配合-w file 选项使用)<br>该选项使得tcpdump 在把原始数据包直接保存到文件中之前, 检查此文件大小是否超过file-size. 如果超过了, 将关闭此文件,另创一个文件继续用于原始数据包的记录. 新创建的文件名与-w 选项指定的文件名一致, 但文件名后多了一个数字.该数字会从1开始随着新创建文件的增多而增加. file-size的单位是百万字节(nt: 这里指1,000,000个字节,并非1,048,576个字节, 后者是以1024字节为1k, 1024k字节为1M计算所得, 即1M=1024 ＊ 1024 ＝ 1,048,576)</p>
<p>-d  以容易阅读的形式,在标准输出上打印出编排过的包匹配码, 随后tcpdump停止.(nt | rt: human readable, 容易阅读的,通常是指以ascii码来打印一些信息. compiled, 编排过的. packet-matching code, 包匹配码,含义未知, 需补充)</p>
<p>-dd 以C语言的形式打印出包匹配码.</p>
<p>-ddd 以十进制数的形式打印出包匹配码(会在包匹配码之前有一个附加的’count’前缀).</p>
<p>-D  打印系统中所有tcpdump可以在其上进行抓包的网络接口. 每一个接口会打印出数字编号, 相应的接口名字, 以及可能的一个网络接口描述. 其中网络接口名字和数字编号可以用在tcpdump 的-i flag 选项(nt: 把名字或数字代替flag), 来指定要在其上抓包的网络接口.</p>
<p>此选项在不支持接口列表命令的系统上很有用(nt: 比如, Windows 系统, 或缺乏 ifconfig -a 的UNIX系统); 接口的数字编号在windows 2000 或其后的系统中很有用, 因为这些系统上的接口名字比较复杂, 而不易使用.</p>
<p>如果tcpdump编译时所依赖的libpcap库太老,-D 选项不会被支持, 因为其中缺乏 pcap_findalldevs()函数.</p>
<p>-e  每行的打印输出中将包括数据包的数据链路层头部信息</p>
<p>-E  spi@ipaddr algo:secret,…</p>
<p>可通过spi@ipaddr algo:secret 来解密IPsec ESP包(nt | rt:IPsec Encapsulating Security Payload,IPsec 封装安全负载, IPsec可理解为, 一整套对ip数据包的加密协议, ESP 为整个IP 数据包或其中上层协议部分被加密后的数据,前者的工作模式称为隧道模式; 后者的工作模式称为传输模式 . 工作原理, 另需补充).</p>
<p>需要注意的是, 在终端启动tcpdump 时, 可以为IPv4 ESP packets 设置密钥(secret）.</p>
<p>可用于加密的算法包括des-cbc, 3des-cbc, blowfish-cbc, rc3-cbc, cast128-cbc, 或者没有(none).默认的是des-cbc(nt: des, Data Encryption Standard, 数据加密标准, 加密算法未知, 另需补充).secret 为用于ESP 的密钥, 使用ASCII 字符串方式表达. 如果以 0x 开头, 该密钥将以16进制方式读入.</p>
<p>该选项中ESP 的定义遵循RFC2406, 而不是 RFC1827. 并且, 此选项只是用来调试的, 不推荐以真实密钥(secret)来使用该选项, 因为这样不安全: 在命令行中输入的secret 可以被其他人通过ps 等命令查看到.</p>
<p>除了以上的语法格式(nt: 指spi@ipaddr algo:secret), 还可以在后面添加一个语法输入文件名字供tcpdump 使用(nt：即把spi@ipaddr algo:secret,… 中…换成一个语法文件名). 此文件在接受到第一个ESP　包时会打开此文件, 所以最好此时把赋予tcpdump 的一些特权取消(nt: 可理解为, 这样防范之后, 当该文件为恶意编写时,不至于造成过大损害).</p>
<p>-f  显示外部的IPv4 地址时(nt: foreign IPv4 addresses, 可理解为, 非本机ip地址), 采用数字方式而不是名字.(此选项是用来对付Sun公司的NIS服务器的缺陷(nt: NIS, 网络信息服务, tcpdump 显示外部地址的名字时会用到她提供的名称服务): 此NIS服务器在查询非本地地址名字时,常常会陷入无尽的查询循环).</p>
<p>由于对外部(foreign)IPv4地址的测试需要用到本地网络接口(nt: tcpdump 抓包时用到的接口)及其IPv4 地址和网络掩码. 如果此地址或网络掩码不可用, 或者此接口根本就没有设置相应网络地址和网络掩码(nt: linux 下的 ‘any’ 网络接口就不需要设置地址和掩码, 不过此’any’接口可以收到系统中所有接口的数据包), 该选项不能正常工作.</p>
<p>-F  file<br>使用file 文件作为过滤条件表达式的输入, 此时命令行上的输入将被忽略.</p>
<p>-i  interface</p>
<p>指定tcpdump 需要监听的接口.  如果没有指定, tcpdump 会从系统接口列表中搜寻编号最小的已配置好的接口(不包括 loopback 接口).一但找到第一个符合条件的接口, 搜寻马上结束.</p>
<p>在采用2.2版本或之后版本内核的Linux 操作系统上, ‘any’ 这个虚拟网络接口可被用来接收所有网络接口上的数据包(nt: 这会包括目的是该网络接口的, 也包括目的不是该网络接口的). 需要注意的是如果真实网络接口不能工作在’混杂’模式(promiscuous)下,则无法在’any’这个虚拟的网络接口上抓取其数据包.</p>
<p>如果 -D 标志被指定, tcpdump会打印系统中的接口编号，而该编号就可用于此处的interface 参数.</p>
<p>-l  对标准输出进行行缓冲(nt: 使标准输出设备遇到一个换行符就马上把这行的内容打印出来).在需要同时观察抓包打印以及保存抓包记录的时候很有用. 比如, 可通过以下命令组合来达到此目的:<br><code>tcpdump  -l  |  tee dat&#39;&#39; 或者</code>tcpdump  -l   &gt; dat  &amp;  tail  -f  dat’’.(nt: 前者使用tee来把tcpdump 的输出同时放到文件dat和标准输出中, 而后者通过重定向操作’&gt;’, 把tcpdump的输出放到dat 文件中, 同时通过tail把dat文件中的内容放到标准输出中)</p>
<p>-L  列出指定网络接口所支持的数据链路层的类型后退出.(nt: 指定接口通过-i 来指定)</p>
<p>-m  module<br>通过module 指定的file 装载SMI MIB 模块(nt: SMI，Structure of Management Information, 管理信息结构MIB, Management Information Base, 管理信息库. 可理解为, 这两者用于SNMP(Simple Network Management Protoco)协议数据包的抓取. 具体SNMP 的工作原理未知, 另需补充).</p>
<p>此选项可多次使用, 从而为tcpdump 装载不同的MIB 模块.</p>
<p>-M  secret  如果TCP 数据包(TCP segments)有TCP-MD5选项(在RFC 2385有相关描述), 则为其摘要的验证指定一个公共的密钥secret.</p>
<p>-n  不对地址(比如, 主机地址, 端口号)进行数字表示到名字表示的转换.</p>
<p>-N  不打印出host 的域名部分. 比如, 如果设置了此选现, tcpdump 将会打印’nic’ 而不是 ‘nic.ddn.mil’.</p>
<p>-O  不启用进行包匹配时所用的优化代码. 当怀疑某些bug是由优化代码引起的, 此选项将很有用.</p>
<p>-p  一般情况下, 把网络接口设置为非’混杂’模式. 但必须注意 , 在特殊情况下此网络接口还是会以’混杂’模式来工作； 从而, ‘-p’ 的设与不设, 不能当做以下选现的代名词:’ether host {local-hw-add}’ 或  ‘ether broadcast’(nt: 前者表示只匹配以太网地址为host 的包, 后者表示匹配以太网地址为广播地址的数据包).</p>
<p>-q  快速(也许用’安静’更好?)打印输出. 即打印很少的协议相关信息, 从而输出行都比较简短.</p>
<p>-R  设定tcpdump 对 ESP/AH 数据包的解析按照 RFC1825而不是RFC1829(nt: AH, 认证头, ESP， 安全负载封装, 这两者会用在IP包的安全传输机制中). 如果此选项被设置, tcpdump 将不会打印出’禁止中继’域(nt: relay prevention field). 另外,由于ESP/AH规范中没有规定ESP/AH数据包必须拥有协议版本号域,所以tcpdump不能从收到的ESP/AH数据包中推导出协议版本号.</p>
<p>-r  file<br>从文件file 中读取包数据. 如果file 字段为 ‘-‘ 符号, 则tcpdump 会从标准输入中读取包数据.</p>
<p>-S  打印TCP 数据包的顺序号时, 使用绝对的顺序号, 而不是相对的顺序号.(nt: 相对顺序号可理解为, 相对第一个TCP 包顺序号的差距,比如, 接受方收到第一个数据包的绝对顺序号为232323, 对于后来接收到的第2个,第3个数据包, tcpdump会打印其序列号为1, 2分别表示与第一个数据包的差距为1 和 2. 而如果此时-S 选项被设置, 对于后来接收到的第2个, 第3个数据包会打印出其绝对顺序号:232324, 232325).</p>
<p>-s  snaplen<br>设置tcpdump的数据包抓取长度为snaplen, 如果不设置默认将会是68字节(而支持网络接口分接头(nt: NIT, 上文已有描述,可搜索’网络接口分接头’关键字找到那里)的SunOS系列操作系统中默认的也是最小值是96).68字节对于IP, ICMP(nt: Internet Control Message Protocol,因特网控制报文协议), TCP 以及 UDP 协议的报文已足够, 但对于名称服务(nt: 可理解为dns, nis等服务), NFS服务相关的数据包会产生包截短. 如果产生包截短这种情况, tcpdump的相应打印输出行中会出现’’[|proto]’’的标志（proto 实际会显示为被截短的数据包的相关协议层次). 需要注意的是, 采用长的抓取长度(nt: snaplen比较大), 会增加包的处理时间, 并且会减少tcpdump 可缓存的数据包的数量， 从而会导致数据包的丢失. 所以, 在能抓取我们想要的包的前提下, 抓取长度越小越好.把snaplen 设置为0 意味着让tcpdump自动选择合适的长度来抓取数据包.</p>
<p>-T  type<br>强制tcpdump按type指定的协议所描述的包结构来分析收到的数据包.  目前已知的type 可取的协议为:<br>aodv (Ad-hoc On-demand Distance Vector protocol, 按需距离向量路由协议, 在Ad hoc(点对点模式)网络中使用),<br>cnfp (Cisco  NetFlow  protocol),  rpc(Remote Procedure Call), rtp (Real-Time Applications protocol),<br>rtcp (Real-Time Applications con-trol protocol), snmp (Simple Network Management Protocol),<br>tftp (Trivial File Transfer Protocol, 碎文件协议), vat (Visual Audio Tool, 可用于在internet 上进行电<br>视电话会议的应用层协议), 以及wb (distributed White Board, 可用于网络会议的应用层协议).</p>
<p>-t     在每行输出中不打印时间戳</p>
<p>-tt    不对每行输出的时间进行格式处理(nt: 这种格式一眼可能看不出其含义, 如时间戳打印成1261798315)</p>
<p>-ttt   tcpdump 输出时, 每两行打印之间会延迟一个段时间(以毫秒为单位)</p>
<p>-tttt  在每行打印的时间戳之前添加日期的打印</p>
<p>-u     打印出未加密的NFS 句柄(nt: handle可理解为NFS 中使用的文件句柄, 这将包括文件夹和文件夹中的文件)</p>
<p>-U    使得当tcpdump在使用-w 选项时, 其文件写入与包的保存同步.(nt: 即, 当每个数据包被保存时, 它将及时被写入文件中,而不是等文件的输出缓冲已满时才真正写入此文件)</p>
<p>-U 标志在老版本的libcap库(nt: tcpdump 所依赖的报文捕获库)上不起作用, 因为其中缺乏pcap_cump_flush()函数.</p>
<p>-v    当分析和打印的时候, 产生详细的输出. 比如, 包的生存时间, 标识, 总长度以及IP包的一些选项. 这也会打开一些附加的包完整性检测, 比如对IP或ICMP包头部的校验和.</p>
<p>-vv   产生比-v更详细的输出. 比如, NFS回应包中的附加域将会被打印, SMB数据包也会被完全解码.</p>
<p>-vvv  产生比-vv更详细的输出. 比如, telent 时所使用的SB, SE 选项将会被打印, 如果telnet同时使用的是图形界面,<br>其相应的图形选项将会以16进制的方式打印出来(nt: telnet 的SB,SE选项含义未知, 另需补充).</p>
<p>-w    把包数据直接写入文件而不进行分析和打印输出. 这些包数据可在随后通过-r 选项来重新读入并进行分析和打印.</p>
<p>-W    filecount<br>此选项与-C 选项配合使用, 这将限制可打开的文件数目, 并且当文件数据超过这里设置的限制时, 依次循环替代之前的文件, 这相当于一个拥有filecount 个文件的文件缓冲池. 同时, 该选项会使得每个文件名的开头会出现足够多并用来占位的0, 这可以方便这些文件被正确的排序.</p>
<p>-x    当分析和打印时, tcpdump 会打印每个包的头部数据, 同时会以16进制打印出每个包的数据(但不包括连接层的头部).总共打印的数据大小不会超过整个数据包的大小与snaplen 中的最小值. 必须要注意的是, 如果高层协议数据没有snaplen 这么长,并且数据链路层(比如, Ethernet层)有填充数据, 则这些填充数据也会被打印.(nt: so for link  layers  that pad, 未能衔接理解和翻译, 需补充 )</p>
<p>-xx   tcpdump 会打印每个包的头部数据, 同时会以16进制打印出每个包的数据, 其中包括数据链路层的头部.</p>
<p>-X    当分析和打印时, tcpdump 会打印每个包的头部数据, 同时会以16进制和ASCII码形式打印出每个包的数据(但不包括连接层的头部).这对于分析一些新协议的数据包很方便.</p>
<p>-XX   当分析和打印时, tcpdump 会打印每个包的头部数据, 同时会以16进制和ASCII码形式打印出每个包的数据, 其中包括数据链路层的头部.这对于分析一些新协议的数据包很方便.</p>
<p>-y    datalinktype<br>设置tcpdump 只捕获数据链路层协议类型是datalinktype的数据包</p>
<p>-Z    user<br>使tcpdump 放弃自己的超级权限(如果以root用户启动tcpdump, tcpdump将会有超级用户权限), 并把当前tcpdump的用户ID设置为user, 组ID设置为user首要所属组的ID(nt: tcpdump 此处可理解为tcpdump 运行之后对应的进程)</p>
<p>此选项也可在编译的时候被设置为默认打开.(nt: 此时user 的取值未知, 需补充)</p>
<h2 id="tcpdump_u6761_u4EF6_u8868_u8FBE_u5F0F"><a href="#tcpdump_u6761_u4EF6_u8868_u8FBE_u5F0F" class="headerlink" title="tcpdump条件表达式"></a>tcpdump条件表达式</h2><p>该表达式用于决定哪些数据包将被打印. 如果不给定条件表达式, 网络上所有被捕获的包都会被打印,否则, 只有满足条件表达式的数据包被打印.(nt: all packets, 可理解为, 所有被指定接口捕获的数据包).</p>
<p>表达式由一个或多个’表达元’组成(nt: primitive, 表达元, 可理解为组成表达式的基本元素). 一个表达元通常由一个或多个修饰符(qualifiers)后跟一个名字或数字表示的id组成(nt: 即, ‘qualifiers id’).有三种不同类型的修饰符:type, dir以及 proto.</p>
<p>type 修饰符指定id 所代表的对象类型, id可以是名字也可以是数字. 可选的对象类型有: host, net, port 以及portrange(nt: host 表明id表示主机, net 表明id是网络, port 表明id是端而portrange 表明id 是一个端口范围).  如, ‘host foo’, ‘net 128.3’, ‘port 20’, ‘portrange 6000-6008’(nt: 分别表示主机 foo,网络 128.3, 端口 20, 端口范围 6000-6008). 如果不指定type 修饰符, id默认的修饰符为host.</p>
<p>dir 修饰符描述id 所对应的传输方向, 即发往id 还是从id 接收（nt: 而id 到底指什么需要看其前面的type 修饰符）.可取的方向为: src, dst, src 或 dst, src并且dst.(nt:分别表示, id是传输源, id是传输目的, id是传输源或者传输目的, id是传输源并且是传输目的). 例如, ‘src foo’,’dst net 128.3’, ‘src or dst port ftp-data’.(nt: 分别表示符合条件的数据包中, 源主机是foo, 目的网络是128.3, 源或目的端口为 ftp-data).如果不指定dir修饰符, id 默认的修饰符为src 或 dst.对于链路层的协议,比如SLIP(nt: Serial Line InternetProtocol, 串联线路网际网络协议), 以及linux下指定’any’ 设备, 并指定’cooked’(nt | rt: cooked 含义未知, 需补充) 抓取类型, 或其他设备类型,可以用’inbound’ 和 ‘outbount’ 修饰符来指定想要的传输方向.</p>
<p>proto 修饰符描述id 所属的协议. 可选的协议有: ether, fddi, tr, wlan, ip, ip6, arp, rarp, decnet, tcp以及 upd.(nt | rt: ether, fddi, tr, 具体含义未知, 需补充. 可理解为物理以太网传输协议, 光纤分布数据网传输协议,以及用于路由跟踪的协议.  wlan, 无线局域网协议; ip,ip6 即通常的TCP/IP协议栈中所使用的ipv4以及ipv6网络层协议;arp, rarp 即地址解析协议,反向地址解析协议; decnet, Digital Equipment Corporation开发的, 最早用于PDP-11 机器互联的网络协议; tcp and udp, 即通常TCP/IP协议栈中的两个传输层协议).</p>
<p>例如, <code>ether src foo&#39;,</code>arp net 128.3’, <code>tcp port 21&#39;,</code>udp portrange 7000-7009’分别表示 ‘从以太网地址foo 来的数据包’,’发往或来自128.3网络的arp协议数据包’, ‘发送或接收端口为21的tcp协议数据包’, ‘发送或接收端口范围为7000-7009的udp协议数据包’.</p>
<p>如果不指定proto 修饰符, 则默认为与相应type匹配的修饰符. 例如, ‘src foo’ 含义是 ‘(ip or arp or rarp) src foo’ (nt: 即, 来自主机foo的ip/arp/rarp协议数据包, 默认type为host),<code>net bar&#39; 含义是</code>(ip  or  arp  or rarp) net bar’(nt: 即, 来自或发往bar网络的ip/arp/rarp协议数据包),<code>port 53&#39; 含义是</code>(tcp or udp) port 53’(nt: 即, 发送或接收端口为53的tcp/udp协议数据包).(nt: 由于tcpdump 直接通过数据链路层的 BSD 数据包过滤器或 DLPI(datalink provider interface, 数据链层提供者接口)来直接获得网络数据包, 其可抓取的数据包可涵盖上层的各种协议, 包括arp, rarp, icmp(因特网控制报文协议),ip, ip6, tcp, udp, sctp(流控制传输协议).</p>
<p>对于修饰符后跟id 的格式,可理解为, type id 是对包最基本的过滤条件: 即对包相关的主机, 网络, 端口的限制;dir 表示对包的传送方向的限制; proto表示对包相关的协议限制)</p>
<p>‘fddi’(nt: Fiber Distributed Data Interface) 实际上与’ether’ 含义一样: tcpdump 会把他们当作一种’’指定网络接口上的数据链路层协议’’. 如同ehter网(以太网), FDDI 的头部通常也会有源, 目的, 以及包类型, 从而可以像ether网数据包一样对这些域进行过滤. 此外, FDDI 头部还有其他的域, 但不能被放到表达式中用来过滤</p>
<p>同样, ‘tr’ 和 ‘wlan’ 也和 ‘ether’ 含义一致, 上一段对fddi 的描述同样适用于tr(Token Ring) 和wlan(802.11 wireless LAN)的头部. 对于802.11 协议数据包的头部, 目的域称为DA, 源域称为 SA;而其中的 BSSID, RA, TA 域(nt | rt: 具体含义需补充)不会被检测(nt: 不能被用于包过虑表达式中).</p>
<p>除以上所描述的表达元(‘primitive’)， 还有其他形式的表达元, 并且与上述表达元格式不同. 比如: gateway, broadcast, less, greater以及算术表达式(nt: 其中每一个都算一种新的表达元). 下面将会对这些表达元进行说明.</p>
<p>表达元之间还可以通过关键字and, or 以及 not 进行连接, 从而可组成比较复杂的条件表达式. 比如,`host foo and not port ftp and not port ftp-data’(nt: 其过滤条件可理解为, 数据包的主机为foo,并且端口不是ftp(端口21) 和ftp-data(端口20, 常用端口和名字的对应可在linux 系统中的/etc/service 文件中找到)).</p>
<p>为了表示方便, 同样的修饰符可以被省略, 如’tcp dst port ftp or ftp-data or domain’ 与以下的表达式含义相同’tcp dst port ftp or tcp dst port ftp-data or tcp dst port domain’.(nt: 其过滤条件可理解为,包的协议为tcp, 目的端口为ftp 或 ftp-data 或 domain(端口53) ).</p>
<p>借助括号以及相应操作符,可把表达元组合在一起使用(由于括号是shell的特殊字符, 所以在shell脚本或终端中使用时必须对括号进行转义, 即’(‘ 与’)’需要分别表达成’(‘ 与 ‘)‘).</p>
<p>有效的操作符有:</p>
<p><div class="cnblogs_code"></div></p>
<p><pre class=""> 否定操作 (<code>!&#39; 或</code>not’)<br> 与操作(<code>&amp;amp;&amp;amp;&#39; 或</code>and’)<br> 或操作(<code>||&#39; 或</code>or’)</pre><br><br>否定操作符的优先级别最高. 与操作和或操作优先级别相同, 并且二者的结合顺序是从左到右. 要注意的是, 表达’与操作’时,</p>
<p>需要显式写出’and’操作符, 而不只是把前后表达元并列放置(nt: 二者中间的’and’ 操作符不可省略).</p>
<p>如果一个标识符前没有关键字, 则表达式的解析过程中最近用过的关键字(往往也是从左往右距离标识符最近的关键字)将被使用.比如,<br>not host vs and ace<br>是以下表达的精简:<br>not host vs and host ace<br>而不是not (host vs or ace).(nt: 前两者表示, 所需数据包不是来自或发往host vs, 而是来自或发往ace.而后者表示数据包只要不是来自或发往vs或ac都符合要求)</p>
<p>整个条件表达式可以被当作一个单独的字符串参数也可以被当作空格分割的多个参数传入tcpdump, 后者更方便些. 通常, 如果表达式中包含元字符(nt: 如正则表达式中的’*’, ‘.’以及shell中的’(‘等字符)， 最好还是使用单独字符串的方式传入. 这时,整个表达式需要被单引号括起来. 多参数的传入方式中, 所有参数最终还是被空格串联在一起, 作为一个字符串被解析.</p>
<p>&nbsp;</p>
<h2 id="u4E3E_u4E2A_u6817_u5B50"><a href="#u4E3E_u4E2A_u6817_u5B50" class="headerlink" title="举个栗子"></a>举个栗子</h2><p><strong>默认启动</strong></p>
<p><div class="cnblogs_code"></div></p>
<p><pre>tcpdump</pre><br><br>普通情况下，直接启动<span lang="EN-US">tcpdump</span>将监视第一个网络接口上所有流过的数据包。</p>
<p><strong>监视指定网络接口的数据包</strong></p>
<p><div class="cnblogs_code"></div></p>
<p><pre class="">tcpdump -i eth1</pre><br><br>如果不指定网卡，默认tcpdump只会监视第一个网络接口，一般是eth0，下面的例子都没有指定网络接口。</p>
<p><strong>设置tcpdump的数据包抓取长度为snaplen</strong></p>
<p>默认值抓取数据包的前96个字节， -c 指定 指定数据包的个数</p>
<p><pre class="lang:default decode:true">tcpdump -i eth0 -nnv -s 1500 -c 100</pre><br><strong>抓包数据写入到文件</strong></p>
<p><pre class="lang:default decode:true">tcpdump -i eth0 -nnv -s 1500 -w /file1.tcpdump</pre><br><strong>监视指定主机的数据包</strong></p>
<p>打印所有进出sundown的数据包.</p>
<p><div class="cnblogs_code"></div></p>
<p><pre class="">tcpdump host sundown</pre><br><br>也可以指定ip,例如截获所有<span lang="EN-US">210.27.48.1 </span>的主机收到的和发出的所有的数据包</p>
<p><div class="cnblogs_code"></div></p>
<p><pre>tcpdump host 210.27.48.1</pre><br><br>打印helios 与 hot 或者与 ace 之间通信的数据包</p>
<p><div class="cnblogs_code"></div></p>
<p><pre>tcpdump host helios and ( hot or ace )</pre><br><br>截获主机<span lang="EN-US">210.27.48.1 </span>和主机<span lang="EN-US">210.27.48.2 </span>或<span lang="EN-US">210.27.48.3</span>的通信</p>
<p><div class="cnblogs_code"></div></p>
<p><pre>tcpdump host 210.27.48.1 and \ (210.27.48.2 or 210.27.48.3 )</pre><br><br>打印ace与任何其他主机之间通信的IP 数据包, 但不包括与helios之间的数据包.</p>
<p><div class="cnblogs_code"></div></p>
<p><pre>tcpdump ip host ace and not helios</pre><br><br>如果想要获取主机<span lang="EN-US">210.27.48.1</span>除了和主机<span lang="EN-US">210.27.48.2</span>之外所有主机通信的<span lang="EN-US">ip</span>包，使用命令：</p>
<p><div class="cnblogs_code"></div></p>
<p><pre>tcpdump ip host 210.27.48.1 and ! 210.27.48.2</pre><br><br>截获主机<span lang="EN-US">hostname</span>发送的所有数据</p>
<p><div class="cnblogs_code"></div></p>
<p><pre>tcpdump -i eth0 src host hostname</pre><br><br>监视所有送到主机<span lang="EN-US">hostname</span>的数据包</p>
<p><div class="cnblogs_code"></div></p>
<p><pre class="">tcpdump -i eth0 dst host hostname</pre><br><br><strong>监视指定网络的数据包</strong></p>
<p><pre class="lang:default decode:true">tcpdump -i eth0 -nnv net 192.168.9.0/24</pre><br><strong>监视指定主机和端口的数据包</strong></p>
<p>如果想要获取主机<span lang="EN-US">210.27.48.1</span>接收或发出的<span lang="EN-US">telnet</span>包，使用如下命令</p>
<p><div class="cnblogs_code"></div></p>
<p><pre class="">tcpdump tcp port 23 and host 210.27.48.1</pre><br><br>对本机的<span lang="EN-US">udp 123 </span>端口进行监视<span lang="EN-US"> 123 </span>为<span lang="EN-US">ntp</span>的服务端口</p>
<p><div class="cnblogs_code"></div></p>
<p><pre class="">tcpdump udp port 123</pre><br><br><strong>监视指定网络的数据包</strong></p>
<p>打印本地主机与Berkeley网络上的主机之间的所有通信数据包(nt: ucb-ether, 此处可理解为’Berkeley网络’的网络地址,此表达式最原始的含义可表达为: 打印网络地址为ucb-ether的所有数据包)</p>
<p><div class="cnblogs_code"></div></p>
<p><pre>tcpdump net ucb-ether</pre><br><br>打印所有通过网关snup的ftp数据包(注意, 表达式被单引号括起来了, 这可以防止shell对其中的括号进行错误解析)</p>
<p><div class="cnblogs_code"></div></p>
<p><pre>tcpdump gateway snup and (port ftp or ftp-data)</pre><br><br>打印所有源地址或目标地址是本地主机的IP数据包</p>
<p>(如果本地网络通过网关连到了另一网络, 则另一网络并不能算作本地网络.(nt: 此句翻译曲折,需补充).localnet 实际使用时要真正替换成本地网络的名字)</p>
<p><div class="cnblogs_code"></div></p>
<p><pre>tcpdump ip and not net localnet</pre><br></p>
<p><pre class="lang:default decode:true">tcpdump -i eth0 -nnv net 192.168.9.0/24</pre><br><strong>监视指定协议的数据包</strong></p>
<p>打印TCP会话中的的开始和结束数据包, 并且数据包的源或目的不是本地网络上的主机.(nt: localnet, 实际使用时要真正替换成本地网络的名字))</p>
<p><pre class="lang:default decode:true">tcpdump tcp[tcpflags] &amp; (tcp-syn|tcp-fin) != 0 and not src and dst net localnet</pre><br>打印所有源或目的端口是80, 网络层协议为IPv4, 并且含有数据,而不是SYN,FIN以及ACK-only等不含数据的数据包.(ipv6的版本的表达式可做练习)</p>
<p><pre class="lang:default decode:true">tcpdump tcp port 80 and (((ip[2:2] - ((ip[0]&amp;0xf)&lt;&lt;2)) - ((tcp[12]&amp;0xf0)&gt;&gt;2)) != 0)</pre><br>(nt: 可理解为, ip[2:2]表示整个ip数据包的长度, (ip[0]&amp;0xf)&lt;&lt;2)表示ip数据包包头的长度(ip[0]&amp;0xf代表包中的IHL域, 而此域的单位为32bit, 要换算</p>
<p>成字节数需要乘以4,　即左移2.　(tcp[12]&amp;0xf0)&gt;&gt;4 表示tcp头的长度, 此域的单位也是32bit,　换算成比特数为 ((tcp[12]&amp;0xf0) &gt;&gt; 4)　&lt;&lt;　２,<br>即 ((tcp[12]&amp;0xf0)&gt;&gt;2).　((ip[2:2] - ((ip[0]&amp;0xf)&lt;&lt;2)) - ((tcp[12]&amp;0xf0)&gt;&gt;2)) != 0　表示: 整个ip数据包的长度减去ip头的长度,再减去<br>tcp头的长度不为0, 这就意味着, ip数据包中确实是有数据.对于ipv6版本只需考虑ipv6头中的’Payload Length’ 与 ‘tcp头的长度’的差值, 并且其中表达方式’ip[]’需换成’ip6[]’.)</p>
<p>打印长度超过576字节, 并且网关地址是snup的IP数据包</p>
<p><pre class="lang:default decode:true">tcpdump gateway snup and ip[2:2] &gt; 576</pre><br>打印所有IP层广播或多播的数据包， 但不是物理以太网层的广播或多播数据报</p>
<p><pre class="lang:default decode:true">tcpdump ether[0] &amp; 1 = 0 and ip[16] &gt;= 224</pre><br>打印除’echo request’或者’echo reply’类型以外的ICMP数据包( 比如,需要打印所有非ping 程序产生的数据包时可用到此表达式 .<br>(nt: ‘echo reuqest’ 与 ‘echo reply’ 这两种类型的ICMP数据包通常由ping程序产生))</p>
<p><pre class="lang:default decode:true">tcpdump icmp[icmptype] != icmp-echo and icmp[icmptype] != icmp-echoreply</pre><br>&nbsp;</p>
<p><strong>tcpdump 与 wireshark</strong></p>
<p>Wireshark(以前是ethereal)是Windows下非常简单易用的抓包工具。但在Linux下很难找到一个好用的图形化抓包工具。<br>还好有Tcpdump。我们可以用Tcpdump + Wireshark 的完美组合实现：在 Linux 里抓包，然后在Windows 里分析包。</p>
<p><div class="cnblogs_code"></div></p>
<p><pre class="">tcpdump tcp -i eth1 -t -s 0 -c 100 and dst port ! 22 and src net 192.168.1.0/24 -w ./target.pcap</pre><br><br>(1)tcp: ip icmp arp rarp 和 tcp、udp、icmp这些选项等都要放到第一个参数的位置，用来过滤数据报的类型<br>(2)-i eth1 : 只抓经过接口eth1的包<br>(3)-t : 不显示时间戳<br>(4)-s 0 : 抓取数据包时默认抓取长度为68字节。加上-S 0 后可以抓到完整的数据包<br>(5)-c 100 : 只抓取100个数据包<br>(6)dst port ! 22 : 不抓取目标端口是22的数据包<br>(7)src net 192.168.1.0/24 : 数据包的源网络地址为192.168.1.0/24<br>(8)-w ./target.pcap : 保存成pcap文件，方便用ethereal(即wireshark)分析</p>
<hr>
<p><strong>使用tcpdump抓取HTTP包</strong></p>
<p><pre class="lang:default decode:true">tcpdump  -XvvennSs 0 -i eth0 tcp[20:2]=0x4745 or tcp[20:2]=0x4854</pre><br>0x4745 为”GET”前两个字母”GE”,0x4854 为”HTTP”前两个字母”HT”。</p>
<p>tcpdump 对截获的数据并没有进行彻底解码，数据包内的大部分内容是使用十六进制的形式直接打印输出的。显然这不利于分析网络故障，通常的解决办法是先使用带-w参 数的tcpdump 截获数据并保存到文件中，然后再使用其他程序(如Wireshark)进行解码分析。当然也应该定义过滤规则，以避免捕获的数据包填满整个硬盘。</p>
<p>抓取 demo.suzf.net  80/443 端口数据</p>
<p><pre class="lang:default decode:true">tcpdump  -nnv -s 0 -i eth1 host demo.suzf.net and  ( port 80 or port 443) -w /tmp/portal.pcap</pre><br>&nbsp;</p>
<p>Reference：</p>
<p><a href="http://www.tcpdump.org/manpages/tcpdump.1.html" target="_blank" rel="external">Tcpdump man page</a><br><a href="https://zh.wikipedia.org/wiki/Tcpdump" target="_blank" rel="external">Tcpdump wiki</a><br><a href="http://www.cnblogs.com/ggjucheng/archive/2012/01/14/2322659.html" target="_blank" rel="external">Linux tcpdump命令详解</a></p>
]]></content>
    <summary type="html">
    <![CDATA[<p><strong>tcpdump</strong> 是一个运行在<a href="https://zh.wikipedia.org/wiki/%E5%91%BD%E4%BB%A4%E8%A1%8C" title="命令行">命令行</a>下的<a href="https://zh.wikipedia.org/wiki/%E5%97%85%E6%8E%A2" title="嗅探">嗅探</a>工具。它允许用户拦截和显示发送或收到过<a href="https://zh.wikipedia.org/wiki/%E7%BD%91%E7%BB%9C" title="网络">网络</a>连接到该计算机的<a href="https://zh.wikipedia.org/wiki/TCP/IP" title="TCP/IP">TCP/IP</a>和其他<a href="https://zh.wikipedia.org/wiki/%E6%95%B0%E6%8D%AE%E5%8C%85" title="数据包">数据包</a>。tcpdump 是一个在<a href="https://zh.wikipedia.org/wiki/BSD%E8%AE%B8%E5%8F%AF%E8%AF%81" title="BSD许可证">BSD许可证</a>下发布<sup id="cite_ref-2" class="reference"><a href="https://zh.wikipedia.org/wiki/Tcpdump#cite_note-2">[2]</a></sup>的<a href="https://zh.wikipedia.org/wiki/%E8%87%AA%E7%94%B1%E8%BD%AF%E4%BB%B6" title="自由软件">自由软件</a>。</p>
<p>tcpdump 适用于大多数的<a href="https://zh.wikipedia.org/wiki/%E7%B1%BBUnix%E7%B3%BB%E7%BB%9F" title="类Unix系统">类Unix系统</a> <a href="https://zh.wikipedia.org/wiki/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F" title="操作系统">操作系统</a>：包括<a href="https://zh.wikipedia.org/wiki/Linux" title="Linux">Linux</a>、<a href="https://zh.wikipedia.org/wiki/Solaris" title="Solaris">Solaris</a>、<a href="https://zh.wikipedia.org/wiki/BSD" title="BSD">BSD</a>、<a href="https://zh.wikipedia.org/wiki/Mac_OS_X" title="Mac OS X">Mac OS X</a>、<a href="https://zh.wikipedia.org/wiki/HP-UX" title="HP-UX">HP-UX</a>和<a href="https://zh.wikipedia.org/wiki/AIX" title="AIX">AIX</a> 等等。在这些系统中，tcpdump 需要使用<a href="https://zh.wikipedia.org/w/index.php?title=Libpcap&amp;action=edit&amp;redlink=1" title="Libpcap（页面不存在）">libpcap</a>这个捕捉数据的<a href="https://zh.wikipedia.org/wiki/%E5%BA%93" title="库">库</a>。其在<a href="https://zh.wikipedia.org/wiki/Microsoft_Windows" title="Microsoft Windows">Windows</a>下的版本称为<a href="https://zh.wikipedia.org/w/index.php?title=WinDump&amp;action=edit&amp;redlink=1" title="WinDump（页面不存在）">WinDump</a>；它需要<a href="https://zh.wikipedia.org/w/index.php?title=WinPcap&amp;action=edit&amp;redlink=1" title="WinPcap（页面不存在）">WinPcap</a>驱动，相当于在<a href="https://zh.wikipedia.org/wiki/Linux" title="Linux">Linux</a>平台下的<a href="https://zh.wikipedia.org/w/index.php?title=Libpcap&amp;action=edit&amp;redlink=1" title="Libpcap（页面不存在）">libpcap</a>.</p>
<h2 id="u7528_u9014"><a href="#u7528_u9014" class="headerlink" title="用途"></a><span id=".E7.94.A8.E9.80.94" class="mw-headline">用途</span></h2><p>tcpdump能够分析网络行为，性能和应用产生或接收网络流量。它支持针对网络层、协议、主机、网络或端口的过滤，并提供and、or、not等逻辑语句来帮助你去掉无用的信息，从而使用户能够进一步找出问题的根源。]]>
    
    </summary>
    
      <category term="tcpdump" scheme="http://blog.suzf.net/tags/tcpdump/"/>
    
      <category term="Linux" scheme="http://blog.suzf.net/categories/Linux/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[MySQL  特性分析  InnoDB transaction history]]></title>
    <link href="http://blog.suzf.net/2016/04/06/MySQL__%E7%89%B9%E6%80%A7%E5%88%86%E6%9E%90__InnoDB_transaction_history/"/>
    <id>http://blog.suzf.net/2016/04/06/MySQL__特性分析__InnoDB_transaction_history/</id>
    <published>2016-04-06T04:56:57.000Z</published>
    <updated>2016-04-29T12:43:02.000Z</updated>
    <content type="html"><![CDATA[<div class="content typo"><section class="post"><br><br>## 背景<br><br>在写压力负载比较重的MySQL实例上，InnoDB可能积累了较长的没有被purge掉的transaction history，导致实例性能的衰减，或者空闲空间被耗尽，下面就来看看它是怎么产生的，或者有没有什么方法来减轻，避免这样的问题出现。<br><br>## InnoDB purge 概要<br><br>InnoDB是一个事务引擎，实现了MVCC特性，也就是在存储引擎里对行数据保存了多个版本。在对行数据进行delete或者update更改时，行数据的前映像会保留一段时间，直到可以被删除的时候。<br><br>在大部分OLTP负载情况下，前映像会在数据操作完成后的数秒钟内被删除掉，但在一些情况下，假设存在一些持续很长时间的事务需要看到数据的前映像，那么老版本的数据就会被保留相当长一段时间。<a id="more"></a><br><br>虽然MySQL 5.6版本增加了多个purge threads来加快完成老版本数据的清理工作，但在write-intensive workload情况下，不一定完全凑效。<br><br>## 测试案例<br><br>Peter Zaitsev 使用sysbench的update进行的测试，无论是 innodb_purge_threads=1 还是8的时候，显示的transaction history快速增长的情况，如下图所示:<br><div class="image-wrapper"><br><br><img src="http://mysql.taobao.org/monthly/pic/2016-02-03/1.png" alt="transaction history增长情况"><br><br>transaction history增长情况<br><br></div><br>下面看一下同步测试过程中purge的速度(可以通过<code>I_S.innodb_metrics</code>进行查询)：<br><div class="image-wrapper"><br><br><img src="http://mysql.taobao.org/monthly/pic/2016-02-03/2.png" alt="InnoDB purge 情况"><br><br>InnoDB purge 情况<br><br></div><br>显示在并发 process 的过程中，purge thread 其实处在饥饿状态，待sysbench结束，purge线程满载运行清理工作。<br><br>对于这个测试结果，这里需要说明下：<br><br>1.  对于Peter Zaitsev的测试，其实主要是为了说明transaction history的情况，如果是用sysbench进行小事务的OLTP测试，并不会产生这么明显的transaction history增长而purge thread 跟不上的情况，或者他在测试的时候，对sbtest表进行了全表查询吧，或者设置了RR级别，不过这只是猜测。<br>2.  对于undo page大部分被cache在buffer pool的情况下，purge thread还是比较快的，但如果因为buffer pool的不足而导致undo page被淘汰到disk上的情况，purge操作就会被受限IO情况， 而导致跟不上。<br><br>## 问题分析<br><br>我们来看下出现transaction history增长最常见的两种场景：<br><br><strong>大查询</strong><br>如果你在一张大表上发起一个长时间运行的查询，比如mysqldump，那么purge线程必须停下来等待查询结束，这个时候transaction undo就会累积。如果buffer pool中 free page紧张，undo page 还会被置换到disk上，加剧purge的代价。<br><br><strong>MySQL重启</strong><br>即使transaction history并没有急剧增加，但MySQL重启操作，buffer pool的重新预热，还是导致purge变成IO密集型操作。不过MySQL 5.6提供了InnoDB buffer pool的dump和reload方法，可以显著减轻purge的IO压力。<br><br>这里介绍一下如何查看buffer pool中undo page的cache情况，percona的版本上提供了<code>I_S.innodb_rseg</code>记录undo的分配和使用情况：<code>`
&lt;pre class=&quot;lang:default decode:true &quot;&gt;mysql&amp;gt; select sum(curr_size)*16/1024 undo_space_MB from innodb_rseg;
+---------------+
| undo_space_MB |
+---------------+
|     1688.4531 |
+---------------+
1 row in set (0.00 sec)
mysql&amp;gt; select count(*) cnt, count(*)*16/1024 size_MB, page_type from innodb_buffer_page group by page_type;
+--------+-----------+-------------------+
| cnt    | size_MB   | page_type         |
+--------+-----------+-------------------+
|     55 |    0.8594 | EXTENT_DESCRIPTOR |
|      2 |    0.0313 | FILE_SPACE_HEADER |
|    108 |    1.6875 | IBUF_BITMAP       |
|  17186 |  268.5313 | IBUF_INDEX        |
| 352671 | 5510.4844 | INDEX             |
|     69 |    1.0781 | INODE             |
|    128 |    2.0000 | SYSTEM            |
|      1 |    0.0156 | TRX_SYSTEM        |
|   6029 |   94.2031 | UNDO_LOG          |
|  16959 |  264.9844 | UNKNOWN           |
+--------+-----------+-------------------+
10 rows in set (1.65 sec)
&lt;/pre&gt;
&amp;nbsp;

从这两个information_schema下的两张表可以看到：undo space使用的总大小是1.7G，而buffer pool中cached不足100M。

## InnoDB 优化方法

在一定的写压力情况下，并发进行一些大查询，transaction history就会因为undo log无法purge而一直增加。

InnoDB提供了两个参数</code>innodb_max_purge_lag<code>，</code>innodb_max_purge_lag_delay<code>来调整，即当</code>trx_sys-&gt;rseg_history_len<code>超过了设置的</code>innodb_max_purge_lag<code>，就影响DML操作最大delay不超过</code>innodb_max_purge_lag_delay<code>设置的时间，以microseconds来计算。

其核心计算代码如下：</code> <code>&lt;pre class=&quot;lang:default decode:true &quot;&gt;/*******************************************************************//**
Calculate the DML delay required.
@return delay in microseconds or ULINT_MAX */
static
ulint
trx_purge_dml_delay(void)
/*=====================*/
{
     /* Determine how much data manipulation language (DML) statements
     need to be delayed in order to reduce the lagging of the purge
     thread. */
     ulint     delay = 0; /* in microseconds; default: no delay */

     /* If purge lag is set (ie. &amp;gt; 0) then calculate the new DML delay.
     Note: we do a dirty read of the trx_sys_t data structure here,
     without holding trx_sys-&amp;gt;mutex. */

     if (srv_max_purge_lag &amp;gt; 0) {
          float     ratio;

          ratio = float(trx_sys-&amp;gt;rseg_history_len) / srv_max_purge_lag;

          if (ratio &amp;gt; 1.0) {
               /* If the history list length exceeds the
               srv_max_purge_lag, the data manipulation
               statements are delayed by at least 5000
               microseconds. */
               delay = (ulint) ((ratio - .5) * 10000);
          }

          if (delay &amp;gt; srv_max_purge_lag_delay) {
               delay = srv_max_purge_lag_delay;
          }

          MONITOR_SET(MONITOR_DML_PURGE_DELAY, delay);
     }

     return(delay);
}&lt;/pre&gt;
&amp;nbsp;

但这两个参数设计有明显的两个缺陷：

**缺陷1：针对total history length**
假设transaction history中保留两类records，一类是是马上可以被purge的，一类是因为active transaction而不能purge的。但大多数时间，我们期望的是purgable history比较小，而不是整个history。

**缺陷2：针对大小而非变化**</code>trx_sys-&gt;rseg_history_len<code>是一个当前history的长度，而不是一个interval时间段内undo的增长和减少的变化情况，导致</code>trx_sys-&gt;rseg_history_len<code>一旦超过</code>innodb_max_purge_lag<code>这个设定的值，就对DML产生不超过</code>innodb_max_purge_lag_delay`的时间delay，一旦低于这个值马上delay 时间就又恢复成 0。<br><br>在对系统的吞吐监控的时候，会发现系统抖动非常厉害，而不是一个平滑的曲线。类似于下图：<br><div class="image-wrapper"><br><br><img src="http://mysql.taobao.org/monthly/pic/2016-02-03/3.png" alt="Purge 造成系统抖动"><br><br>Purge 造成系统抖动<br><br></div>

<h2 id="InnoDB_purge__u8BBE_u8BA1_u601D_u8DEF"><a href="#InnoDB_purge__u8BBE_u8BA1_u601D_u8DEF" class="headerlink" title="InnoDB purge 设计思路"></a>InnoDB purge 设计思路</h2><p>针对InnoDB的purge功能，可以从以下几个因素来综合考虑：</p>
<ol>
<li>增加默认 purge thread 的个数；</li>
<li>测量 purgable history 长度而不是总的长度；</li>
<li>针对变化进行调整 delay 数值，以应对 shrinking；</li>
<li>基于 undo space 的大小，而不是事务的个数；</li>
<li>调整 undo page 在 buffer pool 中的缓存策略，类似 insert buffer；</li>
<li>针对 undo page 使用和 index page 不同的预读策略。<br>以上6条可以针对purge线程进行一些改良。</li>
</ol>
<h2 id="u5F53_u524D_u8C03_u4F18_u65B9_u6CD5"><a href="#u5F53_u524D_u8C03_u4F18_u65B9_u6CD5" class="headerlink" title="当前调优方法"></a>当前调优方法</h2><p>在当前的 MySQL 5.6 版本上，我们能做哪些调整或者调优方法，以减少transaction history增加带来的问题呢？</p>
<p><strong>监控</strong><br>监控<code>trx_sys</code>的<code>innodb_history_list_length</code>，为它设置报警值，及时关注和处理。</p>
<p><strong>调整参数</strong><br>如果你的实例是写压力比较大的话，调整<code>innodb_purge_threads=8</code>，增加并发purge线程数。<br>谨慎调整<code>innodb_max_purge_lag</code>和<code>innodb_max_purge_lag_delay</code>参数，依据现在的设计，可能你的实例的吞吐量会急剧的下降。</p>
<p><strong>purge完之后再shutdown</strong><br>大部分的case下，MySQL实例重启后，会发现purge的性能更差，因为undo page未命中的原因，并且是random IO请求。<br>如果是正常shutdown，就等purge完成再shutdown；如果是crash，就启动后等purge完成再接受业务请求。</p>
<p><strong>预热</strong><br>使用MySQL 5.6 提供的<code>innodb_buffer_pool_dump_at_shutdown=on</code> 和 <code>innodb_buffer_pool_load_at_startup=on</code>进行预热，把undo space page预热到buffer pool中。</p>
<p>&nbsp;</p>
<blockquote>
<p><em>原文出处：<a href="http://mysql.taobao.org/monthly/2016/02/03/" target="_blank" rel="external">Taobao mysql</a></em></p>
<p><em>More: <a href="http://mysql.taobao.org/monthly/" target="_blank" rel="external">Taobao 数据内核月报</a></em><br></p></blockquote></section></div><p></p>

]]></content>
    <summary type="html">
    <![CDATA[<div class="content typo"><section class="post"><br><br>## 背景<br><br>在写压力负载比较重的MySQL实例上，InnoDB可能积累了较长的没有被purge掉的transaction history，导致实例性能的衰减，或者空闲空间被耗尽，下面就来看看它是怎么产生的，或者有没有什么方法来减轻，避免这样的问题出现。<br><br>## InnoDB purge 概要<br><br>InnoDB是一个事务引擎，实现了MVCC特性，也就是在存储引擎里对行数据保存了多个版本。在对行数据进行delete或者update更改时，行数据的前映像会保留一段时间，直到可以被删除的时候。<br><br>在大部分OLTP负载情况下，前映像会在数据操作完成后的数秒钟内被删除掉，但在一些情况下，假设存在一些持续很长时间的事务需要看到数据的前映像，那么老版本的数据就会被保留相当长一段时间。]]>
    
    </summary>
    
      <category term="Mysql" scheme="http://blog.suzf.net/tags/Mysql/"/>
    
      <category term="Mysql" scheme="http://blog.suzf.net/categories/Mysql/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[date(): It is not safe to rely on the system's timezone settings]]></title>
    <link href="http://blog.suzf.net/2016/04/06/%22date()/"/>
    <id>http://blog.suzf.net/2016/04/06/"date()/</id>
    <published>2016-04-06T04:00:08.000Z</published>
    <updated>2016-04-29T12:43:02.000Z</updated>
    <content type="html"><![CDATA[<p>date(): It is not safe to rely on the system’s timezone settings. You are <em>required</em> to use the date.timezone setting or the date_default_timezone_set() function. In case you used any of those methods and you are still getting this warning, you most likely misspelled the timezone identifier. We selected the timezone ‘UTC’ for now, but please set date.timezone to select your timezone.</p>
<p>PHP 5.3 +  需要在 php.ini 文件中配置 timezone, 或在调用 date() 函数之前使用 date_default_timezone_set() 方法设置 timezone<a id="more"></a></p>
<p>Case A:<br>在 php.ini 文件中配置 timezone</p>
<p><pre class="lang:default decode:true ">#grep -B 1 timezone ./php.ini<br>[Date]<br>; Defines the default timezone used by the date functions<br>; <a href="http://php.net/date.timezone" target="_blank" rel="external">http://php.net/date.timezone</a><br>date.timezone = “Asia/Shanghai”</pre><br>&nbsp;</p>
<p>之后重启你的 web/php 服务</p>
<p>Case B:<br>在调用 date() 函数之前 通过 date_default_timezone_set() 设置 timezone<br>eg:</p>
<p><pre class="lang:default decode:true ">/<em> set data timezone </em>/<br>date_default_timezone_set(“PRC”);<br>$years = date(‘Y’);</pre><br>&nbsp;</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>date(): It is not safe to rely on the system’s timezone settings. You are <em>required</em> to use the date.timezone setting or the date_default_timezone_set() function. In case you used any of those methods and you are still getting this warning, you most likely misspelled the timezone identifier. We selected the timezone ‘UTC’ for now, but please set date.timezone to select your timezone.</p>
<p>PHP 5.3 +  需要在 php.ini 文件中配置 timezone, 或在调用 date() 函数之前使用 date_default_timezone_set() 方法设置 timezone]]>
    
    </summary>
    
      <category term="PHP" scheme="http://blog.suzf.net/tags/PHP/"/>
    
      <category term="PHP" scheme="http://blog.suzf.net/categories/PHP/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Deprecated: mysql_connect(): The mysql extension is deprecated and will be removed in the future]]></title>
    <link href="http://blog.suzf.net/2016/04/06/'Deprecated/"/>
    <id>http://blog.suzf.net/2016/04/06/'Deprecated/</id>
    <published>2016-04-06T03:57:47.000Z</published>
    <updated>2016-04-29T12:43:02.000Z</updated>
    <content type="html"><![CDATA[<p>昨天刚把 php 的错误日志打开，今天看自己以前写的 <a href="http://suzf.net/thread-1001-345.html" target="_blank" rel="external">监控网站访问量的 demo </a>就一片空白了 一片空白了 一片空白了。<br>手动执行了下 数据采集的 data_access.php 发现有一个警告信息输出：<br>Deprecated: mysql_connect(): The mysql extension is deprecated and will be removed in the future: use mysqli or PDO instead<br>这个警告把原本的数据结构给打乱了，所以会出现 demo 的空白。<br>从提示很明显可以看出  mysql 扩展模块将在将来弃用，可以使用 mysqli 和 PDO 来代替。<a id="more"></a></p>
<p>Case A:<br>将 mysql 替换为 mysqli</p>
<p><pre class="lang:default decode:true ">-$conn = mysql_connect(“db-hostname”,”dnuser”,”password”,”dbname”);<br>+$conn = mysqli_connect(“db-hostname”,”dbuer”,”password”,”dbname”);</pre></p>
<p>-if (!$conn) {</p>
<ul>
<li>die(‘Could not connect: ‘ . mysql_error());<br>+/<em> check connection </em>/<br>+if (mysqli_connect_errno()) {</li>
</ul>
<ul>
<li>printf(“Connect failed: %s\n”, mysqli_connect_error());</li>
<li>exit();<br>}<br>官方文档  <a href="http://www.php.net/manual/zh/mysqli.query.php" target="_blank" rel="external">http://www.php.net/manual/zh/mysqli.query.php</a></li>
</ul>
<p>Case B:<br>将错误日志关闭<br>display_errors = On<br>改为<br>display_errors = Off</p>
<p>Case C:<br>在php程序代码里面设置报警级别<br>error_reporting(E_ALL ^ E_DEPRECATED);</p>
<p>这样 Deprecated 这个问题就解决了。 不过还是推荐 使用 mysqli 或是 PDO 替代老旧的 mysql. 毕竟是趋势嘛。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>昨天刚把 php 的错误日志打开，今天看自己以前写的 <a href="http://suzf.net/thread-1001-345.html">监控网站访问量的 demo </a>就一片空白了 一片空白了 一片空白了。<br>手动执行了下 数据采集的 data_access.php 发现有一个警告信息输出：<br>Deprecated: mysql_connect(): The mysql extension is deprecated and will be removed in the future: use mysqli or PDO instead<br>这个警告把原本的数据结构给打乱了，所以会出现 demo 的空白。<br>从提示很明显可以看出  mysql 扩展模块将在将来弃用，可以使用 mysqli 和 PDO 来代替。]]>
    
    </summary>
    
      <category term="PHP" scheme="http://blog.suzf.net/tags/PHP/"/>
    
      <category term="PHP" scheme="http://blog.suzf.net/categories/PHP/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Hardware  Related notes]]></title>
    <link href="http://blog.suzf.net/2016/04/05/Hardware__Related_notes/"/>
    <id>http://blog.suzf.net/2016/04/05/Hardware__Related_notes/</id>
    <published>2016-04-05T09:23:06.000Z</published>
    <updated>2016-04-29T12:43:02.000Z</updated>
    <content type="html"><![CDATA[<h3 id="IDRAC"><a href="#IDRAC" class="headerlink" title="IDRAC"></a>IDRAC</h3><p>&nbsp;</p>
<p><strong>remoteimage</strong> <a href="http://www.dell.com/support/manuals/us/en/19/integrated-dell-remote-access-cntrllr-8-with-lifecycle-controller-v2.00.00.00/RACADM_iDRAC_Pub-v1/remoteimage?guid=GUID-27BB405E-ACBD-49F6-81B6-E400AB94ECC9&amp;lang=en-us" target="_blank" rel="external">offical manual</a></p>
<p>连接远程 image <strong>&lt; 密码特殊字符用 <code>\</code> 转义 &gt;</strong><br>./bin/idracadm remoteimage -c -u root -p  “${PASSWORD}”  -l  “1.2.3.4:/iso/XXX_amd64.iso”</p>
<p>设置第一启动项为 virtal iso<br>./bin/idracadm config -g cfgServerInfo -o cfgServerFirstBootDevice VCD-DVD</p>
<p>安装完毕 谨记 <span style="color: #ff0000;">断开连接 断开连接 断开连接</span><a id="more"></a><br>./bin/idracadm remoteimage -d</p>
<p>查看状态<br>./bin/idracadm remoteimage -s<br>Synopsis</p>
<p>racadm remoteimage [-m &lt;module&gt; | -a]</p>
<p>racadm remoteimage -d [-m &lt;module&gt; | -a]</p>
<p>racadm remoteimage -s [-m &lt;module&gt; | -a]</p>
<p>racadm remoteimage -c [-m &lt;module&gt; | -a] [-u &lt;username&gt; -p &lt;password&gt; -1 &lt;image_path&gt;]</p>
<p>racadm remoteimage -e [-m &lt;module&gt; | -a] [-u &lt;username&gt; -p &lt;password&gt; -1 &lt;image_path&gt;]</p>
<p>Input</p>
<p>-c — Connect the image.<br>-d — Disconnect image.<br>-u — User name to access the network share.<br>-p — Password to access the network share.<br>-l — Image location on the network share; use double quotation marks around the location.<br>-s — Display current status.</p>
<p>NOTE: Use a forward slash (/) when providing the image location. If backward slash () is used, override the backward slash for the command to run successfully.<br>For example:</p>
<p>racadm remoteimage -c -u user -p password -l /\/\10.94.192.100/\CommonShare/\diskette</p>
<p>NOTE: The following options only apply to connect and deploy actions</p>
<p>-u — Username<br>-p — Password<br>-1</p>
<p>Example</p>
<p>Configure a Remote image.</p>
<p>racadm remoteimage -c -u “user” -p “pass” -l //shrloc/foo.iso<br>Remote Image is now Configured</p>
<p>Disable Remote File Sharing.</p>
<p>racadm remoteimage -d<br>Disable Remote File Started. Please check status using -s option to know Remote File Share is ENABLED or DISABLED.<br>Check Remote File Share status.</p>
<p>racadm remoteimage -s<br>Remote File Share is Enabled<br>UserName<br>Password<br>ShareName //10.94.161.112/xxxx/dtk_3.3_73_Linux.iso</p>
<p>Deploy a remote image on iDRAC CIFS Share.</p>
<p>racadm remoteimage -c -u root -p calvin -l //192.168.0.180/dev/floppy.img</p>
<p>Deploy a remote image on iDRAC NFS Share.</p>
<p>racadm remoteimage -c -u root -p calvin -l ‘//192.168.0.180/dev/floppy.img’</p>
]]></content>
    <summary type="html">
    <![CDATA[<h3 id="IDRAC"><a href="#IDRAC" class="headerlink" title="IDRAC"></a>IDRAC</h3><p>&nbsp;</p>
<p><strong>remoteimage</strong> <a href="http://www.dell.com/support/manuals/us/en/19/integrated-dell-remote-access-cntrllr-8-with-lifecycle-controller-v2.00.00.00/RACADM_iDRAC_Pub-v1/remoteimage?guid=GUID-27BB405E-ACBD-49F6-81B6-E400AB94ECC9&amp;lang=en-us">offical manual</a></p>
<p>连接远程 image <strong>&lt; 密码特殊字符用 <code>\</code> 转义 &gt;</strong><br>./bin/idracadm remoteimage -c -u root -p  “${PASSWORD}”  -l  “1.2.3.4:/iso/XXX_amd64.iso”</p>
<p>设置第一启动项为 virtal iso<br>./bin/idracadm config -g cfgServerInfo -o cfgServerFirstBootDevice VCD-DVD</p>
<p>安装完毕 谨记 <span style="color: #ff0000;">断开连接 断开连接 断开连接</span>]]>
    
    </summary>
    
      <category term="idrac" scheme="http://blog.suzf.net/tags/idrac/"/>
    
      <category term="Hardware" scheme="http://blog.suzf.net/categories/Hardware/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[pip_faq - Cannot fetch index base URL]]></title>
    <link href="http://blog.suzf.net/2016/04/03/pip_faq_-_Cannot_fetch_index_base_URL/"/>
    <id>http://blog.suzf.net/2016/04/03/pip_faq_-_Cannot_fetch_index_base_URL/</id>
    <published>2016-04-03T09:22:26.000Z</published>
    <updated>2016-04-29T12:43:02.000Z</updated>
    <content type="html"><![CDATA[<p>新装了一个 ubuntu, 由于公司内诸多网络限制，未经认证的用户是禁止下载任何东西的。<br>自己就用 cntlm 搭了一个透明代理供自己科学上网。 hah</p>
<p>cntlm 配置我这里就不做过多介绍了，请自行脑补。</p>
<p>配置全局代理</p>
<p><pre class="lang:default decode:true ">^_^[17:20:51][lucy@suzf.net ~]$tail -2  .profile<br>export http_proxy=<a href="http://X.X.X.X:PORT" target="_blank" rel="external">http://X.X.X.X:PORT</a><br>export https_proxy=<a href="http://X.X.X.X:PORT" target="_blank" rel="external">http://X.X.X.X:PORT</a></pre><br>安装 paramiko</p>
<p><pre class="lang:default decode:true">^_^[17:09:33][lucy@suzf.net ~]$sudo pip install paramiko<br>Downloading/unpacking paramiko<br>  Cannot fetch index base URL <a href="https://pypi.python.org/simple/" target="_blank" rel="external">https://pypi.python.org/simple/</a><br>  Could not find any downloads that satisfy the requirement Flask<br>Cleaning up…<br>No distributions at all found for Flask<br>Storing debug log for failure in /home/lucy/.pip/pip.log</pre><br>Woops, 不能用<br>Google 了一把 做了这么一些操作，能用了 喜出望外。 什么鬼？ 和缓存有关？ 和代理有关？看起来是和sudo 权限有关。</p>
<p><pre class="lang:default decode:true">@<em>@[17:18:20][lucy@suzf.net ~]$rm -r ~/.pip/<br>^</em>^[17:18:26][lucy@suzf.net ~]$sudo -E pip install paramiko<br>Downloading/unpacking paramiko<br>  Downloading paramiko-1.16.0-py2.py3-none-any.whl (169kB): 169kB downloaded<br>Downloading/unpacking pycrypto&gt;=2.1,!=2.4 (from paramiko)<br>  Downloading pycrypto-2.6.1.tar.gz (446kB): 446kB downloaded<br>  Running setup.py (path:/tmp/pip_build_root/pycrypto/setup.py) egg_info for package pycrypto</pre></p>
<p>Downloading/unpacking ecdsa&gt;=0.11 (from paramiko)<br>  Downloading ecdsa-0.13-py2.py3-none-any.whl (86kB): 86kB downloaded<br>  … …<br>顺便来说一下 sudo</p>
<p><pre class="lang:default decode:true ">用户也可以通过su切换到root用户运行命令。然而与su的启动一个root shell允许用户运行之后的所有的命令不同，sudo可以针对单个命令授予临时权限。sudo仅在需要时授予用户权限，减少了用户因为错误执行命令损坏系统的可能性。sudo也可以用来以其他用户身份执行命令。此外，sudo可以记录用户执行的命令，以及失败的特权获取。</pre></p>
<p>选项：<br>  -a type       使用指定的 BSD 认证类型<br>  -b            在后台运行命令<br>  -C fd         关闭所有 &gt;= fd 的文件描述符<br>  -E            在执行命令时保留用户环境<br>  -e            编辑文件而非执行命令<br>  -g group      以指定的用户组执行命令<br>  -H            将 HOME 变量设为目标用户的主目录。<br>  -h            显示帮助消息并退出<br>  -i [command]  以目标用户身份运行一个登录 shell<br>  -K            完全移除时间戳文件<br>  -k            无效的时间戳文件<br>  -l[l] command 列出用户能执行的命令<br>  -n            非交互模式，将不提示用户<br>  -P            保留组向量，而非设置为目标的组向量<br>  -p prompt     使用指定的密码提示<br>  -S            从标准输入读取密码<br>  -s [command]  以目标用户身份运行 shell<br>  -U user       在列表时，列出指定用户的权限<br>  -u user       以指定用户身份运行命令(或编辑文件)<br>  -V            显示版本信息并退出<br>  -v            更新用户的时间戳而不执行命令<br>  –            停止处理命令行参数<br>&nbsp;</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>新装了一个 ubuntu, 由于公司内诸多网络限制，未经认证的用户是禁止下载任何东西的。<br>自己就用 cntlm 搭了一个透明代理供自己科学上网。 hah</p>
<p>cntlm 配置我这里就不做过多介绍了，请自行脑补。</p>
<p>配置全局代理</p>
<p><p]]>
    </summary>
    
      <category term="pip" scheme="http://blog.suzf.net/tags/pip/"/>
    
      <category term="sudo" scheme="http://blog.suzf.net/tags/sudo/"/>
    
      <category term="Python" scheme="http://blog.suzf.net/categories/Python/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[How-to setup gtid on replication]]></title>
    <link href="http://blog.suzf.net/2016/04/01/How-to_setup_gtid_on_replication/"/>
    <id>http://blog.suzf.net/2016/04/01/How-to_setup_gtid_on_replication/</id>
    <published>2016-04-01T06:41:02.000Z</published>
    <updated>2016-04-29T12:43:02.000Z</updated>
    <content type="html"><![CDATA[<h3 id="u51C6_u5907_u5DE5_u4F5C"><a href="#u51C6_u5907_u5DE5_u4F5C" class="headerlink" title="准备工作"></a>准备工作</h3><p><a href="http://suzf.net/thread-1202-555.html" target="_blank" rel="external">Mysql 单机多实例详解</a><br><a href="http://suzf.net/thread-0401-693.html" target="_blank" rel="external">What is the GTID of the replication</a></p>
<h3 id="u5B9E_u9A8C_u73AF_u5883"><a href="#u5B9E_u9A8C_u73AF_u5883" class="headerlink" title="实验环境"></a>实验环境</h3><p>Os: CentOS 6.X<br>Mysql: 5.6 单机多实例 [3306,3307]<br>Hostname: lab.suzf.net</p>
<h5 id="u573A_u666F_u4E00_uFF1A_u65B0_u673A_u5668__u65E0_u6570_u636E"><a href="#u573A_u666F_u4E00_uFF1A_u65B0_u673A_u5668__u65E0_u6570_u636E" class="headerlink" title="场景一：新机器 无数据"></a>场景一：新机器 无数据</h5><p>##### </p>
<p>对于GTID的配置，主要修改配置文件中与GTID特性相关的几个重要参数<a id="more"></a></p>
<p><pre class="lang:default decode:true ">[mysqld_multi]<br>mysqld = /usr/local/mysql/bin/mysqld_safe<br>mysqladmin = /usr/local/mysql/bin/mysqladmin<br>log = /usr/local/mysql/data/log/mysqld_multi.log<br>user = root ## Used for stopping the server via mysqladmin</pre></p>
<h1 id="master"><a href="#master" class="headerlink" title="master"></a>master</h1><p>[mysqld3306]<br>socket = /usr/local/mysql/data/run/mysqld_3306.sock<br>port = 3306<br>pid-file = /usr/local/mysql/data/run/mysqld_3306.pid<br>datadir = /usr/local/mysql/data/mysql_3306</p>
<h1 id="set_for_GTID_Replication"><a href="#set_for_GTID_Replication" class="headerlink" title="set for GTID Replication"></a>set for GTID Replication</h1><p>server_id = 3232237894<br>gtid_mode = on<br>enforce_gtid_consistency = on  #强制gtid一致性，开启后对于特定create table不被支持</p>
<h1 id="binlog"><a href="#binlog" class="headerlink" title="binlog"></a>binlog</h1><p>log-bin = /usr/local/mysql/data/binlogs/master-binlog<br>log-slave-updates = 1<br>binlog_format = row            #强烈建议，其他格式可能造成数据不一致</p>
<h1 id="rely_log"><a href="#rely_log" class="headerlink" title="rely log"></a>rely log</h1><p>skip_slave_start=1</p>
<h1 id="slave"><a href="#slave" class="headerlink" title="slave"></a>slave</h1><p>[mysqld3307]<br>socket = /usr/local/mysql/data/run/mysqld_3307.sock<br>port = 3307<br>pid-file = /usr/local/mysql/data/run/mysqld_3307.pid<br>datadir = /usr/local/mysql/data/mysql_3307</p>
<h1 id="set_for_GTID_Replication-1"><a href="#set_for_GTID_Replication-1" class="headerlink" title="set for GTID Replication"></a>set for GTID Replication</h1><p>server_id = 3232237866<br>gtid_mode = on<br>enforce_gtid_consistency = on</p>
<h1 id="bin_log"><a href="#bin_log" class="headerlink" title="bin log"></a>bin log</h1><p>log-bin = /usr/local/mysql/data/binlogs/slave-binlog<br>log-slave-updates = 1<br>binlog_format = row</p>
<h1 id="rely_log-1"><a href="#rely_log-1" class="headerlink" title="rely log"></a>rely log</h1><p>skip_slave_start=1</p>
<p>[client]<br>default-character-set = utf8<br><strong>重启mysql</strong><br>/etc/init.d/mysqld_multi.server restart</p>
<p><strong>Mysql 多实例启动脚本</strong></p>
<p><pre class="lang:default decode:true ">cat /etc/init.d/mysqld_multi.server</pre></p>
<p>#!/bin/sh<br>#</p>
<h1 id="A_simple_startup_script_for_mysqld_multi_by_Tim_Smith_and_Jani_Tolonen"><a href="#A_simple_startup_script_for_mysqld_multi_by_Tim_Smith_and_Jani_Tolonen" class="headerlink" title="A simple startup script for mysqld_multi by Tim Smith and Jani Tolonen."></a>A simple startup script for mysqld_multi by Tim Smith and Jani Tolonen.</h1><h1 id="This_script_assumes_that_my-cnf_file_exists_either_in_/etc/my-cnf_or"><a href="#This_script_assumes_that_my-cnf_file_exists_either_in_/etc/my-cnf_or" class="headerlink" title="This script assumes that my.cnf file exists either in /etc/my.cnf or"></a>This script assumes that my.cnf file exists either in /etc/my.cnf or</h1><h1 id="/root/-my-cnf_and_has_groups__5Bmysqld_multi_5D_and__5BmysqldN_5D-_See_the"><a href="#/root/-my-cnf_and_has_groups__5Bmysqld_multi_5D_and__5BmysqldN_5D-_See_the" class="headerlink" title="/root/.my.cnf and has groups [mysqld_multi] and [mysqldN]. See the"></a>/root/.my.cnf and has groups [mysqld_multi] and [mysqldN]. See the</h1><h1 id="mysqld_multi_documentation_for_detailed_instructions"><a href="#mysqld_multi_documentation_for_detailed_instructions" class="headerlink" title="mysqld_multi documentation for detailed instructions."></a>mysqld_multi documentation for detailed instructions.</h1><p>#</p>
<h1 id="This_script_can_be_used_as_/etc/init-d/mysql-server"><a href="#This_script_can_be_used_as_/etc/init-d/mysql-server" class="headerlink" title="This script can be used as /etc/init.d/mysql.server"></a>This script can be used as /etc/init.d/mysql.server</h1><p>#</p>
<h1 id="Comments_to_support_chkconfig_on_RedHat_Linux"><a href="#Comments_to_support_chkconfig_on_RedHat_Linux" class="headerlink" title="Comments to support chkconfig on RedHat Linux"></a>Comments to support chkconfig on RedHat Linux</h1><h1 id="chkconfig_3A_2345_64_36"><a href="#chkconfig_3A_2345_64_36" class="headerlink" title="chkconfig: 2345 64 36"></a>chkconfig: 2345 64 36</h1><h1 id="description_3A_A_very_fast_and_reliable_SQL_database_engine"><a href="#description_3A_A_very_fast_and_reliable_SQL_database_engine" class="headerlink" title="description: A very fast and reliable SQL database engine."></a>description: A very fast and reliable SQL database engine.</h1><p>#</p>
<h1 id="Version_1-0"><a href="#Version_1-0" class="headerlink" title="Version 1.0"></a>Version 1.0</h1><p>#</p>
<p>basedir=/usr/local/mysql<br>bindir=/usr/local/mysql/bin</p>
<p>conf=$basedir/data/etc/my.cnf<br>export PATH=$PATH:$bindir</p>
<p>if test -x $bindir/mysqld_multi<br>then<br>  mysqld_multi=”$bindir/mysqld_multi”;<br>else<br>  echo “Can’t execute $bindir/mysqld_multi from dir $basedir”;<br>  exit;<br>fi</p>
<p>case “$1” in<br>    ‘start’ )<br>        “$mysqld_multi” –defaults-extra-file=$conf start $2<br>        ;;<br>    ‘stop’ )<br>        “$mysqld_multi” –defaults-extra-file=$conf stop $2<br>        ;;<br>    ‘report’ )<br>        “$mysqld_multi” –defaults-extra-file=$conf report $2<br>        ;;<br>    ‘restart’ )<br>        “$mysqld_multi” –defaults-extra-file=$conf stop $2<br>        “$mysqld_multi” –defaults-extra-file=$conf start $2<br>        ;;<br>    <em>)<br>        echo “Usage: $0 {start|stop|report|restart}” &gt;&amp;2<br>        ;;<br>esac<br><em>*Master OPS</em></em></p>
<p><pre class="lang:default decode:true ">mysql -uroot -S /usr/local/mysql/data/run/mysqld_3306.sock<br>mysql&gt; GRANT REPLICATION SLAVE ON <em>.</em> TO ‘repluser’@’localhost’ IDENTIFIED BY ‘suzf.net666’;<br>Query OK, 0 rows affected (0.00 sec)</pre><br><strong>Slave OPS</strong></p>
<p><pre class="lang:default decode:true">mysql -uroot -S /usr/local/mysql/data/run/mysqld_3307.sock<br>mysql&gt; CHANGE MASTER TO<br>    -&gt; MASTER_HOST=’localhost’,<br>    -&gt; MASTER_USER=’repluser’,<br>    -&gt; MASTER_PASSWORD=’suzf.net666’,<br>    -&gt; MASTER_PORT=3306,<br>    -&gt; MASTER_AUTO_POSITION = 1;<br>Query OK, 0 rows affected, 2 warnings (0.04 sec)<br>mysql&gt; start slave;<br>Query OK, 0 rows affected (0.19 sec)</pre><br>验证</p>
<p><a href="http://suzf.net/wp-content/uploads/2016/04/gtid1.png" target="_blank" rel="external"><img src="http://suzf.net/wp-content/uploads/2016/04/gtid1.png" alt="gtid1"></a></p>
<p>##### </p>
<p>&nbsp;</p>
<h5 id="u573A_u666F_u4E8C_uFF1A_u79FB_u9664_Replication"><a href="#u573A_u666F_u4E8C_uFF1A_u79FB_u9664_Replication" class="headerlink" title="场景二：移除  Replication"></a>场景二：移除  Replication</h5><p>首先关闭 SLAVE</p>
<p><pre class="lang:default decode:true">mysql&gt; STOP SLAVE;<br>Query OK, 0 rows affected (0.00 sec)</pre><br>使用ALL 参数 重置 SLAVE (MySQL &gt;= 5.6.7):</p>
<p><pre class="lang:default decode:true">mysql&gt; RESET SLAVE ALL;<br>Query OK, 0 rows affected (0.02 sec)</pre><br>此时 mysql replication 已经消失了</p>
<p><pre class="lang:default decode:true">mysql&gt; SHOW SLAVE STATUS\G<br>Empty set (0.00 sec)</pre><br>如果你希望这个SLAVE节点继续做一个新的MASTER的slave 节点，那么请设置 gtid_purged,你应该发出一下命令（即使 gtid_puerged 看起来是空的，你也应该重置一下MASTER.）</p>
<p><pre class="lang:default decode:true">mysql&gt; reset master;<br>Query OK, 0 rows affected (0.11 sec)</pre></p>
<p>mysql&gt; show variables like ‘%gtid%’;<br>+————————–+———–+<br>| Variable_name            | Value     |<br>+————————–+———–+<br>| enforce_gtid_consistency | ON        |<br>| gtid_executed            |           |<br>| gtid_mode                | ON        |<br>| gtid_next                | AUTOMATIC |<br>| gtid_owned               |           |<br>| gtid_purged              |           |<br>+————————–+———–+<br>6 rows in set (0.00 sec)<br>备注<br>我很确定我已经删除了 rely-binary-logs. (relay_log_basename variable)</p>
<p>&nbsp;</p>
<h5 id="u573A_u666F_u4E09_uFF1A_u62F7_u8D1D_u6570_u636E__u65B0_u5EFA_GTID_slave"><a href="#u573A_u666F_u4E09_uFF1A_u62F7_u8D1D_u6570_u636E__u65B0_u5EFA_GTID_slave" class="headerlink" title="场景三：拷贝数据 新建 GTID slave"></a>场景三：拷贝数据 新建 GTID slave</h5><h4 id="Using_mysqldump"><a href="#Using_mysqldump" class="headerlink" title="Using mysqldump"></a>Using mysqldump</h4><p>在 slave 几点初始化数据库</p>
<p><pre class="lang:default decode:true ">$ ./scripts/mysql_install_db –datadir=/usr/local/mysql/data/mysql_3307</pre><br>为了更简单使用 mysqldump, 是将下列参数加入配置文件</p>
<p><pre class="lang:default decode:true">[mysqldump]<br>quick<br>max_allowed_packet = 16M<br>port = 3306<br>socket = /usr/local/mysql/data/run/mysqld_3306.sock<br></pre><br>之后使用下面命令导出 Master 节点的 Cherry 数据库</p>
<p><pre class="lang:default decode:true">$ mysqldump –defaults-file=/usr/local/mysql/data/etc/my.cnf –user=root –password=<code>cat ~mysql/.root_password</code> –single-transaction –databases Cherry &gt; backup.sql<br>Warning: Using a password on the command line interface can be insecure.<br>Warning: A partial dump from a server that has GTIDs will by default include the GTIDs of all transactions, even those that changed suppressed parts of the database. If you don’t want to restore GTIDs, pass –set-gtid-purged=OFF. To make a complete dump, pass –all-databases –triggers –routines –events.</pre><br>备注<br>–defaults-file 参数必须放在第一个位置, 否则你将会入到一个我认为已经修复的<a href="http://bugs.mysql.com/bug.php?id=31312" target="_blank" rel="external"> bug</a>.</p>
<p>GTID 的诀窍在这里，当然它是通过 mysqldump 来实现的</p>
<p><pre class="lang:default decode:true">$grep -i gtid 、/tmp/backup.sql<br>– GTID state at the beginning of the backup<br>SET @@GLOBAL.GTID_PURGED=’770d3753-c6e4-11e2-8e78-080027d93e15:1-8’;</pre><br>之后将dump 文件传送到 slave 节点，然后导入它；</p>
<p><pre class="lang:default decode:true">mysql&gt; source /tmp/backup.sql;</pre><br>我最初得到了下面的错误：</p>
<p><pre class="lang:default decode:true">ERROR 1840 (HY000): @@GLOBAL.GTID_PURGED can only be set when @@GLOBAL.GTID_EXECUTED is empty.</pre><br>但是我的 gtid_executed 参数是空的:</p>
<p><pre class="lang:default decode:true">mysql&gt; show variables like ‘%gtid%’;<br>+————————–+——————————————+<br>| Variable_name            | Value                                    |<br>+————————–+——————————————+<br>| enforce_gtid_consistency | ON                                       |<br>| gtid_executed            |                                          |<br>| gtid_mode                | ON                                       |<br>| gtid_next                | AUTOMATIC                                |<br>| gtid_owned               |                                          |<br>| gtid_purged              | 770d3753-c6e4-11e2-8e78-080027d93e15:1-6 |<br>+————————–+——————————————+<br>6 rows in set (0.00 sec)</pre><br>错误消息显示冲突 一个<a href="http://bugs.mysql.com/bug.php?id=68038" target="_blank" rel="external">bug</a>已经打开。实际上，gtid_purged也必须是空的，以便能够设置它。<a href="http://dev.mysql.com/doc/refman/5.6/en/replication-options-gtids.html" target="_blank" rel="external">官方文档</a>中引用的唯一解决方法是使用下面的命令：</p>
<p><pre class="lang:default decode:true">mysql&gt; DROP DATABASE replicationdb;<br>Query OK, 1 row affected (0.07 sec)</pre></p>
<p>mysql&gt; RESET MASTER;<br>Query OK, 0 rows affected (0.06 sec)</p>
<p>mysql&gt; SHOW VARIABLES LIKE ‘%gtid%’;<br>+————————–+———–+<br>| Variable_name            | Value     |<br>+————————–+———–+<br>| enforce_gtid_consistency | ON        |<br>| gtid_executed            |           |<br>| gtid_mode                | ON        |<br>| gtid_next                | AUTOMATIC |<br>| gtid_owned               |           |<br>| gtid_purged              |           |<br>+————————–+———–+<br>6 rows in set (0.01 sec)<br><br>一旦完成你可以从新导入备份文件，如果最后没有错误出现，那么现在可以设置 replication 了。</p>
<p><pre class="lang:default decode:true">mysql&gt; change master to master_host=’lab.suzf.net’, master_port=3306, master_user=’repluser’, master_password=’suzf.net666’, master_auto_position=1;<br>Query OK, 0 rows affected, 2 warnings (0.16 sec)</pre></p>
<p>mysql&gt; start slave;<br>Query OK, 0 rows affected (0.03 sec)</p>
<p>mysql&gt; SHOW SLAVE STATUS\G<br><strong><strong><strong><strong><strong><strong><em>*</em></strong></strong></strong></strong></strong></strong> 1. row <strong><strong><strong><strong><strong><strong><em>*</em></strong></strong></strong></strong></strong></strong></p>
<pre><code>       Slave_IO_Running: Yes
      Slave_SQL_Running: Yes
          ... ...
Slave_SQL_Running_State: Slave has read all relay log; waiting for the slave I/O thread to update it&lt;/pre&gt;
</code></pre><p>如果使用的是mysql 5.5 可能会用到</p>
<p><pre class="lang:default decode:true">change master to master_host=’lab.suzf.net’, master_port=3306, master_user=’repluser’, master_password=’suzf.net666’,  master_log_file=’mysql-bin.000006’, master_log_pos=1026;</pre><br>从哪里可以获得 master_log_file 和 log_position（在你导入数据时请不要将 master 设置为 read-only ）</p>
<p><pre class="lang:default decode:true ">mysql&gt; FLUSH TABLES WITH READ LOCK;<br>mysql&gt; SHOW MASTER STATUS;</pre><br>&nbsp;</p>
<h4 id="Using_XtraBackup"><a href="#Using_XtraBackup" class="headerlink" title="Using XtraBackup"></a>Using XtraBackup</h4><p>准备工作</p>
<p><pre class="lang:default decode:true ">$mkdir  /opt/data/backup/mysql -p<br>$ cat 3306.cnf<br>[mysqld]<br>socket = /usr/local/mysql/data/run/mysqld_3306.sock<br>port = 3306<br>pid-file = /usr/local/mysql/data/run/mysqld_3306.pid<br>datadir = /usr/local/mysql/data/mysql_3306</pre></p>
<h1 id="set_for_GTID_Replication-2"><a href="#set_for_GTID_Replication-2" class="headerlink" title="set for GTID Replication"></a>set for GTID Replication</h1><p>server_id = 3232237894<br>gtid_mode = on<br>enforce_gtid_consistency = on</p>
<h1 id="binlog-1"><a href="#binlog-1" class="headerlink" title="binlog"></a>binlog</h1><p>log-bin = /usr/local/mysql/data/binlogs/master-binlog<br>log-slave-updates = 1<br>binlog_format = row</p>
<h1 id="rely_log-2"><a href="#rely_log-2" class="headerlink" title="rely log"></a>rely log</h1><p>skip_slave_start=1</p>
<p>[client]<br>default-character-set = utf8</p>
<p>$ cat 3307.cnf<br>[mysqld]<br>socket = /usr/local/mysql/data/run/mysqld_3307.sock<br>port = 3307<br>pid-file = /usr/local/mysql/data/run/mysqld_3307.pid<br>datadir = /usr/local/mysql/data/mysql_3307</p>
<h1 id="set_for_GTID_Replication-3"><a href="#set_for_GTID_Replication-3" class="headerlink" title="set for GTID Replication"></a>set for GTID Replication</h1><p>server_id = 3232237866<br>gtid_mode = on<br>enforce_gtid_consistency = on</p>
<h1 id="bin_log-1"><a href="#bin_log-1" class="headerlink" title="bin log"></a>bin log</h1><p>log-bin = /usr/local/mysql/data/binlogs/slave-binlog<br>log-slave-updates = 1<br>binlog_format = row</p>
<h1 id="rely_log-3"><a href="#rely_log-3" class="headerlink" title="rely log"></a>rely log</h1><p>skip_slave_start=1</p>
<p>[client]<br>default-character-set = utf8<br>我们将使用下面命令完整数据库备份：</p>
<p><pre class="lang:default decode:true">$innobackupex –defaults-file=/opt/data/backup/mysql/3306.cnf –user=root  –socket=/usr/local/mysql/data/run/mysqld_3306.sock  /tmp</pre><br><a href="http://suzf.net/wp-content/uploads/2016/04/innobackup.png" target="_blank" rel="external"><img src="http://suzf.net/wp-content/uploads/2016/04/innobackup.png" alt="innobackup"></a></p>
<p>这里要注意的重要的文件是在xtrabackup_binlog_info</p>
<p><pre class="lang:default decode:true ">$ cat /tmp/2016-04-05_15-26-40/xtrabackup_binlog_info<br>master-binlog.000006  191 81ee72fe-c957-11e5-ae70-0800272aa66e:1-12</pre><br>在 Slave 节点恢复数据</p>
<p><pre class="lang:default decode:true ">$ innobackupex –defaults-file=/opt/data/backup/mysql/3307.cnf –user=root  –copy-back /tmp/2016-04-05_15-26-40</pre><br>备注<br>Original data directory must be empty!<br>即 Slave 节点数据目录必须为空</p>
<p>权限修复 启动实例</p>
<p><pre class="lang:default decode:true ">$ chown -R mysql:mysql  /usr/local/mysql/data/mysql_3307<br>$ /etc/init.d/mysqld_multi.server start 3307<br>$ /etc/init.d/mysqld_multi.server report<br>Reporting MySQL servers<br>MySQL server from group: mysqld3306 is running<br>MySQL server from group: mysqld3307 is running</pre><br>你需要先设置 gtid_purged 然后再创建 replication，在 <a href="https://www.percona.com/doc/percona-xtrabackup/2.1/howtos/recipes_ibkx_gtid.html" target="_blank" rel="external">Percona 文档 </a>中有说明</p>
<p><pre class="lang:default decode:true ">mysql&gt;  SET GLOBAL gtid_purged=”81ee72fe-c957-11e5-ae70-0800272aa66e:1-12”;<br>ERROR 1840 (HY000): @@GLOBAL.GTID_PURGED can only be set when @@GLOBAL.GTID_EXECUTED is empty.</pre></p>
<h1 id="u51FA_u73B0_u4E0A_u9762_u4E2A_u9519_u8BEF__u6267_u884C_u4E0B_u9762_u64CD_u4F5C"><a href="#u51FA_u73B0_u4E0A_u9762_u4E2A_u9519_u8BEF__u6267_u884C_u4E0B_u9762_u64CD_u4F5C" class="headerlink" title="出现上面个错误 执行下面操作"></a>出现上面个错误 执行下面操作</h1><p>mysql&gt; reset master;<br>Query OK, 0 rows affected (0.02 sec)</p>
<p>mysql&gt;  SET GLOBAL gtid_purged=”81ee72fe-c957-11e5-ae70-0800272aa66e:1-12”;<br>Query OK, 0 rows affected (0.05 sec)</p>
<p>mysql&gt; CHANGE MASTER TO<br>    -&gt; MASTER_HOST=’localhost’,<br>    -&gt; MASTER_USER=’repluser’,<br>    -&gt; MASTER_PASSWORD=’suzf.net666’,<br>    -&gt; MASTER_PORT=3306,<br>    -&gt; MASTER_AUTO_POSITION = 1;<br>Query OK, 0 rows affected, 2 warnings (0.06 sec)</p>
<p>mysql&gt; SHOW WARNINGS;<br>+——-+——+————————————————————————————————————————————————————————————————————————————————————————————–+<br>| Level | Code | Message                                                                                                                                                                                                                                                                              |<br>+——-+——+————————————————————————————————————————————————————————————————————————————————————————————–+<br>| Note  | 1759 | Sending passwords in plain text without SSL/TLS is extremely insecure.                                                                                                                                                                                                               |<br>| Note  | 1760 | Storing MySQL user name or password information in the master info repository is not secure and is therefore not recommended. Please consider using the USER and PASSWORD connection options for START SLAVE; see the ‘START SLAVE Syntax’ in the MySQL Manual for more information. |<br>+——-+——+————————————————————————————————————————————————————————————————————————————————————————————–+<br>2 rows in set (0.00 sec)<br>在经典的复制中（MySQL的5.5及以下）命令应该是这样的：</p>
<p><pre class="lang:default decode:true ">change master to master_host=’lab.suzf.net’, master_port=3306, master_user=’repluser’, master_password=’suzf.net666’,  master_log_file=’mysql-bin.000006’, master_log_pos=1026;</pre><br>启动 slave 查看状态</p>
<p><pre class="lang:default decode:true ">mysql&gt; start slave;<br>Query OK, 0 rows affected (0.01 sec)</pre></p>
<p>mysql&gt; show slave status\G<br>             Slave_IO_Running: Yes<br>            Slave_SQL_Running: Yes<br>      Slave_SQL_Running_State: Slave has read all relay log; waiting for the slave I/O thread to update it<br>           Retrieved_Gtid_Set: 81ee72fe-c957-11e5-ae70-0800272aa66e:13<br>            Executed_Gtid_Set: 81ee72fe-c957-11e5-ae70-0800272aa66e:1-13<br>                Auto_Position: 1<br>&nbsp;</p>
<p>&nbsp;</p>
<h5 id="u573A_u666F_u56DB_uFF1A_u7ECF_u5178_u590D_u5236__u2013_26gt_3B_GTID_Replication"><a href="#u573A_u666F_u56DB_uFF1A_u7ECF_u5178_u590D_u5236__u2013_26gt_3B_GTID_Replication" class="headerlink" title="场景四：经典复制 –&gt; GTID Replication"></a>场景四：经典复制 –&gt; GTID Replication</h5><p>a. 按场景一中描述配置参数文件<br>b. 所有服务器设置global.read_only参数，等待主从服务器同步完毕；<br>mysql&gt; SET @@global.read_only = ON;<br>c. 依次重启主从服务器；<br>d. 使用change master 更新主从配置；<br>mysql&gt; CHANGE MASTER TO<br>&gt; MASTER_HOST = host,<br>&gt; MASTER_PORT = port,<br>&gt; MASTER_USER = user,<br>&gt; MASTER_PASSWORD = password,<br>&gt; MASTER_AUTO_POSITION = 1;<br>e. 从库开启复制<br>mysql&gt; START SLAVE;<br>f. 验证主从复制</p>
<p>##### </p>
<h3 id="FAQ"><a href="#FAQ" class="headerlink" title="FAQ"></a>FAQ</h3><h3 id="Skip_counter_with_GTID"><a href="#Skip_counter_with_GTID" class="headerlink" title="Skip counter with GTID"></a>Skip counter with GTID</h3><p><pre class="lang:default decode:true mysql ">mysql&gt; show slave status\G<br><strong><strong><strong><strong><strong><strong><em>*</em></strong></strong></strong></strong></strong></strong> 1. row <strong><strong><strong><strong><strong><strong><em>*</em></strong></strong></strong></strong></strong></strong><br>           Retrieved_Gtid_Set: 770d3753-c6e4-11e2-8e78-080027d93e15:1-9<br>            Executed_Gtid_Set: 770d3753-c6e4-11e2-8e78-080027d93e15:1-7,<br>97e23f6a-cc52-11e2-b1e1-08002776e125:1-2<br>                Auto_Position: 1<br>1 row in set (0.00 sec)</pre><br>从上面我们可以猜测到 事务执行到 事务ID 8 可能出现错误，接下来我们需要注入相同的空事务ID。</p>
<p><pre class="lang:default decode:true mysql">mysql&gt; stop slave;<br>Query OK, 0 rows affected (0.00 sec)</pre></p>
<p>mysql&gt; show variables like ‘%gtid%’;<br>+————————–+———–+<br>| Variable_name            | Value     |<br>+————————–+———–+<br>| enforce_gtid_consistency | ON        |<br>| gtid_executed            |           |<br>| gtid_mode                | ON        |<br>| gtid_next                | AUTOMATIC |<br>| gtid_owned               |           |<br>| gtid_purged              |           |<br>+————————–+———–+<br>6 rows in set (0.00 sec)</p>
<p>mysql&gt; set gtid_next=’770d3753-c6e4-11e2-8e78-080027d93e15:8’;<br>Query OK, 0 rows affected (0.00 sec)</p>
<p>mysql&gt; begin;<br>Query OK, 0 rows affected (0.00 sec)</p>
<p>mysql&gt; commit;<br>Query OK, 0 rows affected (0.00 sec)</p>
<p>mysql&gt; set gtid_next=’AUTOMATIC’;<br>Query OK, 0 rows affected (0.00 sec)</p>
<p>mysql&gt; start slave;<br>Query OK, 0 rows affected (0.00 sec)<br>&nbsp;</p>
<p>Reference : <a href="https://dev.mysql.com/doc/refman/5.6/en/replication-gtids.html" target="_blank" rel="external">Mysql manual</a></p>
<p>&nbsp;</p>
]]></content>
    <summary type="html">
    <![CDATA[<h3 id="u51C6_u5907_u5DE5_u4F5C"><a href="#u51C6_u5907_u5DE5_u4F5C" class="headerlink" title="准备工作"></a>准备工作</h3><p><a href="http://suzf.net/thread-1202-555.html">Mysql 单机多实例详解</a><br><a href="http://suzf.net/thread-0401-693.html">What is the GTID of the replication</a></p>
<h3 id="u5B9E_u9A8C_u73AF_u5883"><a href="#u5B9E_u9A8C_u73AF_u5883" class="headerlink" title="实验环境"></a>实验环境</h3><p>Os: CentOS 6.X<br>Mysql: 5.6 单机多实例 [3306,3307]<br>Hostname: lab.suzf.net</p>
<h5 id="u573A_u666F_u4E00_uFF1A_u65B0_u673A_u5668__u65E0_u6570_u636E"><a href="#u573A_u666F_u4E00_uFF1A_u65B0_u673A_u5668__u65E0_u6570_u636E" class="headerlink" title="场景一：新机器 无数据"></a>场景一：新机器 无数据</h5><p>##### </p>
<p>对于GTID的配置，主要修改配置文件中与GTID特性相关的几个重要参数]]>
    
    </summary>
    
      <category term="GTID" scheme="http://blog.suzf.net/tags/GTID/"/>
    
      <category term="Mysql" scheme="http://blog.suzf.net/tags/Mysql/"/>
    
      <category term="Mysql" scheme="http://blog.suzf.net/categories/Mysql/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Mysql GTID 简述]]></title>
    <link href="http://blog.suzf.net/2016/04/01/Mysql_GTID_%E7%AE%80%E8%BF%B0/"/>
    <id>http://blog.suzf.net/2016/04/01/Mysql_GTID_简述/</id>
    <published>2016-04-01T02:24:38.000Z</published>
    <updated>2016-04-29T12:43:02.000Z</updated>
    <content type="html"><![CDATA[<p>GTID是一个基于原始mysql服务器生成的一个已经被成功执行的全局事务ID，它由服务器ID以及事务ID组合而成。这个全局事务ID不仅仅在原始服务器器上唯一，在所有存在主从关系 的mysql服务器上也是唯一的。正是因为这样一个特性使得mysql的主从复制变得更加简单，以及数据库一致性更可靠。本文主要描述了快速配置一个基于GTID的主从复制架构，供大家参考。<a id="more"></a></p>
<h3 id="u4E00_u3001GTID_u7684_u6982_u5FF5"><a href="#u4E00_u3001GTID_u7684_u6982_u5FF5" class="headerlink" title="一、GTID的概念"></a>一、GTID的概念</h3><p>1、全局事务标识：global transaction identifiers。<br>2、GTID是一个事务一一对应，并且全局唯一ID。<br>3、一个GTID在一个服务器上只执行一次，避免重复执行导致数据混乱或者主从不一致。<br>4、GTID用来代替传统复制方法，不再使用MASTER_LOG_FILE+MASTER_LOG_POS开启复制。而是使用MASTER_AUTO_POSTION=1的方式开始复制。<br>5、MySQL-5.6.5开始支持的，MySQL-5.6.10后开始完善。<br>6、在传统的slave端，binlog是不用开启的，但是在GTID中slave端的binlog是必须开启的，目的是记录执行过的GTID（强制）。</p>
<h3 id="u4E8C_u3001GTID_u7684_u7EC4_u6210"><a href="#u4E8C_u3001GTID_u7684_u7EC4_u6210" class="headerlink" title="二、GTID的组成"></a>二、GTID的组成</h3><p>GTID = source_id:transaction_id<br>source_id，用于鉴别原服务器，即mysql服务器唯一的的server_uuid，由于GTID会传递到slave，所以也可以理解为源ID。<br>transaction_id，为当前服务器上已提交事务的一个序列号，通常从1开始自增长的序列，一个数值对应一个事务。<br>示例：<br>3E11FA47-71CA-11E1-9E33-C80AA9429562:23<br>前面的一串为服务器的server_uuid，即3E11FA47-71CA-11E1-9E33-C80AA9429562，后面的23为transaction_id</p>
<h3 id="u4E09_u3001GTID_u7684_u4F18_u52BF"><a href="#u4E09_u3001GTID_u7684_u4F18_u52BF" class="headerlink" title="三、GTID的优势"></a>三、GTID的优势</h3><p>1、更简单的实现failover，不用以前那样在需要找log_file和log_pos。<br>2、更简单的搭建主从复制。<br>3、比传统的复制更加安全。<br>4、GTID是连续的没有空洞的，保证数据的一致性，零丢失。</p>
<h3 id="u56DB_u3001GTID_u7684_u5DE5_u4F5C_u539F_u7406"><a href="#u56DB_u3001GTID_u7684_u5DE5_u4F5C_u539F_u7406" class="headerlink" title="四、GTID的工作原理"></a>四、GTID的工作原理</h3><p>1、当一个事务在主库端执行并提交时，产生GTID，一同记录到binlog日志中。<br>2、binlog传输到slave,并存储到slave的relaylog后，读取这个GTID的这个值设置gtid_next变量，即告诉Slave，下一个要执行的GTID值。<br>3、sql线程从relay log中获取GTID，然后对比slave端的binlog是否有该GTID。<br>4、如果有记录，说明该GTID的事务已经执行，slave会忽略。<br>5、如果没有记录，slave就会执行该GTID事务，并记录该GTID到自身的binlog，<br>在读取执行事务前会先检查其他session持有该GTID，确保不被重复执行。<br>6、在解析过程中会判断是否有主键，如果没有就用二级索引，如果没有就用全部扫描。</p>
<p>节选自： <a href="http://blog.csdn.net/leshami/article/details/50630691" target="_blank" rel="external">乐沙弥的世界</a></p>
]]></content>
    <summary type="html">
    <![CDATA[<p>GTID是一个基于原始mysql服务器生成的一个已经被成功执行的全局事务ID，它由服务器ID以及事务ID组合而成。这个全局事务ID不仅仅在原始服务器器上唯一，在所有存在主从关系 的mysql服务器上也是唯一的。正是因为这样一个特性使得mysql的主从复制变得更加简单，以及数据库一致性更可靠。本文主要描述了快速配置一个基于GTID的主从复制架构，供大家参考。]]>
    
    </summary>
    
      <category term="GTID" scheme="http://blog.suzf.net/tags/GTID/"/>
    
      <category term="Mysql" scheme="http://blog.suzf.net/tags/Mysql/"/>
    
      <category term="Mysql" scheme="http://blog.suzf.net/categories/Mysql/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[[译]  zookeeper 配置文件详解]]></title>
    <link href="http://blog.suzf.net/2016/03/29/'%5B%E8%AF%91%5D__zookeeper_%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3'/"/>
    <id>http://blog.suzf.net/2016/03/29/'[译]__zookeeper_配置文件详解'/</id>
    <published>2016-03-29T07:22:32.000Z</published>
    <updated>2016-03-31T06:27:01.000Z</updated>
    <content type="html"><![CDATA[<p><strong>必填配置参数</strong></p>
<p>clientPort</p>
<p>该端口监听客户端的连接。也就是说，客户端都会尝试连接该端口。</p>
<p>dataDir</p>
<p>该路径用于存储zookeeper内存数据库快照。除非有特殊设定，否则也会存储数据库更新的事物日志。事物日志的存放位置是很有讲究的。有一台专门用于存放事物日志的设备，可以产生持久的高性能。讲日志放在高负荷的设备上，会对性能产生副作用。<a id="more"></a></p>
<p>tickTime</p>
<p>一个心跳的长度，它是zookeeper毫秒级的一个基本时间单位。它用来设定心跳间隔和超时时间。例如，最小会话超时时间是两倍的心跳长度。</p>
<p><strong>可选配置参数</strong></p>
<p>dataLogDir</p>
<p>这个选项指定将事物日志存储于该路径，代替了dataDir。目的是可以用专门的设备来存储日志，这样可以避免日志和快照的资源竞争。有一个专门的 日志存储设备，可以导致高的吞吐量和稳定性。我们更推荐使用一台专用日志设备并用dataLogDir在该设备上指定目录来存放日志，这样可以保证 dataDir指定的目录不在该设备上(dataDir指定存放快照的目录，快照和日志会竞争资源)。</p>
<p>globalOutstandingLimit(java:zookeeper.globalOutstandingLimit)</p>
<p>客户端提交请求的速度可能会超过zookeeper处理请求的速度，尤其是存在大量的客户端。为了避免由于排队的请求导致的内存溢 出，zookeeper将会对客户端进行限流，将请求的数量保持在globalOutstandingLimit以下。 globalOutstandingLimit的默认值是1000。</p>
<p>preAllocSize(java:zookeeper.preAllocSize)</p>
<p>zookeeper将事务日志文件分割成preAllocSize kb大小的模块，这样可以避免查询带来的消耗。默认的模块大小是64M。当快照频繁产生时，我们可以肩上模块的大小来提高系统的效率(这段好难翻译，还不知道对不对)。</p>
<p>snapCount(java:zookeeper.snapCount)</p>
<p>zookeeper将所有事务记录到日志中。当记录了snapCount数量的事务后，会生成新的快照和事务日志文件。snapCount默认值是100000。</p>
<p>traceFile(Java:requestTraceFile)</p>
<p>如果使用该选项，我们会将请求记录在追踪文件中，并将其以traceFile.year.month.day格式命名。这个选项可以提供调试信息，但会影响性能。</p>
<p>maxClientCnxns</p>
<p>一个客户端的最大并发连接数(接口级别)，每台客户端用IP地址区分，成为zookeeper总体中的一个成员(貌似翻译的不对)。它用来防止某些DoS攻击，包括文件描述符耗尽(不懂-_-||)。默认值是60。将其设定为0，则取消并发连接数的限制。</p>
<p>clientPortAddress</p>
<p>监听客户端连接的地址(ipv4,ipv6,hostname)，也就是说，客户端会尝试连接该地址。可选配置，默认情况下，客户端都会连接到clientPort上(address,interface,nic)。</p>
<p>minSessionTimeout</p>
<p>最小会话超时时间(毫秒级)，默认是2倍的tickTime。</p>
<p>maxSessionTimeout</p>
<p>最大会话超时时间(毫秒级)，默认是20倍的tickTime。(在代码中会设置超时时间，但是必须在这里设定的最小与最大值之间，否则直接取最小/最大值)</p>
<p>fsync.warningthresholdms(java:fsync.warningthresholdms)</p>
<p>当日志中的fsync函数超出了该值的长度，就会在日志出输出警告信息。默认值是1000(毫秒级)，是系统属性。</p>
<p>autopurge.snapRetainCount</p>
<p>当启用时，zookeeper将自动储存最近autopurge.snapRetainCount次的快照和事务日志，分别放在dataDir和dataLogDir中，其余部分将被删除。默认值是3，最小值是3。</p>
<p>autopurge.purgeInterval</p>
<p>设置该定时器，能定时触发净化任务(清理快照和日志)，单位为小时，值为大于等于1的正整数，默认值是0。</p>
<p><strong>集群选项</strong></p>
<p>electionAlg</p>
<p>作用是实现选举。0是基于UDP的传统版本，1是基于未认证UDP的快速选举版本，2是基于已认证UDP的快速选举版本，3是基于TCP的快速选举版本。默认值是3。(0/1/2已经不建议使用，在下个版本准备取消)</p>
<p>initLimit</p>
<p>在心跳连接中，允许followers连接leader和与leader同步数据的时间。如果zookeeper管理的数据比较大，可以增加此值。</p>
<p>leaderServes(zookeeper.leaderServes)</p>
<p>leader接受客户端的连接。默认值是“yes”。leader主机的坐标更新。要实现使用很少的读取量而达到更高的更新量，leader可以不 接受客户端的连接而是只专注于负载的均衡。默认值是“yes”，就是可以接受连接。(当集群中存在3台以上的zookeeper服务端时，推荐使用 “no”)</p>
<p>server.x=[hostname]:nnnnn[:nnnnn]，etc</p>
<p>配置的服务端组成zookeeper集群。集群启动时，将在配置的服务端上寻找myid文件。该文件包含服务器编号，于server.x中的x值相匹配。</p>
<p>每台zookeeper服务器都持有这个服务器列表，客户端必须根据这个列表进行连接。</p>
<p>配置中还存在两个端口号nnnnn。第一个端口号用于follower连接leader，第二个端口号用于leader的选举。当electionAlg=1,2,3时，选举端口是必要的。当=0时，不是必要的。加入想要在单机上测试集群，可以使用不同端口号来模拟。</p>
<p>syncLimit</p>
<p>在心跳连接中，允许followers同步zookeeper数据的时间。如果followers与leader长久失去连接，它将被丢弃。</p>
<p>group.x=nnnnn[:nnnnn]</p>
<p>实现一个分层的法定人数的构造。“x”是组的标识，“=”后边是服务器的标识。</p>
<p>例：group.2=4:5:6<br>group.3=7:8:9</p>
<p>weight.x=nnnnn[:nnnnn]</p>
<p>要与group搭配使用，为服务器设置一个比重。这个比重就是选举投票时一台服务器的比重。group.1=1:2:3</p>
<p>例：weight.1=1<br>weight.2=1<br>weight.3=1<br>weight.4=1<br>weight.5=1<br>weight.6=1<br>weight.7=1<br>weight.8=1<br>weight.9=1</p>
<p>cnxTimeout</p>
<p>leader选举的超时时间，electionAlg=3时才起作用。默认值是5秒。</p>
<p>原文地址：<a href="http://zookeeper.apache.org/doc/r3.4.5/zookeeperAdmin.html" target="_blank" rel="external">http://zookeeper.apache.org/doc/r3.4.5/zookeeperAdmin.html</a></p>
<p>来源： <a href="http://my.csdn.net/u011796274" target="_blank" rel="external">静静的小猪</a></p>
]]></content>
    <summary type="html">
    <![CDATA[<p><strong>必填配置参数</strong></p>
<p>clientPort</p>
<p>该端口监听客户端的连接。也就是说，客户端都会尝试连接该端口。</p>
<p>dataDir</p>
<p>该路径用于存储zookeeper内存数据库快照。除非有特殊设定，否则也会存储数据库更新的事物日志。事物日志的存放位置是很有讲究的。有一台专门用于存放事物日志的设备，可以产生持久的高性能。讲日志放在高负荷的设备上，会对性能产生副作用。]]>
    
    </summary>
    
      <category term="zookeeper" scheme="http://blog.suzf.net/tags/zookeeper/"/>
    
      <category term="Hadoop" scheme="http://blog.suzf.net/categories/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[[译] zookpeer 入门教程]]></title>
    <link href="http://blog.suzf.net/2016/03/29/'%5B%E8%AF%91%5D_zookpeer_%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B'/"/>
    <id>http://blog.suzf.net/2016/03/29/'[译]_zookpeer_入门教程'/</id>
    <published>2016-03-29T07:19:33.000Z</published>
    <updated>2016-03-31T06:27:01.000Z</updated>
    <content type="html"><![CDATA[<h3 id="u5165_u95E8_uFF1A_u5206_u5E03_u5F0F_u5E94_u7528_u7A0B_u5E8F_u534F_u8C03_u670D_u52A1_ZooKeeper"><a href="#u5165_u95E8_uFF1A_u5206_u5E03_u5F0F_u5E94_u7528_u7A0B_u5E8F_u534F_u8C03_u670D_u52A1_ZooKeeper" class="headerlink" title="入门：分布式应用程序协调服务 ZooKeeper"></a>入门：分布式应用程序协调服务 ZooKeeper</h3><p>本文档包含的信息来帮助你的ZooKeeper快速入门。它是在开发人员希望能够尝试一下主要目的，并包含安装简单说明一个ZooKeeper的服务器，几个命令，以验证它是否正在运行，一个简单的编程示例。最后，为了方便，还有更多的关于安装复杂，几节，例如运行复制的部署和优化事务日志。然而，对于商业部署的完整说明，请参阅的<a href="http://zookeeper.apache.org/doc/trunk/zookeeperAdmin.html" target="_blank" rel="external">ZooKeeper管理员指南</a>。</p>
<h3 id="u5148_u51B3_u6761_u4EF6"><a href="#u5148_u51B3_u6761_u4EF6" class="headerlink" title="先决条件"></a>先决条件</h3><p>见管理员指南中的<a href="http://zookeeper.apache.org/doc/trunk/zookeeperAdmin.html#sc_systemReq" target="_blank" rel="external">系统要求</a>。</p>
<h3 id="u4E0B_u8F7D"><a href="#u4E0B_u8F7D" class="headerlink" title="下载"></a>下载</h3><p>从Apache下载镜像下载最近的<a href="http://zookeeper.apache.org/releases.html" target="_blank" rel="external">稳定版本</a> ，从而得到 ZooKeeper 程序。</p>
<h3 id="Standalone__u6A21_u5F0F_u4E0B_u64CD_u4F5C"><a href="#Standalone__u6A21_u5F0F_u4E0B_u64CD_u4F5C" class="headerlink" title="Standalone 模式下操作"></a>Standalone 模式下操作</h3><p>设置在独立模式&lt; standalone &gt;下的ZooKeeper服务器很简单。服务器被包含在一个单一的JAR文件中，所以安装包括创建一个新的配置。</p>
<p>一旦你下载一个稳定ZooKeeper的版本 解压它并进入解压的根路径<br>要启动的ZooKeeper你需要一个配置文件。下面是一个示例, 新建文件  conf/zoo.cfg：</p>
<p><pre class="lang:default decode:true ">tickTime=2000<br>dataDir=/var/lib/zookeeper<br>clientPort=2181</pre><br>这个文件可以叫任何一个名字，但是一般我们更喜欢 设置为  conf/zoo.cfg. 我们需要将 dataDir 的值 设置为一个指定的目录，一开始这个是空的。<br>下面是每个参数的含义：<br>tickTime：基本事件单元，以毫秒为单位。它用来指示心跳，最小的 session 过期时间为两倍的 tickTime. 。<br>dataDir：存储内存中数据库快照的位置，如果不设置参数，更新事务日志将被存储到默认位置。<br>clientPort：监听客户端连接的端口</p>
<p>现在你可以创建文件并且启动它了<br>bin/zkServer.sh start</p>
<p>ZooKeeper 日志使用 log4j – 更多详细信息请查看编程指南的 <a href="http://zookeeper.apache.org/doc/trunk/zookeeperProgrammers.html#Logging" target="_blank" rel="external">日志</a> 部分。 你将会看到日志出现在控制台&lt; 默认 &gt; 日志文件依赖于log4j 的配置文件。</p>
<p>上面所述的是如何使 ZooKeeper 运行在单点模式下。这里没有复制，所以如果 ZooKeeper 进程出现错误，服务将不可用。这是一个不错的开发解决方案，但是如果想要使 ZooKeeper 运行在复制模式下，请参见 <a href="http://zookeeper.apache.org/doc/trunk/zookeeperStarted.html#sc_RunningReplicatedZooKeeper" target="_blank" rel="external">Running Replicated ZooKeeper</a>.</p>
<h3 id="u7BA1_u7406_ZooKeeper__u5B58_u50A8"><a href="#u7BA1_u7406_ZooKeeper__u5B58_u50A8" class="headerlink" title="管理 ZooKeeper 存储"></a>管理 ZooKeeper 存储</h3><p>对于长期运行在生产环境的 ZooKeeper 来说 存储必须外部管理（dataDir &amp;&amp; logs）。获取更多信息见 <a href="http://zookeeper.apache.org/doc/trunk/zookeeperAdmin.html#sc_maintenance" target="_blank" rel="external">维护部分</a>。</p>
<h3 id="u8FDE_u63A5_ZooKeeper"><a href="#u8FDE_u63A5_ZooKeeper" class="headerlink" title="连接 ZooKeeper"></a>连接 ZooKeeper</h3><p>一旦 ZooKeeper 运行起来，你会有很多种方式连接它：</p>
<ul>
<li>Java:<br>bin/zkCli.sh -server 127.0.0.1:2181<br>这样是你的操作变得简单，想文件操作一样。</li>
<li>C:  C: compile cli_mt (multi-threaded) or cli_st (single-threaded) by running make     cli_mt or make cli_st in the src/c subdirectory in the ZooKeeper sources. See the     README contained within src/c for full details<br>You can run the program from src/c using:<br>LD_LIBRARY_PATH=. cli_mt 127.0.0.1:2181<br>or<br>LD_LIBRARY_PATH=. cli_st 127.0.0.1:2181<br>它会给你在ZooKeeper上提供一个简单的shell执行文件操作。<br>一旦你成功连接，你将会看到类似下面的信息：<br><pre class="lang:default decode:true ">Connecting to localhost:2181<br>log4j:WARN No appenders could be found for logger (org.apache.zookeeper.ZooKeeper).<br>log4j:WARN Please initialize the log4j system properly.<br>Welcome to ZooKeeper!<br>JLine support is enabled<br>[zkshell: 0]</pre><br>在shell中，在客户端键入 <code>help</code> 可以得到帮助信息：<br><pre class="lang:default decode:true">[zkshell: 0] help<br>ZooKeeper host:port cmd args<pre><code>get path [watch]
ls path [watch]
set path data [version]
delquota [-n|-b] path
quit
printwatches on|off
create path data acl
stat path [watch]
listquota path
history
setAcl path acl
getAcl path
sync path
redo cmdno
addauth scheme auth
delete path [version]
deleteall path
setquota -n|-b val path&lt;/pre&gt;
</code></pre>在这里，你可以键入一些简单的命令来感受这个简单的命令行界面。首先，从list 命令开始 ，如ls：<br><pre class="lang:default decode:true ">[zkshell: 8] ls /<br>[zookeeper]</pre><br>接下来，执行 <code>create /zk_test my_data</code> 创建一个新的 znode。这个新创建的znode 和字符串”my_data”是关联的。你应该可以看到：<br><pre class="lang:default decode:true ">[zkshell: 9] create /zk_test my_data<br>Created /zk_test</pre><br>发出另一个 <code>ls /</code> 命令查看目录：<br><pre class="lang:default decode:true ">[zkshell: 11] ls /<br>[zookeeper, zk_test]</pre><br>请注意，zk_test 目录现在已经创建完成了。<br>接下来，执行 get 命令来验证数据与其关联的znode:<br><pre class="lang:default decode:true ">[zkshell: 12] get /zk_test<br>my_data<br>cZxid = 5<br>ctime = Fri Jun 05 13:57:06 PDT 2009<br>mZxid = 5<br>mtime = Fri Jun 05 13:57:06 PDT 2009<br>pZxid = 5<br>cversion = 0<br>dataVersion = 0<br>aclVersion = 0<br>ephemeralOwner = 0<br>dataLength = 7<br>numChildren = 0</pre><br>我们可以使用 set 命令来修改与zk_test相关的数据：<br><pre class="lang:default decode:true">[zkshell: 14] set /zk_test junk<br>cZxid = 5<br>ctime = Fri Jun 05 13:57:06 PDT 2009<br>mZxid = 6<br>mtime = Fri Jun 05 14:01:52 PDT 2009<br>pZxid = 5<br>cversion = 0<br>dataVersion = 1<br>aclVersion = 0<br>ephemeralOwner = 0<br>dataLength = 4<br>numChildren = 0<br>[zkshell: 15] get /zk_test<br>junk<br>cZxid = 5<br>ctime = Fri Jun 05 13:57:06 PDT 2009<br>mZxid = 6<br>mtime = Fri Jun 05 14:01:52 PDT 2009<br>pZxid = 5<br>cversion = 0<br>dataVersion = 1<br>aclVersion = 0<br>ephemeralOwner = 0<br>dataLength = 4<br>numChildren = 0</pre><br>（请注意，我们在更新完数据之后通过get得到了它有变动）<br>最后，让我们删除我们之前创建的znode:<br><pre class="lang:default decode:true ">[zkshell: 16] delete /zk_test<br>[zkshell: 17] ls /<br>[zookeeper]<br>[zkshell: 18]</pre><br>到此为止吧。如果要获取更多信息，继续本文档的其余部分和 <a href="http://zookeeper.apache.org/doc/trunk/zookeeperProgrammers.html" target="_blank" rel="external">程序员指南</a>。</pre></li>
</ul>
<h3 id="ZooKeeper__u7F16_u7A0B"><a href="#ZooKeeper__u7F16_u7A0B" class="headerlink" title="ZooKeeper 编程"></a>ZooKeeper 编程</h3><p>ZooKeeper提供了 Java 和 C 两种程序语言接口。它们功能上是等价的。但是C接口有两种变种存在：单线程和多线程。这些只有在如何完成消息循环是不同的。欲了解更多信息，请参阅的<a href="http://zookeeper.apache.org/doc/trunk/zookeeperProgrammers.html" target="_blank" rel="external">ZooKeeper程序员指南中的编程示例</a>使用不同的API的示例代码。</p>
<h3 id="ZooKeeper_Replicated"><a href="#ZooKeeper_Replicated" class="headerlink" title="ZooKeeper Replicated"></a>ZooKeeper Replicated</h3><p>在开发和测试模式下，将ZooKeeper运行在独立模式下便于评估。但是在生产模式下，你应该讲ZooKeeper运行在 replicated 模式下。对于相同的应用程序来说，一组运行在replicated 的机器被称作 quorum。所有在 quorum 中的机器都有相同配置文件。</p>
<blockquote>
<p>注意：</p>
<p>对于复制模式来说，至少需要三台机器，这里强烈建议你有奇数台机器。如果你只有两台机器，那么你可能会出现这种情况，如果其中一个出现故障，在有些情况下没有足够的机器来形成多数quorum。两个服务器比单个服务器还不稳定，因为当有故障时它们都指向错误。<br>这里在复制模式下需要的 cong/zoo.cfg 文件与在单节点模式下很相近，但是这里有些不同。<br>请看下面的例子：</p>
<p><pre class="lang:default decode:true ">tickTime=2000<br>dataDir=/var/lib/zookeeper<br>clientPort=2181<br>initLimit=5<br>syncLimit=2<br>server.1=zoo1:2888:3888<br>server.2=zoo2:2888:3888<br>server.3=zoo3:2888:3888</pre><br>新的条目<br>initLimit 在心跳连接中，允许followers连接leader和与leader同步数据的时间。如果zookeeper管理的数据比较大，可以增加此值。<br>syncLimit 在心跳连接中，允许followers同步zookeeper数据的时间。如果followers与leader长久失去连接，它将被丢弃。</p>
</blockquote>
<p>有了这两个关于超时的参数，你可以使用tickTime确定时间单元。在这个例子中，initLimit 的超时是 5 ticks &lt;2000 毫秒 一 tick &gt;,或者是10 秒。</p>
<p>表单中的 <code>server.x</code> 列出了组成 ZooKeeper 服务的机器。当服务启动的时候，它通过查找数据目录中的文件身份识别码来识别它是哪台服务器。这个文件有包含了以ASCII码 编码的服务器编号。</p>
<p>最后，注意每个服务器名称后的两个端口号：”2888”和”3888”。同行使用当前端口连接到其他节点。这样的连接测试是必要的，这样对等体可以进行通信，例如，在更新的顺序一致中。更具体地说，ZooKeeper的服务器使用此端口将follower连接到leader。当一个新的leader出现，follower打开一个TCP连接，使用此端口连接到leader。因为默认leader选举也采用TCP，我们目前需要的其他端口用来leader的选举。这就是在server条目的第二端口。</p>
<blockquote>
<p>注意：</p>
<p>如果你现在单机上测试集群伪分布。在本地主机该服务器的配置文件中的每个server.X 中指定服务器名与唯一的 quorum &amp; leader 选举端口(如：2888:3888, 2889:3889, 2890:3890 )。当然，独立的dataDirs和不同的客户端端口也是必要的（在上面的复制例如，在一个单一的本地主机上运行，你仍然有三个配置文件）。</p>
<p>请注意，在一台机器上设置的集群伪分布不会产生任何冗余。如果出了什么错误造成机器不能正常提供服务，所有的ZooKeeper服务将下线。完全冗余需要每个服务器都有它自己的机器。它必须是一个完全独立的物理服务器。在同一台物理主机上的多个虚拟机仍然容易受到威胁。<br>&nbsp;</p>
</blockquote>
<h3 id="u5176_u4ED6_u64CD_u4F5C"><a href="#u5176_u4ED6_u64CD_u4F5C" class="headerlink" title="其他操作"></a>其他操作</h3><p>这里仍有一些其他配置参数可以大大提升性能：</p>
<p>有一个专门的事务日志目录是很重要的可以在更新的时候降低延迟。在默认情况下，在同一目录存放 data snapshots 和 myid 文件.这个 dataLogDir 参数表示不同的目录用于事务日志。</p>
<p>待定： … …</p>
<p>原文：<a href="http://zookeeper.apache.org/doc/trunk/zookeeperStarted.html" target="_blank" rel="external">ZooKeeper Getting Started Guide</a></p>
]]></content>
    <summary type="html">
    <![CDATA[<h3 id="u5165_u95E8_uFF1A_u5206_u5E03_u5F0F_u5E94_u7528_u7A0B_u5E8F_u534F_u8C03_u670D_u52A1_ZooKeeper"><a href="#u5165_u95E8_uFF1A_u5206_u5E]]>
    </summary>
    
      <category term="zookeeper" scheme="http://blog.suzf.net/tags/zookeeper/"/>
    
      <category term="Hadoop" scheme="http://blog.suzf.net/categories/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[zookeeper 工作原理]]></title>
    <link href="http://blog.suzf.net/2016/03/23/zookeeper_%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/"/>
    <id>http://blog.suzf.net/2016/03/23/zookeeper_工作原理/</id>
    <published>2016-03-23T13:26:16.000Z</published>
    <updated>2016-03-31T05:38:36.000Z</updated>
    <content type="html"><![CDATA[<p>ZooKeeper 是一个分布式的，开放源码的分布式应用程序协调服务，它包含一个简单的原语集，分布式应用程序可以基于它实现同步服务，配置维护和命名服务等。 Zookeeper是hadoop的一个子项目，其发展历程无需赘述。在分布式应用中，由于工程师不能很好地使用锁机制，以及基于消息的协调机制不适合在 某些应用中使用，因此需要有一种可靠的、可扩展的、分布式的、可配置的协调机制来统一系统的状态。Zookeeper的目的就在于此。本文简单分析 zookeeper的工作原理，对于如何使用zookeeper不是本文讨论的重点。<a id="more"></a></p>
<p><strong>1 Zookeeper的基本概念</strong></p>
<p><strong>1.1 角色</strong></p>
<p>Zookeeper中的角色主要有以下三类，如下表所示：</p>
<p><a href="http://suzf.net/wp-content/uploads/2016/03/zk1.png" target="_blank" rel="external"><img src="http://suzf.net/wp-content/uploads/2016/03/zk1.png" alt="zk1"></a></p>
<p>系统模型如图所示：</p>
<p><a href="http://suzf.net/wp-content/uploads/2016/03/zk2.png" target="_blank" rel="external"><img src="http://suzf.net/wp-content/uploads/2016/03/zk2.png" alt="zk2"></a></p>
<p><strong>1.2 设计目的</strong></p>
<p>1.最终一致性：client不论连接到哪个Server，展示给它都是同一个视图，这是zookeeper最重要的性能。</p>
<p>2 .可靠性：具有简单、健壮、良好的性能，如果消息m被到一台服务器接受，那么它将被所有的服务器接受。</p>
<p>3 .实时性：Zookeeper保证客户端将在一个时间间隔范围内获得服务器的更新信息，或者服务器失效的信息。但由于网络延时等原因，Zookeeper不能保证两个客户端能同时得到刚更新的数据，如果需要最新数据，应该在读数据之前调用sync()接口。</p>
<p>4 .等待无关（wait-free）：慢的或者失效的client不得干预快速的client的请求，使得每个client都能有效的等待。</p>
<p>5.原子性：更新只能成功或者失败，没有中间状态。</p>
<p>6 .顺序性：包括全局有序和偏序两种：全局有序是指如果在一台服务器上消息a在消息b前发布，则在所有Server上消息a都将在消息b前被发布；偏序是指如果一个消息b在消息a后被同一个发送者发布，a必将排在b前面。</p>
<p><strong>2 ZooKeeper的工作原理</strong></p>
<p>Zookeeper的核心是原子广播，这个机制保证了各个Server之间的同步。实现这个机制的协议叫做Zab协议。Zab协议有两种模式，它们 分别是恢复模式（选主）和广播模式（同步）。当服务启动或者在领导者崩溃后，Zab就进入了恢复模式，当领导者被选举出来，且大多数Server完成了和 leader的状态同步以后，恢复模式就结束了。状态同步保证了leader和Server具有相同的系统状态。</p>
<p>为了保证事务的顺序一致性，zookeeper采用了递增的事务id号（zxid）来标识事务。所有的提议（proposal）都在被提出的时候加 上了zxid。实现中zxid是一个64位的数字，它高32位是epoch用来标识leader关系是否改变，每次一个leader被选出来，它都会有一 个新的epoch，标识当前属于那个leader的统治时期。低32位用于递增计数。</p>
<p>每个Server在工作过程中有三种状态：</p>
<ul>
<li>LOOKING：当前Server不知道leader是谁，正在搜寻</li>
<li>LEADING：当前Server即为选举出来的leader</li>
<li>FOLLOWING：leader已经选举出来，当前Server与之同步<br><strong>2.1 选主流程</strong></li>
</ul>
<p>当leader崩溃或者leader失去大多数的follower，这时候zk进入恢复模式，恢复模式需要重新选举出一个新的leader，让所有 的Server都恢复到一个正确的状态。Zk的选举算法有两种：一种是基于basic paxos实现的，另外一种是基于fast paxos算法实现的。系统默认的选举算法为fast paxos。先介绍basic paxos流程：</p>
<ol>
<li>1 .选举线程由当前Server发起选举的线程担任，其主要功能是对投票结果进行统计，并选出推荐的Server；</li>
<li>2 .选举线程首先向所有Server发起一次询问(包括自己)；</li>
<li>3 .选举线程收到回复后，验证是否是自己发起的询问(验证zxid是否一致)，然后获取对方的id(myid)，并存储到当前询问对象列表中，最后获取对方提议的leader相关信息(id,zxid)，并将这些信息存储到当次选举的投票记录表中；</li>
<li>收到所有Server回复以后，就计算出zxid最大的那个Server，并将这个Server相关信息设置成下一次要投票的Server；</li>
<li>线程将当前zxid最大的Server设置为当前Server要推荐的Leader，如果此时获胜的Server获得n/2 + 1的Server票数， 设置当前推荐的leader为获胜的Server，将根据获胜的Server相关信息设置自己的状态，否则，继续这个过程，直到leader被选举出来。<br>通过流程分析我们可以得出：要使Leader获得多数Server的支持，则Server总数必须是奇数2n+1，且存活的Server的数目不得少于n+1.</li>
</ol>
<p>每个Server启动后都会重复以上流程。在恢复模式下，如果是刚从崩溃状态恢复的或者刚启动的server还会从磁盘快照中恢复数据和会话信息，zk会记录事务日志并定期进行快照，方便在恢复时进行状态恢复。选主的具体流程图如下所示：</p>
<p><a href="http://suzf.net/wp-content/uploads/2016/03/zk3.png" target="_blank" rel="external"><img src="http://suzf.net/wp-content/uploads/2016/03/zk3.png" alt="zk3"></a></p>
<p>fast paxos流程是在选举过程中，某Server首先向所有Server提议自己要成为leader，当其它Server收到提议以后，解决epoch和 zxid的冲突，并接受对方的提议，然后向对方发送接受提议完成的消息，重复这个流程，最后一定能选举出Leader。其流程图如下所示：</p>
<p><a href="http://suzf.net/wp-content/uploads/2016/03/zk4.png" target="_blank" rel="external"><img src="http://suzf.net/wp-content/uploads/2016/03/zk4.png" alt="zk4"></a></p>
<p><strong>2.2 同步流程</strong></p>
<p>选完leader以后，zk就进入状态同步过程。</p>
<ol>
<li>leader等待server连接；</li>
<li>2 .Follower连接leader，将最大的zxid发送给leader；</li>
<li>3 .Leader根据follower的zxid确定同步点；</li>
<li>4 .完成同步后通知follower 已经成为uptodate状态；</li>
<li>5 .Follower收到uptodate消息后，又可以重新接受client的请求进行服务了。<br>流程图如下所示：</li>
</ol>
<p><a href="http://suzf.net/wp-content/uploads/2016/03/zk5.png" target="_blank" rel="external"><img src="http://suzf.net/wp-content/uploads/2016/03/zk5.png" alt="zk5"></a></p>
<p><strong>2.3 工作流程</strong></p>
<p><strong>2.3.1 Leader工作流程</strong></p>
<p>Leader主要有三个功能：</p>
<ol>
<li>1 .恢复数据；</li>
<li>2 .维持与Learner的心跳，接收Learner请求并判断Learner的请求消息类型；</li>
<li>3 .Learner的消息类型主要有PING消息、REQUEST消息、ACK消息、REVALIDATE消息，根据不同的消息类型，进行不同的处理。<br>PING消息是指Learner的心跳信息；REQUEST消息是Follower发送的提议信息，包括写请求及同步请求；ACK消息是 Follower的对提议的回复，超过半数的Follower通过，则commit该提议；REVALIDATE消息是用来延长SESSION有效时间。<br>Leader的工作流程简图如下所示，在实际实现中，流程要比下图复杂得多，启动了三个线程来实现功能。</li>
</ol>
<p><a href="http://suzf.net/wp-content/uploads/2016/03/zk6.png" target="_blank" rel="external"><img src="http://suzf.net/wp-content/uploads/2016/03/zk6.png" alt="zk6"></a></p>
<p><strong>2.3.2 Follower工作流程</strong></p>
<p>Follower主要有四个功能：</p>
<ol>
<li>向Leader发送请求（PING消息、REQUEST消息、ACK消息、REVALIDATE消息）；</li>
<li>2 .接收Leader消息并进行处理；</li>
<li>3 .接收Client的请求，如果为写请求，发送给Leader进行投票；</li>
<li><p>4 .返回Client结果。<br>Follower的消息循环处理如下几种来自Leader的消息：</p>
</li>
<li><p><strong>1 .PING</strong>消息： 心跳消息；</p>
</li>
<li><strong>2 .PROPOSAL</strong>消息：Leader发起的提案，要求Follower投票；</li>
<li><strong>3 .COMMIT</strong>消息：服务器端最新一次提案的信息；</li>
<li><strong>4 .UPTODATE</strong>消息：表明同步完成；</li>
<li><strong>5 .REVALIDATE</strong>消息：根据Leader的REVALIDATE结果，关闭待revalidate的session还是允许其接受消息；</li>
<li><strong>6 .SYNC</strong>消息：返回SYNC结果到客户端，这个消息最初由客户端发起，用来强制得到最新的更新。<br>Follower的工作流程简图如下所示，在实际实现中，Follower是通过5个线程来实现功能的。</li>
</ol>
<p><a href="http://suzf.net/wp-content/uploads/2016/03/zk7.png" target="_blank" rel="external"><img src="http://suzf.net/wp-content/uploads/2016/03/zk7.png" alt="zk7"></a></p>
<p>对于observer的流程不再叙述，observer流程和Follower的唯一不同的地方就是observer不会参加leader发起的投票。</p>
<p>出处 未知</p>
<p>~ ~ EOF ~~</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>ZooKeeper 是一个分布式的，开放源码的分布式应用程序协调服务，它包含一个简单的原语集，分布式应用程序可以基于它实现同步服务，配置维护和命名服务等。 Zookeeper是hadoop的一个子项目，其发展历程无需赘述。在分布式应用中，由于工程师不能很好地使用锁机制，以及基于消息的协调机制不适合在 某些应用中使用，因此需要有一种可靠的、可扩展的、分布式的、可配置的协调机制来统一系统的状态。Zookeeper的目的就在于此。本文简单分析 zookeeper的工作原理，对于如何使用zookeeper不是本文讨论的重点。]]>
    
    </summary>
    
      <category term="zookeeper" scheme="http://blog.suzf.net/tags/zookeeper/"/>
    
      <category term="Hadoop" scheme="http://blog.suzf.net/categories/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[高可用 开源的 Redis 缓存集群方案]]></title>
    <link href="http://blog.suzf.net/2016/03/21/%E9%AB%98%E5%8F%AF%E7%94%A8_%E5%BC%80%E6%BA%90%E7%9A%84_Redis_%E7%BC%93%E5%AD%98%E9%9B%86%E7%BE%A4%E6%96%B9%E6%A1%88/"/>
    <id>http://blog.suzf.net/2016/03/21/高可用_开源的_Redis_缓存集群方案/</id>
    <published>2016-03-21T09:47:35.000Z</published>
    <updated>2016-03-31T05:38:36.000Z</updated>
    <content type="html"><![CDATA[<div id="content"><br><br><span class="author_general">作者 <a href="http://www.infoq.com/cn/author/%E6%9D%8E%E5%A3%AB%E7%AA%91" target="_blank" rel="external"> 李士窑 </a></span><br><br>原文 <a href="http://www.infoq.com/cn/news/2014/11/open-source-redis-cache" target="_blank" rel="external">链接</a><br><br>由于单台<a href="http://redis.io/" target="_blank" rel="external">Redis</a>服务器的内存管理能力有限，使用过大内存的Redis又会使得 服务器的性能急剧下降，一旦服务器发生故障将会影响更大范围业务，而Redis 3.0 beta1支持的集群功能还不适合生产环境的使用。于是为了获取更好的Redis缓存性能及可用性，很多公司都研发了Redis缓存集群方案。现对<a href="https://www.netflix.com/" target="_blank" rel="external">NetFlix</a>、Twitter、国内的<a href="http://www.wandoujia.com/" target="_blank" rel="external">豌豆荚</a>在缓存集群方面的解决方案进行一个汇总，以供读者参考，具体内容如下：<a id="more"></a><br><br>## 1、NetFlix对Dynamo的开源通用实现Dynomite<br><br><a href="https://github.com/Netflix/dynomite" target="_blank" rel="external">Dynomite</a>是NetFlix对亚马逊分布式存储引擎Dynamo的一个开源通用实现，使用C/C++语言编写、以代理的方式实现的Redis缓存集群方案。Dynomite不仅能够将基于内存的Redis和Memcached打造成分布式数据库，还支持持久化的MySQL、<a href="http://www.oracle.com/technetwork/database/database-technologies/berkeleydb/overview/index.html" target="_blank" rel="external">BerkeleyDB</a>、<a href="http://code.google.com/p/leveldb/" target="_blank" rel="external">LevelDB</a>等数据库，并具有简单、高效、支持跨数据中心的数据复制等优点。Dynomite的最终目标是提供数据库存储引擎不能提供的简单、高效、跨数据中心的数据复制功能。Dynomite遵循<a href="http://www.apache.org/licenses/LICENSE-2.0.html" target="_blank" rel="external">Apache License 2.0开源协议</a>发布，更多关于Dynomite的信息请查看NetFlix技术博客对<a href="http://techblog.netflix.com/2014/11/introducing-dynomite.html" target="_blank" rel="external">Dynomite的介绍</a>。<br><br>## 2、Twitter的Redis/Memcached代理服务Twemproxy<br><br><a href="https://github.com/twitter/twemproxy" target="_blank" rel="external">Twemproxy</a>是一个使用C语言编 写、以代理的方式实现的、轻量级的Redis代理服务器，它通过引入一个代理层，将应用程序后端的多台Redis实例进行统一管理，使应用程序只需要在 Twemproxy上进行操作，而不用关心后面具体有多少个真实的Redis或Memcached实例，从而实现了基于Redis和Memcached的 集群服务。当某个节点宕掉时，Twemproxy可以自动将它从集群中剔除，而当它恢复服务时，Twemproxy也会自动连接。由于是代理，所以 Twemproxy会有微小的性能损失。根据 Redis作者的测试结果，在大多数情况下，Twemproxy的性能相当不错，同直接操作Redis相比，最多只有20%的性能损失。 Twemproxy遵循Apache License 2.0开源协议发布，更多关于Twemproxy的信息请登录其在GitHub的主页查看。<br><br>## 3、豌豆荚的 Redis 集群解决方案Codis<br><br><a href="https://github.com/wandoulabs/codis" target="_blank" rel="external">Codis</a>是豌豆荚使用Go和C语言开 发、以代理的方式实现的一个Redis分布式集群解决方案,且完全兼容Twemproxy。Twemproxy对于上一层的应用来说, 连接Codis Proxy（Redis代理服务）和连接原生的Redis服务器没有明显的区别,上一层应用能够像使用单机的 Redis一样对待。Codis底层会处理请求的转发、不停机的数据迁移等工作, 所有底层的一切处理, 对于客户端来说是透明的。总之，可以简单的认为后台连接的是一个内存无限大的Redis服务。Codis遵循<a href="http://zh.wikipedia.org/wiki/MIT%E8%A8%B1%E5%8F%AF%E8%AD%89" target="_blank" rel="external">MIT开源协议</a>发布，更多关于Codis的信息请登录其在GitHub的主页查看。<br><br>另外，还有一些未开源的解决方案，比如新浪、百度、淘宝、腾讯等的Redis集群方案。在Redis官方正式推出可用于生产环境的集群方案前，以上三种方案是非常值得考虑在生产环境使用的方案。<br><br></div>]]></content>
    <summary type="html">
    <![CDATA[<div id="content"><br><br><span class="author_general">作者 <a href="http://www.infoq.com/cn/author/%E6%9D%8E%E5%A3%AB%E7%AA%91"> 李士窑 </a></span><br><br>原文 <a href="http://www.infoq.com/cn/news/2014/11/open-source-redis-cache">链接</a><br><br>由于单台<a href="http://redis.io/">Redis</a>服务器的内存管理能力有限，使用过大内存的Redis又会使得 服务器的性能急剧下降，一旦服务器发生故障将会影响更大范围业务，而Redis 3.0 beta1支持的集群功能还不适合生产环境的使用。于是为了获取更好的Redis缓存性能及可用性，很多公司都研发了Redis缓存集群方案。现对<a href="https://www.netflix.com/">NetFlix</a>、Twitter、国内的<a href="http://www.wandoujia.com/">豌豆荚</a>在缓存集群方面的解决方案进行一个汇总，以供读者参考，具体内容如下：]]>
    
    </summary>
    
      <category term="redis" scheme="http://blog.suzf.net/tags/redis/"/>
    
      <category term="Redis" scheme="http://blog.suzf.net/categories/Redis/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Redis 常用命令总结]]></title>
    <link href="http://blog.suzf.net/2016/03/21/Redis_%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93/"/>
    <id>http://blog.suzf.net/2016/03/21/Redis_常用命令总结/</id>
    <published>2016-03-21T09:03:39.000Z</published>
    <updated>2016-03-31T05:38:36.000Z</updated>
    <content type="html"><![CDATA[<p>Redis 提供了丰富的命令（ command）对数据库和各种数据类型进行操作<br>下面对常用操作做出简单总结, 希望对大家有所帮助。<br>Redis commands – <a href="http://redis.io/commands" target="_blank" rel="external">http://redis.io/commands</a></p>
<p><strong><em> redis 默认端口 6379 </em></strong><br>redis-cli -p ${port}    # 指定端口<a id="more"></a></p>
<p><pre class="lang:default decode:true ">===== 键值 相关命令 =====<br>keys<br>返回满足给定 pattern 的所有 key</pre></p>
<ul>
<li>表示所有key<br>redis 127.0.0.1:1111&gt; keys *<br>1) “mylist8”<br>2) “key1”<br>3) “mylist2”<br>4) “mylist4”<br>5) “myhash”<br>6) “name”<br>7) “age”<br>8) “mylist6”<br>9) “name6”<br>10) “key2”<br>11) “mail”<br>12) “mylist3”<br>13) “mylist7”<br>14) “mylist”<br>15) “mylist5”</li>
</ul>
<p>表达式 name<em> 表示所有以 name 开头的key<br>redis 127.0.0.1:1111&gt; keys name</em><br>1) “name”<br>2) “name6”</p>
<p>exists<br>– 1 存在<br>– 0 不存在<br>redis 127.0.0.1:1111&gt; EXISTS suzf.net<br>(integer) 0<br>redis 127.0.0.1:1111&gt; EXISTS name<br>(integer) 1</p>
<p>del<br>删除一个key<br>– 1 删除成功<br>– 0 删除失败<br>redis 127.0.0.1:1111&gt; DEL name6<br>(integer) 1<br>redis 127.0.0.1:1111&gt; EXISTS name6<br>(integer) 0</p>
<p>expire</p>
<p>设置一个key 的 生存时间 &lt; 单位: s/秒 &gt;<br>redis 127.0.0.1:1111&gt; help EXPIRE</p>
<p>  EXPIRE key seconds<br>  summary: Set a key’s time to live in seconds<br>  since: 0.09<br>  group: generic</p>
<p>redis 127.0.0.1:1111&gt; set mykey “hello world”<br>OK<br>redis 127.0.0.1:1111&gt; EXPIRE mykey 10<br>(integer) 1<br>redis 127.0.0.1:1111&gt; TTL mykey<br>(integer) 4<br>redis 127.0.0.1:1111&gt; TTL mykey<br>(integer) 3<br>redis 127.0.0.1:1111&gt; TTL mykey<br>(integer) -2</p>
<p>move<br>将当前数据库中的 key 转移到其它数据库中<br>redis 127.0.0.1:1111&gt; SELECT 0<br>OK<br>redis 127.0.0.1:1111&gt; set name athena<br>OK<br>redis 127.0.0.1:1111&gt; get name<br>“athena”<br>redis 127.0.0.1:1111&gt; move name 1<br>(integer) 1<br>redis 127.0.0.1:1111&gt; get name<br>(nil)<br>redis 127.0.0.1:1111&gt; SELECT 1<br>OK<br>redis 127.0.0.1:1111[1]&gt; get name<br>“athena”<br>redis 127.0.0.1:1111[1]&gt;<br>在本例中,我先显式的选择了数据库 0,然后在这个库中设置一个 key,接下来我们将这个<br>key 从数据库 0 移到数据库 1,之后我们确认在数据库 0 中无此 key 了, 但在数据库 1 中存在<br>这个 key,说明我们转移成功了</p>
<p>persist<br>移除给定 key 的过期时间<br>redis 127.0.0.1:1111[1]&gt; EXPIRE name 666<br>(integer) 1<br>redis 127.0.0.1:1111[1]&gt; TTL name<br>(integer) 660<br>redis 127.0.0.1:1111[1]&gt; PERSIST name<br>(integer) 1<br>redis 127.0.0.1:1111[1]&gt; TTL name<br>(integer) -1</p>
<p>randomkey<br>随机返回 key 空间的一个 key<br>redis 127.0.0.1:1111&gt; RANDOMKEY<br>“myhash”<br>redis 127.0.0.1:1111&gt; RANDOMKEY<br>“mail”<br>redis 127.0.0.1:1111&gt; RANDOMKEY<br>“key2”<br>redis 127.0.0.1:1111&gt; RANDOMKEY<br>“mylist5”</p>
<p>rename<br>rename key<br>redis 127.0.0.1:1111&gt; SELECT 1<br>OK<br>redis 127.0.0.1:1111[1]&gt; keys <em><br>1) “name”<br>redis 127.0.0.1:1111[1]&gt; RENAME name name_new<br>OK<br>redis 127.0.0.1:1111[1]&gt; keys </em><br>1) “name_new”</p>
<p>type<br>返回值的类型<br>redis 127.0.0.1:1111&gt; TYPE mylist<br>list<br>redis 127.0.0.1:1111&gt; TYPE addr<br>none<br>redis 127.0.0.1:1111&gt; TYPE mail<br>string<br>redis 127.0.0.1:1111&gt; TYPE myhash<br>hash</p>
<p>===== 服务器相关命令 =====</p>
<p>Ping 测试连接 时候存活<br>– 正常<br>  redis 127.0.0.1:1111&gt; ping<br>  PONG</p>
<p>– 错误</p>
<p>  #redis-cli  -p 2222 ping<br>  Could not connect to Redis at 127.0.0.1:2222: Connection refused</p>
<p>Echo<br>在命令行中打印内容<br>redis 127.0.0.1:1111&gt; ECHO “Hello Kitty”<br>“Hello Kitty”</p>
<p>Select<br>选择数据库. Redis 数据库编号从 0~15,我们可以选择任意一个数据库来进行数据的存取.<br>redis 127.0.0.1:1111&gt; help select </p>
<p>  SELECT index<br>  summary: Change the selected database for the current connection<br>  since: 0.07<br>  group: connection<br>redis 127.0.0.1:1111&gt; SELECT 9<br>OK<br>redis 127.0.0.1:1111[9]&gt; SELECT 16<br>(error) ERR invalid DB index</p>
<p>Quit<br>退出连接<br>redis 127.0.0.1:1111[16]&gt; QUIT<br>^_^[16:15:32][root@master01 ~]#</p>
<p>Dbsize<br>返回当前数据库中 key 的条目</p>
<p>redis 127.0.0.1:1111&gt; DBSIZE<br>(integer) 12<br>redis 127.0.0.1:1111&gt; keys *<br> 1) “mylist8”<br> 2) “key1”<br> 3) “mylist2”<br> 4) “mylist4”<br> 5) “myhash”<br> 6) “mylist6”<br> 7) “key2”<br> 8) “mail”<br> 9) “mylist3”<br>10) “mylist7”<br>11) “mylist”<br>12) “mylist5”</p>
<p>当前数据库中有 12 个 key</p>
<p>Info<br>获取服务器信息和统计<br>redis 127.0.0.1:1111&gt; INFO</p>
<h1 id="Server"><a href="#Server" class="headerlink" title="Server"></a>Server</h1><p>redis_version:3.0.7<br>redis_git_sha1:00000000<br>…<br>…</p>
<h1 id="Cluster"><a href="#Cluster" class="headerlink" title="Cluster"></a>Cluster</h1><p>cluster_enabled:0</p>
<h1 id="Keyspace"><a href="#Keyspace" class="headerlink" title="Keyspace"></a>Keyspace</h1><p>db0:keys=12,expires=0,avg_ttl=0<br>db1:keys=1,expires=0,avg_ttl=0</p>
<p>Monitor<br>实时转储接到的请求<br>redis 127.0.0.1:1111&gt; MONITOR<br>OK<br>1458548482.249883 [0 192.168.9.70:44260] “PING”<br>1458548482.485299 [0 192.168.9.10:49031] “PING”<br>1458548483.309169 [0 192.168.9.70:44260] “PING”<br>1458548483.370627 [0 192.168.9.70:44260] “PUBLISH” “<strong>sentinel</strong>:hello” “192.168.9.70,6666,b5cd420208ca00f50c45b95587205235b6b2b675,9,master-1111,192.168.9.10,1111,9”<br>1458548483.559755 [0 192.168.9.10:49031] “PING”<br>1458548484.120162 [0 192.168.9.10:49031] “PUBLISH” “<strong>sentinel</strong>:hello” “192.168.9.10,6666,555e6555dc34bd819f8343005cd76af147ebec63,9,master-1111,192.168.9.10,1111,9”<br>1458548484.384204 [0 192.168.9.70:44260] “PING”<br>1458548484.567478 [0 192.168.9.10:49031] “PING”<br>1458548485.403481 [0 127.0.0.1:51102] “keys” “*”</p>
<p>从上面可以看出 服务器收到了 “keys *” “PUBLISH” 和 “PING” 请求</p>
<p>Conf get<br>获取当前服务器配置<br>redis 127.0.0.1:1111&gt; CONFIG GET dir<br>1) “dir”<br>2) “/var/lib/redis/1111”<br>redis 127.0.0.1:1111&gt; CONFIG GET timeout<br>1) “timeout”<br>2) “0”<br>redis 127.0.0.1:1111&gt; CONFIG GET slaveof<br>1) “slaveof”<br>2) “”<br>redis 127.0.0.1:1111&gt; CONFIG GET <em><br>执行” config get </em>”即可将全部的值都显示出来</p>
<p>Conf set<br>设置临时环境变量, 重启后失效<br>config set $variable $value<br>E.g.<br>redis 127.0.0.1:1111&gt; config set repl-timeout 300<br>OK</p>
<p>Flushdb<br>删除当前选择数据库中的所有 key<br>redis 127.0.0.1:1111&gt; DBSIZE<br>(integer) 12<br>redis 127.0.0.1:1111&gt; FLUSHDB<br>OK<br>redis 127.0.0.1:1111&gt; DBSIZE<br>(integer) 0</p>
<p>Flushall<br>删除所有数据库中的所有 key<br>redis 127.0.0.1:1111&gt; SELECT 1<br>OK<br>redis 127.0.0.1:1111[1]&gt; DBSIZE<br>(integer) 1<br>redis 127.0.0.1:1111[1]&gt; SELECT 0<br>OK<br>redis 127.0.0.1:1111&gt; FLUSHALL<br>OK<br>redis 127.0.0.1:1111&gt; SELECT 1<br>OK<br>redis 127.0.0.1:1111[1]&gt; DBSIZE<br>(integer) 0</p>
<p>client list<br>获取客户连接列表<br>redis 127.0.0.1:1111&gt; client list<br>id=100 addr=127.0.0.1:51251 fd=13 name= age=1315 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=32768 obl=0 oll=0 omem=0 events=r cmd=client<br>id=101 addr=127.0.0.1:51897 fd=14 name= age=33 idle=33 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=NULL</p>
<p>client kill<br>终止某个客户端连接<br>redis 127.0.0.1:1111&gt; client kill 127.0.0.1:51897<br>OK</p>
<p>save<br>立即保存数据到硬盘<br>redis 127.0.0.1:1111&gt; help Save</p>
<p>  SAVE -<br>  summary: Synchronously save the dataset to disk<br>  since: 0.07<br>  group: server</p>
<p>redis 127.0.0.1:1111&gt; save<br>OK</p>
<p>bgsave<br>异步保存数据到硬盘</p>
<p>lastsave<br>获取上次成功保存到硬盘的unix时间戳<br>redis 127.0.0.1:1111&gt; lastsave<br>(integer) 1458550236</p>
<p>slowlog len<br>查询慢查询日志条数<br>redis 127.0.0.1:1111&gt; slowlog len<br>(integer) 5</p>
<p>slowlog get<br>返回所有的慢查询日志,最大值取决于slowlog-max-len配置<br>redis 127.0.0.1:1111&gt; slowlog get<br>1) 1) (integer) 4<br>   2) (integer) 1458550236<br>   3) (integer) 10857<br>   4) 1) “save”<br>2) 1) (integer) 3<br>   2) (integer) 1458550230<br>   3) (integer) 10731<br>   4) 1) “save”<br>3) 1) (integer) 2<br>   2) (integer) 1458548969<br>   3) (integer) 10589<br>   4) 1) “FLUSHALL”<br>4) 1) (integer) 1<br>   2) (integer) 1458539756<br>   3) (integer) 26752<br>   4) 1) “hset”<br>      2) “myhash”<br>      3) “field1”<br>      4) “hello”<br>5) 1) (integer) 0<br>   2) (integer) 1458270728<br>   3) (integer) 21491<br>   4) 1) “SETNX”<br>      2) “858C783EA7F646021E63E5A6147B7B58”<br>      3) “null”</p>
<p>slowlog get 2<br>打印两条慢查询日志<br>redis 127.0.0.1:1111&gt; slowlog get 2<br>1) 1) (integer) 4<br>   2) (integer) 1458550236<br>   3) (integer) 10857<br>   4) 1) “save”<br>2) 1) (integer) 3<br>   2) (integer) 1458550230<br>   3) (integer) 10731<br>   4) 1) “save”</p>
<p>slowlog reset<br>清空慢查询日志信息<br>redis 127.0.0.1:1111&gt; slowlog reset<br>OK<br>redis 127.0.0.1:1111&gt; slowlog get<br>(empty list or set)<br>&nbsp;</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>Redis 提供了丰富的命令（ command）对数据库和各种数据类型进行操作<br>下面对常用操作做出简单总结, 希望对大家有所帮助。<br>Redis commands – <a href="http://redis.io/commands">http://redis.io/commands</a></p>
<p><strong><em> redis 默认端口 6379 </em></strong><br>redis-cli -p ${port}    # 指定端口]]>
    
    </summary>
    
      <category term="redis" scheme="http://blog.suzf.net/tags/redis/"/>
    
      <category term="Redis" scheme="http://blog.suzf.net/categories/Redis/"/>
    
  </entry>
  
</feed>

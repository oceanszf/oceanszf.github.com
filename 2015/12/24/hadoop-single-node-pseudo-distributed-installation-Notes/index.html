<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Hadoop 单节点_伪分布 安装手记 | Suzf Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="实验环境CentOS 6.XHadoop 2.6.0JDK    1.8.0_65
目的这篇文档的目的是帮助你快速完成单机上的Hadoop安装与使用以便你对Hadoop分布式文件系统(HDFS)和Map-Reduce框架有所体会，比如在HDFS上运行示例程序或简单作业等。
先决条件支持平台GNU/Linux是产品开发和运行的平台。 Hadoop已在有2000个节点的GNU/Linux主机组成的集群">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop 单节点_伪分布 安装手记">
<meta property="og:url" content="http://blog.suzf.net/2015/12/24/hadoop-single-node-pseudo-distributed-installation-Notes/index.html">
<meta property="og:site_name" content="Suzf Blog">
<meta property="og:description" content="实验环境CentOS 6.XHadoop 2.6.0JDK    1.8.0_65
目的这篇文档的目的是帮助你快速完成单机上的Hadoop安装与使用以便你对Hadoop分布式文件系统(HDFS)和Map-Reduce框架有所体会，比如在HDFS上运行示例程序或简单作业等。
先决条件支持平台GNU/Linux是产品开发和运行的平台。 Hadoop已在有2000个节点的GNU/Linux主机组成的集群">
<meta property="og:image" content="http://s1.51cto.com/wyfs02/M00/78/52/wKiom1Z6Q3vAlkXcAACeq3_WIqU567.png">
<meta property="og:updated_time" content="2016-01-13T06:45:32.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hadoop 单节点_伪分布 安装手记">
<meta name="twitter:description" content="实验环境CentOS 6.XHadoop 2.6.0JDK    1.8.0_65
目的这篇文档的目的是帮助你快速完成单机上的Hadoop安装与使用以便你对Hadoop分布式文件系统(HDFS)和Map-Reduce框架有所体会，比如在HDFS上运行示例程序或简单作业等。
先决条件支持平台GNU/Linux是产品开发和运行的平台。 Hadoop已在有2000个节点的GNU/Linux主机组成的集群">
  
    <link rel="alternative" href="/atom.xml" title="Suzf Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css" type="text/css">
  

</head>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Suzf Blog</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">Life is short, We need smile.</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://blog.suzf.net"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-hadoop-single-node-pseudo-distributed-installation-Notes" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/12/24/hadoop-single-node-pseudo-distributed-installation-Notes/" class="article-date">
  <time datetime="2015-12-24T02:40:45.000Z" itemprop="datePublished">2015-12-24</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Hadoop 单节点_伪分布 安装手记
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>实验环境<br>CentOS 6.X<br>Hadoop 2.6.0<br>JDK    1.8.0_65</p>
<p>目的<br>这篇文档的目的是帮助你快速完成单机上的Hadoop安装与使用以便你对Hadoop分布式文件系统(HDFS)和Map-Reduce框架有所体会，比如在HDFS上运行示例程序或简单作业等。</p>
<p>先决条件<br>支持平台<br>GNU/Linux是产品开发和运行的平台。 Hadoop已在有2000个节点的GNU/Linux主机组成的集群系统上得到验证。<br>Win32平台是作为开发平台支持的。由于分布式操作尚未在Win32平台上充分测试，所以还不作为一个生产平台被支持。</p>
<p>安装软件<br>如果你的集群尚未安装所需软件，你得首先安装它们。<br>以 CentOS 为例:</p>
<h1 id="yum_install_ssh_rsync_-y"><a href="#yum_install_ssh_rsync_-y" class="headerlink" title="yum install ssh rsync -y"></a>yum install ssh rsync -y</h1><h1 id="ssh__u5FC5_u987B_u5B89_u88C5_u5E76_u4E14_u4FDD_u8BC1_sshd_u4E00_u76F4_u8FD0_u884C_uFF0C_u4EE5_u4FBF_u7528Hadoop__u811A_u672C_u7BA1_u7406_u8FDC_u7AEFHadoop_u5B88_u62A4_u8FDB_u7A0B_u3002"><a href="#ssh__u5FC5_u987B_u5B89_u88C5_u5E76_u4E14_u4FDD_u8BC1_sshd_u4E00_u76F4_u8FD0_u884C_uFF0C_u4EE5_u4FBF_u7528Hadoop__u811A_u672C_u7BA1_u7406_u8FDC_u7AEFHadoop_u5B88_u62A4_u8FDB_u7A0B_u3002" class="headerlink" title="ssh 必须安装并且保证 sshd一直运行，以便用Hadoop 脚本管理远端Hadoop守护进程。"></a>ssh 必须安装并且保证 sshd一直运行，以便用Hadoop 脚本管理远端Hadoop守护进程。</h1><p>创建用户</p>
<h1 id="useradd_-m_hadoop_-s_/bin/bash__23__u521B_u5EFA_u65B0_u7528_u6237hadoop"><a href="#useradd_-m_hadoop_-s_/bin/bash__23__u521B_u5EFA_u65B0_u7528_u6237hadoop" class="headerlink" title="useradd -m hadoop -s /bin/bash   # 创建新用户hadoop"></a>useradd -m hadoop -s /bin/bash   # 创建新用户hadoop</h1><p>Hosts解析</p>
<h1 id="cat_/etc/hosts_7C_grep_ocean-lab"><a href="#cat_/etc/hosts_7C_grep_ocean-lab" class="headerlink" title="cat /etc/hosts| grep ocean-lab"></a>cat /etc/hosts| grep ocean-lab</h1><p>192.168.9.70     ocean-lab.ocean.org  ocean-lab</p>
<p>安装jdk<br>JDK – <a href="http://www.oracle.com/technetwork/java/javase/downloads/index.html" target="_blank" rel="external">http://www.oracle.com/technetwork/java/javase/downloads/index.html</a><br>首先安装JAVA环境</p>
<h1 id="wget__u2013no-cookies__u2013no-check-certificate__u2013header__u201CCookie_3A_gpw_e24_3Dhttp_253A_252F_252Fwww-oracle-com_252F_3B_oraclelicense_3Daccept-securebackup-cookie_u201D__u201Chttp_3A//download-oracle-com/otn-pub/java/jdk/8u65-b17/jdk-8u65-linux-x64-rpm_u201C"><a href="#wget__u2013no-cookies__u2013no-check-certificate__u2013header__u201CCookie_3A_gpw_e24_3Dhttp_253A_252F_252Fwww-oracle-com_252F_3B_oraclelicense_3Daccept-securebackup-cookie_u201D__u201Chttp_3A//download-oracle-com/otn-pub/java/jdk/8u65-b17/jdk-8u65-linux-x64-rpm_u201C" class="headerlink" title="wget –no-cookies –no-check-certificate –header “Cookie: gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie” “http://download.oracle.com/otn-pub/java/jdk/8u65-b17/jdk-8u65-linux-x64.rpm“"></a>wget –no-cookies –no-check-certificate –header “Cookie: gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie” “<a href="http://download.oracle.com/otn-pub/java/jdk/8u65-b17/jdk-8u65-linux-x64.rpm" target="_blank" rel="external">http://download.oracle.com/otn-pub/java/jdk/8u65-b17/jdk-8u65-linux-x64.rpm</a>“</h1><h1 id="rpm_-Uvh_jdk-8u65-linux-x64-rpm"><a href="#rpm_-Uvh_jdk-8u65-linux-x64-rpm" class="headerlink" title="rpm -Uvh jdk-8u65-linux-x64.rpm"></a>rpm -Uvh jdk-8u65-linux-x64.rpm</h1><p>配置 Java</p>
<h1 id="echo__u201Cexport_JAVA_HOME_3D/usr/java/jdk1-8-0_65_u201D__26gt_3B_26gt_3B_/home/hadoop/-bashrc"><a href="#echo__u201Cexport_JAVA_HOME_3D/usr/java/jdk1-8-0_65_u201D__26gt_3B_26gt_3B_/home/hadoop/-bashrc" class="headerlink" title="echo “export JAVA_HOME=/usr/java/jdk1.8.0_65” &gt;&gt; /home/hadoop/.bashrc"></a>echo “export JAVA_HOME=/usr/java/jdk1.8.0_65” &gt;&gt; /home/hadoop/.bashrc</h1><h1 id="source_/home/hadoop/-bashrc"><a href="#source_/home/hadoop/-bashrc" class="headerlink" title="source /home/hadoop/.bashrc"></a>source /home/hadoop/.bashrc</h1><h1 id="echo__24JAVA_HOME"><a href="#echo__24JAVA_HOME" class="headerlink" title="echo $JAVA_HOME"></a>echo $JAVA_HOME</h1><p>/usr/java/jdk1.8.0_65</p>
<p>下载安装hadoop<br>为了获取Hadoop的发行版，从Apache的某个镜像服务器上下载最近的 稳定发行版。<br>运行Hadoop集群的准备工作</p>
<h1 id="wget_http_3A//apache-fayea-com/hadoop/common/hadoop-2-6-0/hadoop-2-6-0-tar-gz"><a href="#wget_http_3A//apache-fayea-com/hadoop/common/hadoop-2-6-0/hadoop-2-6-0-tar-gz" class="headerlink" title="wget http://apache.fayea.com/hadoop/common/hadoop-2.6.0/hadoop-2.6.0.tar.gz"></a>wget <a href="http://apache.fayea.com/hadoop/common/hadoop-2.6.0/hadoop-2.6.0.tar.gz" target="_blank" rel="external">http://apache.fayea.com/hadoop/common/hadoop-2.6.0/hadoop-2.6.0.tar.gz</a></h1><p>解压所下载的Hadoop发行版。编辑 conf/hadoop-env.sh文件，至少需要将JAVA_HOME设置为Java安装根路径。</p>
<h1 id="tar_xf_hadoop-2-6-0-tar-gz_-C_/usr/local"><a href="#tar_xf_hadoop-2-6-0-tar-gz_-C_/usr/local" class="headerlink" title="tar xf hadoop-2.6.0.tar.gz -C /usr/local"></a>tar xf hadoop-2.6.0.tar.gz -C /usr/local</h1><h4 id="mv_/usr/local/hadoop-2-6-0_/usr/local/hadoop"><a href="#mv_/usr/local/hadoop-2-6-0_/usr/local/hadoop" class="headerlink" title="mv /usr/local/hadoop-2.6.0 /usr/local/hadoop"></a>mv /usr/local/hadoop-2.6.0 /usr/local/hadoop</h4><p>尝试如下命令：</p>
<h1 id="bin/hadoop"><a href="#bin/hadoop" class="headerlink" title="bin/hadoop"></a>bin/hadoop</h1><p>将会显示hadoop 脚本的使用文档。</p>
<p>现在你可以用以下<strong>三种支持的模式</strong>中的一种启动Hadoop集群：<br>单机模式<br>伪分布式模式<br>完全分布式模式</p>
<p><strong>单机模式的操作方法</strong></p>
<p>默认情况下，Hadoop被配置成以非分布式模式运行的一个独立Java进程。这对调试非常有帮助。<br>现在我们可以执行例子来感受下 Hadoop 的运行。Hadoop 附带了丰富的例子包括 wordcount、terasort、join、grep 等。<br>在此我们选择运行 grep 例子，我们将 input 文件夹中的所有文件作为输入，筛选当中符合正则表达式 dfs[a-z.]+ 的单词并统计出现的次数，最后输出结果到 output 文件夹中。</p>
<h1 id="mkdir_input"><a href="#mkdir_input" class="headerlink" title="mkdir input"></a>mkdir input</h1><h1 id="cp_conf/*-xml_input"><a href="#cp_conf/*-xml_input" class="headerlink" title="cp conf/*.xml input"></a>cp conf/*.xml input</h1><h1 id="/bin/hadoop_jar_-/share/hadoop/mapreduce/hadoop-mapreduce-examples-2-6-0-jar_grep_-/input/_-/ouput__u2018dfs_5Ba-z-_5D+_u2019"><a href="#/bin/hadoop_jar_-/share/hadoop/mapreduce/hadoop-mapreduce-examples-2-6-0-jar_grep_-/input/_-/ouput__u2018dfs_5Ba-z-_5D+_u2019" class="headerlink" title="./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar grep ./input/ ./ouput ‘dfs[a-z.]+’"></a>./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar grep ./input/ ./ouput ‘dfs[a-z.]+’</h1><h1 id="cat_output/*"><a href="#cat_output/*" class="headerlink" title="cat output/*"></a>cat output/*</h1><p>若执行成功的话会输出很多作业的相关信息，最后的输出信息如下图所示。作业的结果会输出在指定的 output 文件夹中，通过命令 cat ./output/<em> 查看结果，符合正则的单词 dfsadmin 出现了1次：<br>[10:57:58][hadoop@ocean-lab hadoop-2.6.0]$ cat ./ouput/</em><br>1 dfsadmin</p>
<p>注意，Hadoop 默认不会覆盖结果文件，因此再次运行上面实例会提示出错，需要先将 ./output 删除。<br>否则会报如下错误<br>INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized<br>org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/usr/local/hadoop-2.6.0/ouput already exists<br>若出现提示 “INFO metrics.MetricsUtil: Unable to obtain hostName java.net.UnknowHostException”，这需要执行如下命令修改 hosts 文件，为你的主机名增加IP映射：</p>
<h1 id="cat_/etc/hosts_7C_grep_ocean-lab-1"><a href="#cat_/etc/hosts_7C_grep_ocean-lab-1" class="headerlink" title="cat /etc/hosts| grep ocean-lab"></a>cat /etc/hosts| grep ocean-lab</h1><p>192.168.9.70     ocean-lab.ocean.org  ocean-lab</p>
<p><strong>伪分布式模式的操作方法</strong></p>
<p>Hadoop可以在单节点上以所谓的伪分布式模式运行，此时每一个Hadoop守护进程都作为一个独立的Java进程运行。<br>节点既作为 NameNode 也作为 DataNode，同时，读取的是 HDFS 中的文件。</p>
<p>在设置 Hadoop 伪分布式配置前，我们还需要设置 HADOOP 环境变量，执行如下命令在 ~/.bashrc 中设置</p>
<h1 id="Hadoop_Environment_Variables"><a href="#Hadoop_Environment_Variables" class="headerlink" title="Hadoop Environment Variables"></a>Hadoop Environment Variables</h1><p>export HADOOP_HOME=/usr/local/hadoop-2.6.0<br>export HADOOP_INSTALL=$HADOOP_HOME<br>export HADOOP_MAPRED_HOME=$HADOOP_HOME<br>export HADOOP_COMMON_HOME=$HADOOP_HOME<br>export HADOOP_HDFS_HOME=$HADOOP_HOME<br>export YARN_HOME=$HADOOP_HOME<br>export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native<br>export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin</p>
<p>source ~/.bashrc</p>
<p>配置</p>
<p>使用如下的 etc/hadoop/core-site.xml</p>
<p>&lt;configuration&gt;<br>&lt;property&gt;<br>&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;<br>&lt;value&gt;file:/usr/local/hadoop-2.6.0/tmp&lt;/value&gt;<br>&lt;description&gt;Abase for other temporary directories.&lt;/description&gt;<br>&lt;/property&gt;<br>&lt;property&gt;<br>&lt;name&gt;fs.defaultFS&lt;/name&gt;<br>&lt;value&gt;hdfs://localhost:9000&lt;/value&gt;<br>&lt;/property&gt;<br>&lt;/configuration&gt;</p>
<p>同样的，修改配置文件 <strong>hdfs-site.xml</strong></p>
<p>&lt;configuration&gt;<br>&lt;property&gt;<br>&lt;name&gt;dfs.replication&lt;/name&gt;<br>&lt;value&gt;1&lt;/value&gt;<br>&lt;/property&gt;<br>&lt;property&gt;<br>&lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;<br>&lt;value&gt;file:/usr/local/hadoop-2.6.0/tmp/dfs/name&lt;/value&gt;<br>&lt;/property&gt;<br>&lt;property&gt;<br>&lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;<br>&lt;value&gt;file:/usr/local/hadoop-2.6.0/tmp/dfs/data&lt;/value&gt;<br>&lt;/property&gt;<br>&lt;/configuration&gt;</p>
<p>&nbsp;</p>
<p><strong>关于Hadoop配置项的一点说明</strong></p>
<p>虽 然只需要配置 fs.defaultFS 和 dfs.replication 就可以运行（官方教程如此），不过若没有配置 hadoop.tmp.dir 参数，则默认使用的临时目录为 /tmp/hadoo-hadoop，而这个目录在重启时有可能被系统清理掉，导致必须重新执行 format 才行。所以我们进行了设置，同时也指定 dfs.namenode.name.dir 和 dfs.datanode.data.dir，否则在接下来的步骤中可能会出错。</p>
<p>&nbsp;</p>
<p>免密码ssh设置<br>现在确认能否不输入口令就用ssh登录localhost:</p>
<h1 id="ssh_localhost_date"><a href="#ssh_localhost_date" class="headerlink" title="ssh localhost date"></a>ssh localhost date</h1><p>如果不输入口令就无法用ssh登陆localhost，执行下面的命令：</p>
<h1 id="ssh-keygen_-t_dsa_-P__u2018_u2019_-f__7E/-ssh/id_dsa"><a href="#ssh-keygen_-t_dsa_-P__u2018_u2019_-f__7E/-ssh/id_dsa" class="headerlink" title="ssh-keygen -t dsa -P ‘’ -f ~/.ssh/id_dsa"></a>ssh-keygen -t dsa -P ‘’ -f ~/.ssh/id_dsa</h1><h1 id="cat__7E/-ssh/id_dsa-pub__26gt_3B_26gt_3B__7E/-ssh/authorized_keys"><a href="#cat__7E/-ssh/id_dsa-pub__26gt_3B_26gt_3B__7E/-ssh/authorized_keys" class="headerlink" title="cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys"></a>cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys</h1><p>#chmod  600 ~/.ssh/authorized_keys</p>
<p>格式化一个新的分布式文件系统：<br>$ bin/hadoop namenode -format<br>15/12/23 11:30:20 INFO util.GSet: VM type       = 64-bit<br>15/12/23 11:30:20 INFO util.GSet: 0.029999999329447746% max memory 966.7 MB = 297.0 KB<br>15/12/23 11:30:20 INFO util.GSet: capacity      = 2^15 = 32768 entries<br>15/12/23 11:30:20 INFO namenode.NNConf: ACLs enabled? false<br>15/12/23 11:30:20 INFO namenode.NNConf: XAttrs enabled? true<br>15/12/23 11:30:20 INFO namenode.NNConf: Maximum size of an xattr: 16384<br>15/12/23 11:30:20 INFO namenode.FSImage: Allocated new BlockPoolId: BP-823870322-192.168.9.70-1450841420347<br>15/12/23 11:30:20 INFO common.Storage: Storage directory /usr/local/hadoop-2.6.0/tmp/dfs/name has been successfully formatted.<br>15/12/23 11:30:20 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid &gt;= 0<br>15/12/23 11:30:20 INFO util.ExitUtil: <strong>Exiting with status 0</strong><br>15/12/23 11:30:20 INFO namenode.NameNode: SHUTDOWN_MSG:<br>/<strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><em>**</em></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong><br>SHUTDOWN_MSG: Shutting down NameNode at ocean-lab.ocean.org/192.168.9.70<br><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><em>**</em></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong>/<br><strong>成功的话，会看到 “successfully formatted” 和 “Exitting with status 0″ 的提示</strong></p>
<p><strong>注意</strong><br>下次启动 hadoop 时，无需进行 NameNode 的初始化，只需要运行 ./sbin/start-dfs.sh 就可以！</p>
<p>启动 NameNode 和  DataNode</p>
<p>$  ./sbin/start-dfs.sh<br>15/12/23 11:37:20 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform… using builtin-java classes where applicable<br>Starting namenodes on [localhost]<br>localhost: starting namenode, logging to /usr/local/hadoop-2.6.0/logs/hadoop-hadoop-namenode-ocean-lab.ocean.org.out<br>localhost: starting datanode, logging to /usr/local/hadoop-2.6.0/logs/hadoop-hadoop-datanode-ocean-lab.ocean.org.out<br>Starting secondary namenodes [0.0.0.0]<br>The authenticity of host ‘0.0.0.0 (0.0.0.0)’ can’t be established.<br>RSA key fingerprint is a5:26:42:a0:5f:da:a2:88:52:04:9c:7f:8d:6a:98:9b.<br>Are you sure you want to continue connecting (yes/no)?<strong> yes</strong><br>0.0.0.0: Warning: Permanently added ‘0.0.0.0’ (RSA) to the list of known hosts.<br>0.0.0.0: starting secondarynamenode, logging to /usr/local/hadoop-2.6.0/logs/hadoop-hadoop-secondarynamenode-ocean-lab.ocean.org.out<br>15/12/23 11:37:44 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform… using builtin-java classes where applicable</p>
<p>[13:57:08][hadoop@ocean-lab hadoop-2.6.0]$ jps<br>27686 <strong>SecondaryNameNode</strong><br>28455 Jps<br>27501<strong> DataNode</strong><br>27405 <strong>NameNode</strong><br>27006 GetConf</p>
<p>如果没有进程则说明启动失败 查看日志bebug</p>
<p>成功启动后，可以访问 Web 界面  <a href="http://oceanszf.blog.51cto.com/50070" target="_blank" rel="external">http://[ip,fqdn]:/50070</a>  查看 NameNode 和 Datanode 信息，还可以在线查看 HDFS 中的文件。</p>
<p><a href="http://s1.51cto.com/wyfs02/M00/78/52/wKiom1Z6Q3vAlkXcAACeq3_WIqU567.png" target="_blank" rel="external"><img src="http://s1.51cto.com/wyfs02/M00/78/52/wKiom1Z6Q3vAlkXcAACeq3_WIqU567.png" alt="wKiom1Z6Q3vAlkXcAACeq3_WIqU567.png" title="hadoop1.PNG"></a></p>
<h2 id="u8FD0_u884CHadoop_u4F2A_u5206_u5E03_u5F0F_u5B9E_u4F8B"><a href="#u8FD0_u884CHadoop_u4F2A_u5206_u5E03_u5F0F_u5B9E_u4F8B" class="headerlink" title="运行Hadoop伪分布式实例"></a>运行Hadoop伪分布式实例</h2><p>上面的单机模式，grep 例子读取的是本地数据，伪分布式读取的则是 HDFS 上的数据。</p>
<p>要使用 HDFS，首先需要在 HDFS 中创建用户目录：</p>
<h1 id="/bin/hdfs_dfs_-mkdir_-p_/user/hadoop"><a href="#/bin/hdfs_dfs_-mkdir_-p_/user/hadoop" class="headerlink" title="./bin/hdfs dfs -mkdir -p /user/hadoop"></a>./bin/hdfs dfs -mkdir -p /user/hadoop</h1><h1 id="/bin/hadoop_fs_-ls_/user/hadoop"><a href="#/bin/hadoop_fs_-ls_/user/hadoop" class="headerlink" title="./bin/hadoop fs -ls /user/hadoop"></a>./bin/hadoop fs -ls /user/hadoop</h1><p>Found 1 items<br>drwxr-xr-x   - hadoop supergroup          0 2015-12-23 15:03 /user/hadoop/input</p>
<p>接 着将 ./etc/hadoop 中的 xml 文件作为输入文件复制到分布式文件系统中，即将 /usr/local/hadoop/etc/hadoop 复制到分布式文件系统中的 /user/hadoop/input 中。我们使用的是 hadoop 用户，并且已创建相应的用户目录 /user/hadoop ，因此在命令中就可以使用相对路径如 input，其对应的绝对路径就是 /user/hadoop/input:</p>
<h1 id="/bin/hdfs_dfs_-mkdir_input"><a href="#/bin/hdfs_dfs_-mkdir_input" class="headerlink" title="./bin/hdfs dfs -mkdir input"></a>./bin/hdfs dfs -mkdir input</h1><h1 id="/bin/hdfs_dfs_-put_-/etc/hadoop/*-xml_input"><a href="#/bin/hdfs_dfs_-put_-/etc/hadoop/*-xml_input" class="headerlink" title="./bin/hdfs dfs -put ./etc/hadoop/*.xml input"></a>./bin/hdfs dfs -put ./etc/hadoop/*.xml input</h1><p>复制完成后，可以通过如下命令查看 HDFS 中的文件列表：</p>
<h1 id="/bin/hdfs_dfs_-ls_input"><a href="#/bin/hdfs_dfs_-ls_input" class="headerlink" title="./bin/hdfs dfs -ls input"></a>./bin/hdfs dfs -ls input</h1><p>-rw-r–r–   1 hadoop supergroup       4436 2015-12-23 16:46 input/capacity-scheduler.xml<br>-rw-r–r–   1 hadoop supergroup       1180 2015-12-23 16:46 input/core-site.xml<br>-rw-r–r–   1 hadoop supergroup       9683 2015-12-23 16:46 input/hadoop-policy.xml<br>-rw-r–r–   1 hadoop supergroup       1136 2015-12-23 16:46 input/hdfs-site.xml<br>-rw-r–r–   1 hadoop supergroup        620 2015-12-23 16:46 input/httpfs-site.xml<br>-rw-r–r–   1 hadoop supergroup       3523 2015-12-23 16:46 input/kms-acls.xml<br>-rw-r–r–   1 hadoop supergroup       5511 2015-12-23 16:46 input/kms-site.xml<br>-rw-r–r–   1 hadoop supergroup        858 2015-12-23 16:46 input/mapred-site.xml<br>-rw-r–r–   1 hadoop supergroup        690 2015-12-23 16:46 input/yarn-site.xml</p>
<p>伪分布式运行 MapReduce 作业的方式跟单机模式相同，区别在于伪分布式读取的是HDFS中的文件（可以将单机步骤中创建的本地 input 文件夹，输出结果 output 文件夹都删掉来验证这一点）。</p>
<h1 id="/bin/hadoop_jar_-/share/hadoop/mapreduce/hadoop-mapreduce-examples-2-6-0-jar_grep_input_output__u2018dfs_5Ba-z-_5D+_u2019"><a href="#/bin/hadoop_jar_-/share/hadoop/mapreduce/hadoop-mapreduce-examples-2-6-0-jar_grep_input_output__u2018dfs_5Ba-z-_5D+_u2019" class="headerlink" title="./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar grep input output ‘dfs[a-z.]+’"></a>./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar grep input output ‘dfs[a-z.]+’</h1><p>查看运行结果的命令（查看的是位于 HDFS 中的输出结果）：<br>$ ./bin/hdfs dfs -cat output/*<br>1   dfsadmin<br>1   dfs.replication<br>1   dfs.namenode.name.dir<br>1   dfs.datanode.data.dir</p>
<p>结果如下，注意到刚才我们已经更改了配置文件，所以运行结果不同。<br>Hadoop伪分布式运行grep的结果Hadoop伪分布式运行grep的结果<br>我们也可以将运行结果取回到本地：</p>
<h1 id="rm_-r_-/output__23__u5148_u5220_u9664_u672C_u5730_u7684_output__u6587_u4EF6_u5939_uFF08_u5982_u679C_u5B58_u5728_uFF09"><a href="#rm_-r_-/output__23__u5148_u5220_u9664_u672C_u5730_u7684_output__u6587_u4EF6_u5939_uFF08_u5982_u679C_u5B58_u5728_uFF09" class="headerlink" title="rm -r ./output    # 先删除本地的 output 文件夹（如果存在）"></a>rm -r ./output    # 先删除本地的 output 文件夹（如果存在）</h1><h1 id="/bin/hdfs_dfs_-get_output_-/output__23__u5C06_HDFS__u4E0A_u7684_output__u6587_u4EF6_u5939_u62F7_u8D1D_u5230_u672C_u673A"><a href="#/bin/hdfs_dfs_-get_output_-/output__23__u5C06_HDFS__u4E0A_u7684_output__u6587_u4EF6_u5939_u62F7_u8D1D_u5230_u672C_u673A" class="headerlink" title="./bin/hdfs dfs -get output ./output     # 将 HDFS 上的 output 文件夹拷贝到本机"></a>./bin/hdfs dfs -get output ./output     # 将 HDFS 上的 output 文件夹拷贝到本机</h1><h1 id="cat_-/output/*"><a href="#cat_-/output/*" class="headerlink" title="cat ./output/*"></a>cat ./output/*</h1><p>1   dfsadmin<br>1   dfs.replication<br>1   dfs.namenode.name.dir<br>1   dfs.datanode.data.dir</p>
<p>Hadoop 运行程序时，输出目录不能存在，否则会提示错误 “org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs://localhost:9000/user/hadoop/output already exists” ，因此若要再次执行，需要执行如下命令删除 output 文件夹:</p>
<h1 id="u5220_u9664_output__u6587_u4EF6_u5939"><a href="#u5220_u9664_output__u6587_u4EF6_u5939" class="headerlink" title="删除 output 文件夹"></a>删除 output 文件夹</h1><p>$./bin/hdfs dfs -rm -r output<br>Deleted output</p>
<p>运行程序时，输出目录不能存在<br>运行 Hadoop 程序时，为了防止覆盖结果，程序指定的输出目录（如 output）不能存在，否则会提示错误，因此运行前需要先删除输出目录。在实际开发应用程序时，可考虑在程序中加上如下代码，能在每次运行时自动删除输出目录，避免繁琐的命令行操作：<br>Configuration conf = new Configuration();<br>Job job = new Job(conf);<br>/<em> 删除输出目录 </em>/<br>Path outputPath = new Path(args[1]);<br>outputPath.getFileSystem(conf).delete(outputPath, true);</p>
<p>若要关闭 Hadoop，则运行<br>./sbin/stop-dfs.sh</p>
<p>启动YARN<br>(伪分布式不启动 YARN 也可以，一般不会影响程序执行)<br>有 的读者可能会疑惑，怎么启动 Hadoop 后，见不到书上所说的 JobTracker 和 TaskTracker，这是因为新版的 Hadoop 使用了新的 MapReduce 框架（MapReduce V2，也称为 YARN，Yet Another Resource Negotiator）。</p>
<p>YARN 是从 MapReduce 中分离出来的，负责资源管理与任务调度。YARN 运行于 MapReduce 之上，提供了高可用性、高扩展性，YARN 的更多介绍在此不展开，有兴趣的可查阅相关资料。</p>
<p>上述通过 ./sbin/start-dfs.sh 启动 Hadoop，仅仅是启动了 MapReduce 环境，我们可以启动 YARN ，让 YARN 来负责资源管理与任务调度。</p>
<p>首先修改配置文件 mapred-site.xml<br>&lt;configuration&gt;<br>&lt;property&gt;<br>&lt;name&gt;mapreduce.framework.name&lt;/name&gt;<br>&lt;value&gt;yarn&lt;/value&gt;<br>&lt;/property&gt;<br>&lt;/configuration&gt;</p>
<p>接着修改配置文件 yarn-site.xml：<br>&lt;configuration&gt;<br>&lt;property&gt;<br>&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;<br>&lt;value&gt;mapreduce_shuffle&lt;/value&gt;<br>&lt;/property&gt;<br>&lt;/configuration&gt;</p>
<p>然后就可以启动 YARN 了（需要先执行过 ./sbin/start-dfs.sh）：</p>
<h1 id="/sbin/start-yarn-sh__23__u542F_u52A8YARN"><a href="#/sbin/start-yarn-sh__23__u542F_u52A8YARN" class="headerlink" title="./sbin/start-yarn.sh                                # 启动YARN"></a>./sbin/start-yarn.sh                                # 启动YARN</h1><h1 id="/sbin/mr-jobhistory-daemon-sh_start_historyserver__23__u5F00_u542F_u5386_u53F2_u670D_u52A1_u5668_uFF0C_u624D_u80FD_u5728Web_u4E2D_u67E5_u770B_u4EFB_u52A1_u8FD0_u884C_u60C5_u51B5"><a href="#/sbin/mr-jobhistory-daemon-sh_start_historyserver__23__u5F00_u542F_u5386_u53F2_u670D_u52A1_u5668_uFF0C_u624D_u80FD_u5728Web_u4E2D_u67E5_u770B_u4EFB_u52A1_u8FD0_u884C_u60C5_u51B5" class="headerlink" title="./sbin/mr-jobhistory-daemon.sh start historyserver  # 开启历史服务器，才能在Web中查看任务运行情况"></a>./sbin/mr-jobhistory-daemon.sh start historyserver  # 开启历史服务器，才能在Web中查看任务运行情况</h1><p>开启后通过 jps 查看，可以看到多了 NodeManager 和 ResourceManager 两个后台进程:</p>
<p>[09:18:34][hadoop@ocean-lab ~]$ jps<br>27686 SecondaryNameNode<br>6968 ResourceManager<br>7305 Jps<br>7066 NodeManager<br>27501 DataNode<br>27405 NameNode</p>
<p>启 动 YARN 之后，运行实例的方法还是一样的，仅仅是资源管理方式、任务调度不同。观察日志信息可以发现，不启用 YARN 时，是 “mapred.LocalJobRunner” 在跑任务，启用 YARN 之后，是 “mapred.YARNRunner” 在跑任务。启动 YARN 有个好处是可以通过 Web 界面查看任务的运行情况：<a href="http://[ip,fqdn]:8088/cluster" target="_blank" rel="external">http://[ip,fqdn]:8088/cluster</a></p>
<p>开启YARN后可以查看任务运行信息开启YARN后可以查看任务运行信息<br>但 YARN 主要是为集群提供更好的资源管理与任务调度，然而这在单机上体现不出价值，反而会使程序跑得稍慢些。因此在单机上是否开启 YARN 就看实际情况了。<br>不启动 YARN 需删掉/重命名 mapred-site.xml<br>否则在该配置文件存在，而未开启 YARN 的情况下，运行程序会提示 “Retrying connect to server: 0.0.0.0/0.0.0.0:8032″ 的错误。</p>
<p>同样的，关闭 YARN 的脚本如下：</p>
<h1 id="/sbin/stop-yarn-sh"><a href="#/sbin/stop-yarn-sh" class="headerlink" title="./sbin/stop-yarn.sh"></a>./sbin/stop-yarn.sh</h1><h1 id="/sbin/mr-jobhistory-daemon-sh_stop_historyserver"><a href="#/sbin/mr-jobhistory-daemon-sh_stop_historyserver" class="headerlink" title="./sbin/mr-jobhistory-daemon.sh stop historyserver"></a>./sbin/mr-jobhistory-daemon.sh stop historyserver</h1><p><strong>hadoop 常用命令</strong></p>
<h1 id="u67E5_u770BHDFS_u6587_u4EF6_u5217_u8868"><a href="#u67E5_u770BHDFS_u6587_u4EF6_u5217_u8868" class="headerlink" title="查看HDFS文件列表"></a>查看HDFS文件列表</h1><p>hadoop fs -ls /usr/local/log/</p>
<h1 id="u521B_u5EFA_u6587_u4EF6_u76EE_u5F55"><a href="#u521B_u5EFA_u6587_u4EF6_u76EE_u5F55" class="headerlink" title="创建文件目录"></a>创建文件目录</h1><p>hadoop fs -mkdir /usr/local/log/test</p>
<h1 id="u5220_u9664_u6587_u4EF6"><a href="#u5220_u9664_u6587_u4EF6" class="headerlink" title="删除文件"></a>删除文件</h1><p>/hadoop fs -rm /usr/local/log/07</p>
<h1 id="u4E0A_u4F20_u4E00_u4E2A_u672C_u673A_u6587_u4EF6_u5230HDFS_u4E2D/usr/local/log/_u76EE_u5F55_u4E0B"><a href="#u4E0A_u4F20_u4E00_u4E2A_u672C_u673A_u6587_u4EF6_u5230HDFS_u4E2D/usr/local/log/_u76EE_u5F55_u4E0B" class="headerlink" title="上传一个本机文件到HDFS中/usr/local/log/目录下"></a>上传一个本机文件到HDFS中/usr/local/log/目录下</h1><p>adoop fs -put /usr/local/src/infobright-4.0.6-0-x86_64-ice.rpm  /usr/local/log/</p>
<h1 id="u4E0B_u8F7D"><a href="#u4E0B_u8F7D" class="headerlink" title="下载"></a>下载</h1><p>hadoop fs –get /usr/local/log/infobright-4.0.6-0-x86_64-ice.rpm   /usr/local/src/</p>
<h1 id="u67E5_u770B_u6587_u4EF6"><a href="#u67E5_u770B_u6587_u4EF6" class="headerlink" title="查看文件"></a>查看文件</h1><p>hadoop fs -cat /usr/local/log/zabbix/access.log.zabbix</p>
<h1 id="u67E5_u770BHDFS_u57FA_u672C_u4F7F_u7528_u60C5_u51B5"><a href="#u67E5_u770BHDFS_u57FA_u672C_u4F7F_u7528_u60C5_u51B5" class="headerlink" title="查看HDFS基本使用情况"></a>查看HDFS基本使用情况</h1><h1 id="hadoop_dfsadmin_-report"><a href="#hadoop_dfsadmin_-report" class="headerlink" title="hadoop dfsadmin -report"></a>hadoop dfsadmin -report</h1><p>DEPRECATED: Use of this script to execute hdfs command is deprecated.<br>Instead use the hdfs command for it.</p>
<p>Configured Capacity: 29565767680 (27.54 GB)<br>Present Capacity: 17956433920 (16.72 GB)<br>DFS Remaining: 17956405248 (16.72 GB)<br>DFS Used: 28672 (28 KB)<br>DFS Used%: 0.00%<br>Under replicated blocks: 0<br>Blocks with corrupt replicas: 0<br>Missing blocks: 0</p>
<hr>
<p>Live datanodes (1):</p>
<p>Name: 127.0.0.1:50010 (localhost)<br>Hostname: ocean-lab.ocean.org<br>Decommission Status : Normal<br>Configured Capacity: 29565767680 (27.54 GB)<br>DFS Used: 28672 (28 KB)<br>Non DFS Used: 11609333760 (10.81 GB)<br>DFS Remaining: 17956405248 (16.72 GB)<br>DFS Used%: 0.00%<br>DFS Remaining%: 60.73%<br>Configured Cache Capacity: 0 (0 B)<br>Cache Used: 0 (0 B)<br>Cache Remaining: 0 (0 B)<br>Cache Used%: 100.00%<br>Cache Remaining%: 0.00%<br>Xceivers: 1<br>Last contact: Thu Dec 24 09:52:14 CST 2015</p>
<p>自此，你已经掌握 Hadoop 的配置和基本使用了。</p>
<p>Reference doc:  <a href="https://hadoop.apache.org/docs/r2.6.0/" target="_blank" rel="external">https://hadoop.apache.org/docs/r2.6.0/</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://blog.suzf.net/2015/12/24/hadoop-single-node-pseudo-distributed-installation-Notes/" data-id="ciqcd6ltx009eclo9exgydi0l" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/hadoop/">hadoop</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2015/12/25/use-vim-to-build-python-development-ide/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          使用 VIM 打造 Python 开发IDE
        
      </div>
    </a>
  
  
    <a href="/2015/12/22/why-does-ceph-monitor-db-compaction-fail/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">How-to deal with Ceph Monitor DB compaction?</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Apache/">Apache</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Auto-ops/">Auto ops</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/CouchBase/">CouchBase</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/HA/">HA</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hadoop/">Hadoop</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hardware/">Hardware</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Highcharts/">Highcharts</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/LVS/">LVS</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Life/">Life</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a><span class="category-list-count">28</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/MongoDB/">MongoDB</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Mysql/">Mysql</a><span class="category-list-count">10</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Nginx/">Nginx</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Oracle/">Oracle</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/PHP/">PHP</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Puppet/">Puppet</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a><span class="category-list-count">23</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Redis/">Redis</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Shell/">Shell</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Tomcat/">Tomcat</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Web/">Web</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Zabbix/">Zabbix</a><span class="category-list-count">13</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Apache/">Apache</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CMD/">CMD</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Ceph/">Ceph</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Debian/">Debian</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ELK/">ELK</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Exsi/">Exsi</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Flask/">Flask</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GTID/">GTID</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Kernel/">Kernel</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Kickstart/">Kickstart</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LB/">LB</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LVS/">LVS</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Life/">Life</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux/">Linux</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Lnmp/">Lnmp</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Log/">Log</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MongoDB/">MongoDB</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Mysql/">Mysql</a><span class="tag-list-count">15</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Nginx/">Nginx</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NoSQL/">NoSQL</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Oracle/">Oracle</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PHP/">PHP</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Proxy/">Proxy</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Puppet/">Puppet</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/">Python</a><span class="tag-list-count">23</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RAC/">RAC</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Re/">Re</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ZK/">ZK</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Zabbix/">Zabbix</a><span class="tag-list-count">13</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/bug/">bug</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/code/">code</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/coredump/">coredump</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/couchbase/">couchbase</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/debug/">debug</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/diy/">diy</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/elasticsearch/">elasticsearch</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/expect/">expect</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/facter/">facter</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/faq/">faq</a><span class="tag-list-count">9</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hadoop/">hadoop</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/highcharts/">highcharts</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/idrac/">idrac</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/iso/">iso</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kafka/">kafka</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/lvm/">lvm</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pip/">pip</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/redis/">redis</a><span class="tag-list-count">7</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/rewrite/">rewrite</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/rsync/">rsync</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/rsyslog/">rsyslog</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/snmp/">snmp</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/strace/">strace</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sudo/">sudo</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tcpdump/">tcpdump</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tomcat/">tomcat</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/vim/">vim</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/web/">web</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/wiki/">wiki</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/zookeeper/">zookeeper</a><span class="tag-list-count">4</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Apache/" style="font-size: 10px;">Apache</a> <a href="/tags/CMD/" style="font-size: 10px;">CMD</a> <a href="/tags/Ceph/" style="font-size: 10.91px;">Ceph</a> <a href="/tags/Debian/" style="font-size: 10px;">Debian</a> <a href="/tags/ELK/" style="font-size: 10px;">ELK</a> <a href="/tags/Exsi/" style="font-size: 10px;">Exsi</a> <a href="/tags/Flask/" style="font-size: 10px;">Flask</a> <a href="/tags/GTID/" style="font-size: 10.91px;">GTID</a> <a href="/tags/Kernel/" style="font-size: 10.91px;">Kernel</a> <a href="/tags/Kickstart/" style="font-size: 10px;">Kickstart</a> <a href="/tags/LB/" style="font-size: 10px;">LB</a> <a href="/tags/LVS/" style="font-size: 10px;">LVS</a> <a href="/tags/Life/" style="font-size: 10px;">Life</a> <a href="/tags/Linux/" style="font-size: 10px;">Linux</a> <a href="/tags/Lnmp/" style="font-size: 10px;">Lnmp</a> <a href="/tags/Log/" style="font-size: 10px;">Log</a> <a href="/tags/MongoDB/" style="font-size: 11.82px;">MongoDB</a> <a href="/tags/Mysql/" style="font-size: 19.09px;">Mysql</a> <a href="/tags/Nginx/" style="font-size: 16.36px;">Nginx</a> <a href="/tags/NoSQL/" style="font-size: 12.73px;">NoSQL</a> <a href="/tags/Oracle/" style="font-size: 11.82px;">Oracle</a> <a href="/tags/PHP/" style="font-size: 10.91px;">PHP</a> <a href="/tags/Proxy/" style="font-size: 10px;">Proxy</a> <a href="/tags/Puppet/" style="font-size: 14.55px;">Puppet</a> <a href="/tags/Python/" style="font-size: 20px;">Python</a> <a href="/tags/RAC/" style="font-size: 10.91px;">RAC</a> <a href="/tags/Re/" style="font-size: 11.82px;">Re</a> <a href="/tags/ZK/" style="font-size: 10px;">ZK</a> <a href="/tags/Zabbix/" style="font-size: 18.18px;">Zabbix</a> <a href="/tags/bug/" style="font-size: 10px;">bug</a> <a href="/tags/code/" style="font-size: 10px;">code</a> <a href="/tags/coredump/" style="font-size: 10px;">coredump</a> <a href="/tags/couchbase/" style="font-size: 10px;">couchbase</a> <a href="/tags/debug/" style="font-size: 10px;">debug</a> <a href="/tags/diy/" style="font-size: 10px;">diy</a> <a href="/tags/elasticsearch/" style="font-size: 10px;">elasticsearch</a> <a href="/tags/expect/" style="font-size: 10px;">expect</a> <a href="/tags/facter/" style="font-size: 10px;">facter</a> <a href="/tags/faq/" style="font-size: 17.27px;">faq</a> <a href="/tags/hadoop/" style="font-size: 10px;">hadoop</a> <a href="/tags/highcharts/" style="font-size: 10px;">highcharts</a> <a href="/tags/idrac/" style="font-size: 10px;">idrac</a> <a href="/tags/iso/" style="font-size: 10px;">iso</a> <a href="/tags/kafka/" style="font-size: 10px;">kafka</a> <a href="/tags/lvm/" style="font-size: 10px;">lvm</a> <a href="/tags/pip/" style="font-size: 12.73px;">pip</a> <a href="/tags/redis/" style="font-size: 15.45px;">redis</a> <a href="/tags/rewrite/" style="font-size: 10px;">rewrite</a> <a href="/tags/rsync/" style="font-size: 10px;">rsync</a> <a href="/tags/rsyslog/" style="font-size: 10px;">rsyslog</a> <a href="/tags/snmp/" style="font-size: 10px;">snmp</a> <a href="/tags/strace/" style="font-size: 10px;">strace</a> <a href="/tags/sudo/" style="font-size: 10px;">sudo</a> <a href="/tags/tcpdump/" style="font-size: 10px;">tcpdump</a> <a href="/tags/tomcat/" style="font-size: 13.64px;">tomcat</a> <a href="/tags/vim/" style="font-size: 10.91px;">vim</a> <a href="/tags/web/" style="font-size: 12.73px;">web</a> <a href="/tags/wiki/" style="font-size: 10px;">wiki</a> <a href="/tags/zookeeper/" style="font-size: 12.73px;">zookeeper</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/05/">May 2016</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/04/">April 2016</a><span class="archive-list-count">13</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/03/">March 2016</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/02/">February 2016</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/01/">January 2016</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/12/">December 2015</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/11/">November 2015</a><span class="archive-list-count">9</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/10/">October 2015</a><span class="archive-list-count">12</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/08/">August 2015</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/07/">July 2015</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/06/">June 2015</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/05/">May 2015</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/03/">March 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/12/">December 2014</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/11/">November 2014</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/10/">October 2014</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/09/">September 2014</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/08/">August 2014</a><span class="archive-list-count">14</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/07/">July 2014</a><span class="archive-list-count">10</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2016/05/12/839/">Linux 下使用 strace 诊断疑难杂症</a>
          </li>
        
          <li>
            <a href="/2016/04/27/MySQL_mysqldump_数据导出详解/">MySQL mysqldump 数据导出详解</a>
          </li>
        
          <li>
            <a href="/2016/04/24/Python_Re_module_learn/">Python Re module learn</a>
          </li>
        
          <li>
            <a href="/2016/04/22/Python正则表达式操作指南/">Python正则表达式操作指南</a>
          </li>
        
          <li>
            <a href="/2016/04/18/Hello_Kafka/">Hello Kafka</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2016 Jeffrey Su<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">
  <script src="/fancybox/jquery.fancybox.pack.js" type="text/javascript"></script>


<script src="/js/script.js" type="text/javascript"></script>

  </div>
</body>
</html>